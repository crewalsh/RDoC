---
title: "MVPA DFR Unsmoothed"
author: "Catherine Walsh"
date: "8/31/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Another potentially interesting question we can try to answer is how much face representation we see across the task. In order to do so, we've trained a linear SVM classifier within subjects on the data from the smoothed FFA localizer to classify signal into faces, objects and scrambles. We can then apply that classifier to various facets of our data. For each of these analyses, we will look at the probability of the classifier predicting a face. If the classifier does indeed predict a face, we score that TR with a "1", otherwise, it gets a "0", meaning chance becomes 1/3 = .33. 

First, we will apply it to each TR of individual trials. Trials are split into 4 bins based on accuracy and load, and averaged over those measures to create a single time course for each category. The classifier was also applied to each TR of a "template" for each condition. In this analysis, all trials in a given condition were averaged to create a prototypical example for the category. The classifier was then applied to those averages. 

We can then look at the probability of classification across subjects. First, we look at it across all subjects, but then we can look at it across our working memory capacity groups. 

Finally, we will relate these neural measures to behavior, both averaged over time and for each TR. 

```{r import packages, data etc}

library(reshape2)
library(tidyverse)
library(patchwork)

load('data/behav.RData')
load('data/split_groups_info.RData')
load('data/DFR_split_groups_info.RData')

source("helper_fxns/split_into_groups.R")
source('helper_fxns/prep_trial_levels_for_plot.R')
source("helper_fxns/split_trial_type.R")

se <- function(x) {
  sd(x,na.rm=TRUE)/sqrt(length(x[!is.na(x)])) 
}

```

```{r load in data}

#classifier information
clf_acc <- read.csv('data/MVPA/DFR_unsmoothed/clf_acc.csv', header=FALSE)
best_c <- read.csv('data/MVPA/DFR_unsmoothed/best_C.csv', header=FALSE)

# averaages from template 
averages_from_template <- list(high_correct = read.csv('data/MVPA/DFR_unsmoothed/all_suj_high_correct_avg.csv',header=FALSE), 
                               high_incorrect = read.csv('data/MVPA/DFR_unsmoothed/all_suj_high_incorrect_avg.csv',header=FALSE), 
                               low_correct = read.csv('data/MVPA/DFR_unsmoothed/all_suj_low_correct_avg.csv',header=FALSE), 
                               low_incorrect = read.csv('data/MVPA/DFR_unsmoothed/all_suj_low_incorrect_avg.csv',header=FALSE))

averages_from_template[["high_load_correct_diff"]] <- averages_from_template[["high_correct"]][,1:14] - averages_from_template[["high_incorrect"]][,1:14]
averages_from_template[["low_load_correct_diff"]] <- averages_from_template[["low_correct"]][,1:14] - averages_from_template[["low_incorrect"]][,1:14]



# averages from individual trials
individual_trial_averages_probs <- list(
  high_correct = read.csv('data/MVPA/DFR_unsmoothed/all_suj_high_correct_indiv_avg_probs.csv',header=FALSE),
  high_incorrect = read.csv('data/MVPA/DFR_unsmoothed/all_suj_high_incorrect_indiv_avg_probs.csv',header=FALSE),
  low_correct = read.csv('data/MVPA/DFR_unsmoothed/all_suj_low_correct_indiv_avg_probs.csv',header=FALSE),
  low_incorrect = read.csv('data/MVPA/DFR_unsmoothed/all_suj_low_incorrect_indiv_avg_probs.csv',header=FALSE)) 

individual_trial_averages_probs[["high_load_correct_diff"]] <- individual_trial_averages_probs[["high_correct"]][,1:14] - individual_trial_averages_probs[["high_incorrect"]][,1:14]
individual_trial_averages_probs[["low_load_correct_diff"]] <- individual_trial_averages_probs[["low_correct"]][,1:14] - individual_trial_averages_probs[["low_incorrect"]][,1:14]


# averages from individual trials
individual_trial_averages_preds <- list(
  high_correct = read.csv('data/MVPA/DFR_unsmoothed/all_suj_high_correct_indiv_avg_preds.csv',header=FALSE),
  high_incorrect = read.csv('data/MVPA/DFR_unsmoothed/all_suj_high_incorrect_indiv_avg_preds.csv',header=FALSE),
  low_correct = read.csv('data/MVPA/DFR_unsmoothed/all_suj_low_correct_indiv_avg_preds.csv',header=FALSE),
  low_incorrect = read.csv('data/MVPA/DFR_unsmoothed/all_suj_low_incorrect_indiv_avg_preds.csv',header=FALSE)) 

individual_trial_averages_preds[["high_load_correct_diff"]] <- individual_trial_averages_preds[["high_correct"]][,1:14] - individual_trial_averages_preds[["high_incorrect"]][,1:14]

individual_trial_averages_preds[["low_load_correct_diff"]] <- individual_trial_averages_preds[["low_correct"]][,1:14] - individual_trial_averages_preds[["low_incorrect"]][,1:14]


# replace NaNs with NA, add in PTID  

for (i in seq.int(1,6)){
  for (ii in seq.int(1,14)){
    averages_from_template[[i]][is.nan(averages_from_template[[i]][,ii]),ii] <- NA
    individual_trial_averages_probs[[i]][is.nan(individual_trial_averages_probs[[i]][,ii]),ii] <- NA
    individual_trial_averages_preds[[i]][is.nan(individual_trial_averages_preds[[i]][,ii]),ii] <- NA
    
  }
  averages_from_template[[i]]$PTID <- constructs_fMRI$PTID
  individual_trial_averages_probs[[i]]$PTID <- constructs_fMRI$PTID
  individual_trial_averages_preds[[i]]$PTID <- constructs_fMRI$PTID
  
}

save(list=c("clf_acc", "best_c", "averages_from_template", "individual_trial_averages_probs","individual_trial_averages_preds"), file = "data/MVPA_DFR_delay_mask.RData")

```

# Probability of classifying faces 

On average, we were able to classify faces with 63.2% accuracy (statistically significantly different from chance = 0.33). The classifier was trained on data from an independent FFA localizer. Data was masked derived from the high > low load contrast during the DFR task - that is, regions that are sensitive to load during the delay period. From that mask, the top 100 voxels based on the faces vs objects contrast in the overall subject GLM were selected as features for the classifier. The data used to train the classifier were shifted by 4.5 seconds to account for the hemodynamic delay. 

A linear SVM classifer was used; the localizer task was split into 6 blocks of stimuli. These blocks were used in a pre-defined split for cross validation, where one block of each stimulus type was held out as a test set. Data were normalized within the training and test sets separately. Within this training set, another cross validation process was repeated to tune the cost of the model over the values [0.01, 0.1, 1, 10]. The best value of the cost function was used for each cross validation to score the classifier on the test set. The best classifer was also used to predict face presence at each TR during the DFR task. 


```{r calculate classifier average}

clf_acc$average <- rowMeans(clf_acc)
t.test(clf_acc$average,mu=0.33)

ggplot(data = clf_acc, aes(x = average))+ 
  geom_histogram()+
  geom_vline(aes(xintercept=0.33), linetype="dotted")+
  theme_classic()+
  xlab("Average classifier accuracy")


```

```{r average over all subjects}

template_preds_melt <- prep_trial_levels_for_plot(averages_from_template)
individual_trial_probs_melt <- prep_trial_levels_for_plot(individual_trial_averages_probs)
individual_trial_preds_melt <- prep_trial_levels_for_plot(individual_trial_averages_preds)

```

## All subjects

The shape of the time course is different here than it was for the fusiform region - here, we're well below chance for encoding, but start to see a significant probability during delay (starting around TR 8) and the probe. 

### From individual trials 

During delay period, there is no difference in probability of classifying face across load, but we do see significantly higher probability of classifying a face in correct vs incorrect trials. 

```{r plot individual trial avgs for all subjects}

ggplot(data=individual_trial_probs_melt %>% filter(level %in% c("high_correct", "high_incorrect", "low_correct", "low_incorrect")),aes(x=TR,y=value))+
  geom_line(aes(color=level))+
  geom_line(aes(x=TR,y=0.33),color="black",linetype="dotted")+
  geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=level),alpha=0.2)+
  scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
  ylab("Probability of classifier predicting a face")+
  theme_classic()


```

```{r compare indiv delay prob}

delay_level_avg <- data.frame(high = rowMeans(cbind(individual_trial_averages_probs[["high_correct"]]$V8, individual_trial_averages_probs[["high_incorrect"]]$V8), na.rm=TRUE), low = rowMeans(cbind(individual_trial_averages_probs[["low_correct"]]$V8, individual_trial_averages_probs[["low_incorrect"]]$V8),na.rm=TRUE))

t.test(delay_level_avg$high,delay_level_avg$low,paired=TRUE)

delay_acc_avg <- data.frame(correct = rowMeans(cbind(individual_trial_averages_probs[["high_correct"]]$V8, individual_trial_averages_probs[["low_correct"]]$V8), na.rm=TRUE), incorrect = rowMeans(cbind(individual_trial_averages_probs[["low_incorrect"]]$V8, individual_trial_averages_probs[["high_incorrect"]]$V8),na.rm=TRUE))

t.test(delay_acc_avg$correct,delay_acc_avg$incorrect,paired=TRUE)


```

In this mask, we see pretty much always a larger probability of classifying a face from correct trials.

```{r plot differences between correctness for all subjects}

ggplot(data=individual_trial_probs_melt %>% filter(level %in% c("low_load_correct_diff","high_load_correct_diff")),aes(x=TR,y=value))+
  geom_line(aes(x=TR,y=0), linetype="dotted")+
  geom_line(aes(color=level))+
  geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=level),alpha=0.2)+
  scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
  ylab("Correct - Incorrect Diff in Probability of Classifying Faces")+
  theme_classic()


```

### From templates

In the templates, we see a similar structure as in the individual trials. However, instead of only seeing differences in load (like we saw in the fusiform data), we see a difference in accuracy, where there is higher probability of being able to classify a face from delay and probe periods in correct trials (regardless of load) than incorrect trials. We also see a difference in load during delay but not probe.

```{r plot template average over all subjects}


ggplot(data=template_preds_melt%>% filter(level %in% c("high_correct", "high_incorrect", "low_correct", "low_incorrect")),aes(x=TR,y=value))+
  geom_line(aes(color=level))+
  geom_line(aes(x=TR,y=0.33),color="black",linetype="dotted")+
  geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=level),alpha=0.2)+
  scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
  ylab("Probability of classifier predicting a face")+
  theme_classic()


```

```{r test differences in accuracy}

acc_data_delay <- data.frame(correct = rowMeans(cbind(averages_from_template[["high_correct"]]$V8,averages_from_template[["low_correct"]]$V8)), incorrect = averages_from_template[["high_incorrect"]]$V8)
t.test(acc_data_delay$correct,acc_data_delay$incorrect, paired=TRUE)

acc_data_probe <- data.frame(correct = rowMeans(cbind(averages_from_template[["high_correct"]]$V10,averages_from_template[["low_correct"]]$V10)), incorrect = averages_from_template[["high_incorrect"]]$V10)
t.test(acc_data_probe$correct,acc_data_probe$incorrect, paired=TRUE)

```

```{r test differences in load}

load_data_delay <- data.frame(correct = rowMeans(cbind(averages_from_template[["high_correct"]]$V8,averages_from_template[["high_incorrect"]]$V8)), incorrect = averages_from_template[["low_correct"]]$V8)
t.test(load_data_delay$correct,load_data_delay$incorrect, paired=TRUE)

load_data_probe <- data.frame(correct = rowMeans(cbind(averages_from_template[["high_correct"]]$V10,averages_from_template[["high_incorrect"]]$V10)), incorrect = averages_from_template[["low_correct"]]$V10)
t.test(load_data_probe$correct,load_data_probe$incorrect, paired=TRUE)

```

```{r probe template anova}

probe_data_template <- data.frame(high_correct=averages_from_template[["high_correct"]]$V10, high_incorrect = averages_from_template[["high_incorrect"]]$V10, low_correct = averages_from_template[["low_correct"]]$V10)
probe_data_template <- melt(probe_data_template)

probe.aov <- aov(value ~ variable, data = probe_data_template)
summary(probe.aov)
TukeyHSD(probe.aov)

```

I'm not 100% sure this is statistically valid, but the average prediction is higher for the predictions from template vs predictions from the individual trials. 

```{r compare template to indiv trials}

compare_across_temp_indiv <- data.frame(template = rowMeans(cbind(averages_from_template[["high_correct"]]$V10,
                                                                  averages_from_template[["high_incorrect"]]$V10,
                                                                  averages_from_template[["low_correct"]]$V10)),
                                        indiv = rowMeans(cbind(individual_trial_averages_probs[["high_correct"]]$V10,
                                                               individual_trial_averages_probs[["high_incorrect"]]$V10,
                                                               individual_trial_averages_probs[["low_correct"]]$V10)))

wilcox.test(compare_across_temp_indiv$template, compare_across_temp_indiv$indiv,paired=TRUE)

```

There is a difference between correct and incorrect trials at probe, which we saw in aboe data. 

```{r plot differences between correctness for template}

ggplot(data=template_preds_melt %>% filter(level %in% c("low_load_correct_diff","high_load_correct_diff")),aes(x=TR,y=value))+
  geom_line(aes(color=level))+
  geom_line(aes(x=TR,y=0),color="black",linetype="dotted")+
  geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=level),alpha=0.2)+
  scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
  ylab("Correct - Incorrect Diff in Probability of Classifying Faces")+
  theme_classic()

probe_correct_diff_high <- data.frame(correct=averages_from_template[["high_correct"]]$V11, incorrect=averages_from_template[["high_incorrect"]]$V11)
t.test(probe_correct_diff_high$correct, probe_correct_diff_high$incorrect, paired=TRUE)

```

## By Working Memory Capacity Groups 

```{r split into groups}

split_template <- split_trial_type(averages_from_template,WM_groups)
split_indiv_probs <- split_trial_type(individual_trial_averages_probs, WM_groups)

```

### From Indiv Trials  

Thhere are no differences between working memory capacity groups. 

```{r split group indiv prob plots}

indiv_avgs <- list()

for (i in seq.int(1,4)){
  indiv_avgs[[i]] <- ggplot(data = split_indiv_probs[["avgs"]][[i]][["all"]])+
    geom_line(aes(x=TR,y=mean,color=group))+
    geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=group),alpha=0.2)+
    geom_line(aes(x=TR,y=0.33),color="black",linetype="dotted")+
    scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
    ggtitle(names(split_indiv_probs[["avgs"]])[i])+
    ylab("Probability")+
    theme_classic()
  
}

(indiv_avgs[[1]] + indiv_avgs[[2]]) / (indiv_avgs[[3]] + indiv_avgs[[4]])+
  plot_layout(guides = "collect")+
  plot_annotation(title="Probability of classifier predicting a face from individual trials")

```

```{r anova between groups indiv}

for (trial_type in seq.int(1,4)){ 
  print(names(split_indiv_probs[["all_data"]])[trial_type])
  temp.aov <- aov(split_indiv_probs[["all_data"]][[trial_type]][["all"]][,8] ~ split_indiv_probs[["all_data"]][[trial_type]][["all"]][,16])
  print(summary(temp.aov))
  print(TukeyHSD(temp.aov))
}

```

### From templates 

Similarly, no differences between groups at delay or probe in the template. 

```{r split group template prob plots}

template_avgs <- list()

for (i in seq.int(1,4)){
  template_avgs[[i]] <- ggplot(data = split_template[["avgs"]][[i]][["all"]])+
    geom_line(aes(x=TR,y=mean,color=group))+
    geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=group),alpha=0.2)+
    geom_line(aes(x=TR,y=0.33),color="black",linetype="dotted")+
    scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
    ggtitle(names(split_template[["avgs"]])[i])+
    ylab("Probability")+
    theme_classic()
  
}

(template_avgs[[1]] + template_avgs[[2]]) / (template_avgs[[3]] + template_avgs[[4]])+
  plot_layout(guides = "collect")+
  plot_annotation(title="Probability of classifier predicting a face from trial templates")

```

```{r anova between groups template}

for (trial_type in seq.int(1,4)){ 
  print(names(split_template[["all_data"]])[trial_type])
  temp.aov <- aov(split_template[["all_data"]][[trial_type]][["all"]][,10] ~ split_template[["all_data"]][[trial_type]][["all"]][,16])
  print(summary(temp.aov))
  print(TukeyHSD(temp.aov))
}

```

# Correlation with Behavior 

## Individual Trials

### Averaged over time

We see that there is a significant negative correlation between classification averaged over time and accuracy for the high load correct trials, and a significant positive correlation between BPRS and the difference between correct and incorrect trials at high load.  

```{r make plots to correlate indiv over time}

indiv_avg_over_time <- data.frame(high_correct = rowMeans(individual_trial_averages_probs[["high_correct"]][,1:14]),
                                  high_incorrect = rowMeans(individual_trial_averages_probs[["high_incorrect"]][,1:14]),
                                  low_correct = rowMeans(individual_trial_averages_probs[["low_correct"]][,1:14]),
                                  low_incorrect = rowMeans(individual_trial_averages_probs[["low_incorrect"]][,1:14],na.rm=TRUE), 
                                  high_load_diff_correct = rowMeans(individual_trial_averages_probs[["high_load_correct_diff"]][,1:14]),
                                  low_load_diff_correct = rowMeans(individual_trial_averages_probs[["low_load_correct_diff"]][,1:14]))

indiv_avg_over_time[is.na(indiv_avg_over_time)] <- NA 
indiv_avg_over_time <- data.frame(indiv_avg_over_time, omnibus_span = constructs_fMRI$omnibus_span_no_DFR_MRI, PTID = constructs_fMRI$PTID)
indiv_avg_over_time <- merge(indiv_avg_over_time, p200_data[,c("PTID","BPRS_TOT","XDFR_MRI_ACC_L3", "XDFR_MRI_ACC_L1")],by="PTID")


plot_list <- list()

for (i in seq.int(1,6)){
  plot_data <- indiv_avg_over_time[,c(i+1,8:11)]
  colnames(plot_data)[1] <- "prob"
  plot_list[["omnibus"]][[i]] <- ggplot(data = plot_data,aes(x=prob,y=omnibus_span))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(indiv_avg_over_time)[i+1])+
    theme_classic()
  
  plot_list[["DFR_Acc"]][[i]] <- ggplot(data = plot_data,aes(x=prob,y=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(indiv_avg_over_time)[i+1])+
    theme_classic()
  
  plot_list[["BPRS"]][[i]] <- ggplot(data = plot_data,aes(x=prob,y=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(indiv_avg_over_time)[i+1])+
    theme_classic()
  
}

(plot_list[["omnibus"]][[1]] + plot_list[["omnibus"]][[2]]) /
  (plot_list[["omnibus"]][[3]] + plot_list[["omnibus"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and Omnibus Span")

(plot_list[["omnibus"]][[5]] + plot_list[["omnibus"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and Omnibus Span")

(plot_list[["DFR_Acc"]][[1]] + plot_list[["DFR_Acc"]][[2]]) /
  (plot_list[["DFR_Acc"]][[3]] + plot_list[["DFR_Acc"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and DFR High Load Accuracy")

(plot_list[["DFR_Acc"]][[5]] + plot_list[["DFR_Acc"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and DFR High Load Accuracy")

(plot_list[["BPRS"]][[1]] + plot_list[["BPRS"]][[2]]) /
  (plot_list[["BPRS"]][[3]] + plot_list[["BPRS"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and BPRS")
(plot_list[["BPRS"]][[5]] + plot_list[["BPRS"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and BPRS")

cor.test(indiv_avg_over_time$high_load_diff_correct, indiv_avg_over_time$omnibus_span)
cor.test(indiv_avg_over_time$low_load_diff_correct, indiv_avg_over_time$omnibus_span)

cor.test(indiv_avg_over_time$high_correct, indiv_avg_over_time$XDFR_MRI_ACC_L3)
cor.test(indiv_avg_over_time$high_load_diff_correct, indiv_avg_over_time$BPRS_TOT)



```

### All subjects

#### Across time 

If we look at the patterns over time, we can see that BPRS tends to be positively related to classification only in the probe period during the high load trials, but starts to peak earlier in the low load trials. There is most correlation with accuracy during the encoding period. We also see a slight negative correlation with omnibus span during probe, particularly in the correct high load trials. 

Next step is to pull out some of these correlations and see if they're significant. 

```{r make indiv correlations with behav across time for all subj}
data_to_plot <- merge(constructs_fMRI,p200_data,by="PTID")
data_to_plot <- merge(data_to_plot,p200_clinical_zscores,by="PTID")

data_to_plot <- data_to_plot[,c(1,7,14,15,41,42)]
data_to_plot$ACC_LE <- data_to_plot$XDFR_MRI_ACC_L3 - data_to_plot$XDFR_MRI_ACC_L1

corr_to_behav_plots <- list()

for (i in seq.int(1,6)){
  measure_by_time <- data.frame(matrix(nrow=4,ncol=14))
  
  for (measure in seq.int(2,5)){
    for (TR in seq.int(1,14)){
      measure_by_time[measure-1,TR] <- cor(data_to_plot[,measure],individual_trial_averages_probs[[i]][,TR],use = "pairwise.complete.obs")
    }
  }
  
  measure_by_time <- data.frame(t(measure_by_time))
  measure_by_time$TR <- seq.int(1,14)
  
  colnames(measure_by_time)[1:4] <- colnames(data_to_plot)[2:5]
  
  melted_measure_by_time <- melt(measure_by_time,id.vars="TR")
  
  corr_to_behav_plots[[names(individual_trial_averages_probs)[i]]] <- ggplot(data=melted_measure_by_time,aes(x=TR,y=value))+
    geom_line(aes(color=variable))+
    scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
    ggtitle(names(individual_trial_averages_probs)[i])+
    theme_classic()
  
}


```

```{r print TR indiv correlation all subj plots}

(corr_to_behav_plots[[1]] + corr_to_behav_plots[[2]]) / (corr_to_behav_plots[[3]] + corr_to_behav_plots[[4]])+
  plot_layout(guides="collect")+
  plot_annotation(title = "Correlation between face classification and behavioral measures")

(corr_to_behav_plots[[5]] + corr_to_behav_plots[[6]])+
  plot_layout(guides="collect")+
  plot_annotation(title = "Correlation between difference across correctness in face classification and behavioral measures")




```

```{r pull out specfic time points from indiv correlation}

plot_list <- list()

for(trial_type in seq.int(1,6)){ 
  temp_plot_data <- merge(p200_data, individual_trial_averages_probs[[trial_type]],by="PTID")
  temp_plot_data <- merge(temp_plot_data,constructs_fMRI,by="PTID")
  
  plot_list[["omnibus"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["omnibus"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["omnibus"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  # Acc
  
  plot_list[["L3_Acc"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["L3_Acc"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["L3_Acc"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  # BPRS  
  plot_list[["BPRS"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["BPRS"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["BPRS"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  
}


```

#### Encoding 

We see significant negative relationships with omnibus span and classification at correct high load trials, negative relationships with high load accuracy at high load trials (regardless of accuracy), and positive relationships with BPRS total at both correct high load trials and the difference between correct and incorrect at high load. 

```{r plot specific time points from indiv - encoding }

(plot_list[["omnibus"]][["cue"]][[1]] + plot_list[["omnibus"]][["cue"]][[2]]) /  
  (plot_list[["omnibus"]][["cue"]][[3]] + plot_list[["omnibus"]][["cue"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at Cue Period")

(plot_list[["omnibus"]][["cue"]][[5]] + plot_list[["omnibus"]][["cue"]][[6]])  +
  plot_annotation(title = "Omnibus vs Classification at Cue Period")

(plot_list[["L3_Acc"]][["cue"]][[1]] + plot_list[["L3_Acc"]][["cue"]][[2]]) /  
  (plot_list[["L3_Acc"]][["cue"]][[3]] + plot_list[["L3_Acc"]][["cue"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at Cue Period")

(plot_list[["L3_Acc"]][["cue"]][[5]] + plot_list[["L3_Acc"]][["cue"]][[6]])  +
  plot_annotation(title = "L3_Acc vs Classification at Cue Period")

(plot_list[["BPRS"]][["cue"]][[1]] + plot_list[["BPRS"]][["cue"]][[2]]) /  
  (plot_list[["BPRS"]][["cue"]][[3]] + plot_list[["BPRS"]][["cue"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at Cue Period")

(plot_list[["BPRS"]][["cue"]][[5]] + plot_list[["BPRS"]][["cue"]][[6]])  +
  plot_annotation(title = "BPRS vs Classification at Cue Period")


cor.test(individual_trial_averages_probs[["high_correct"]]$V6,temp_plot_data$omnibus_span_no_DFR_MRI)
cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V6,temp_plot_data$omnibus_span_no_DFR_MRI)
cor.test(individual_trial_averages_probs[["low_load_correct_diff"]]$V6,temp_plot_data$omnibus_span_no_DFR_MRI)

cor.test(individual_trial_averages_probs[["high_correct"]]$V6,temp_plot_data$XDFR_MRI_ACC_L3)
cor.test(individual_trial_averages_probs[["high_incorrect"]]$V6,temp_plot_data$XDFR_MRI_ACC_L3)

cor.test(individual_trial_averages_probs[["high_correct"]]$V6[temp_plot_data$BPRS_TOT < 70],temp_plot_data$BPRS_TOT[temp_plot_data$BPRS_TOT < 70])
cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V6[temp_plot_data$BPRS_TOT < 70],temp_plot_data$BPRS_TOT[temp_plot_data$BPRS_TOT < 70])


``` 

#### Delay 

There are no significant relationships between individual differences and classification probability at delay. 

``` {r plot specific time points from indiv - delay }

(plot_list[["omnibus"]][["delay"]][[1]] + plot_list[["omnibus"]][["delay"]][[2]]) /  
  (plot_list[["omnibus"]][["delay"]][[3]] + plot_list[["omnibus"]][["delay"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at delay Period")

(plot_list[["omnibus"]][["delay"]][[5]] + plot_list[["omnibus"]][["delay"]][[6]])  +
  plot_annotation(title = "Omnibus vs Classification at delay Period")

(plot_list[["L3_Acc"]][["delay"]][[1]] + plot_list[["L3_Acc"]][["delay"]][[2]]) /  
  (plot_list[["L3_Acc"]][["delay"]][[3]] + plot_list[["L3_Acc"]][["delay"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at delay Period")

(plot_list[["L3_Acc"]][["delay"]][[5]] + plot_list[["L3_Acc"]][["delay"]][[6]])  +
  plot_annotation(title = "L3_Acc vs Classification at delay Period")

(plot_list[["BPRS"]][["delay"]][[1]] + plot_list[["BPRS"]][["delay"]][[2]]) /  
  (plot_list[["BPRS"]][["delay"]][[3]] + plot_list[["BPRS"]][["delay"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at delay Period")

(plot_list[["BPRS"]][["delay"]][[5]] + plot_list[["BPRS"]][["delay"]][[6]])  +
  plot_annotation(title = "BPRS vs Classification at delay Period")

cor.test(individual_trial_averages_probs[["low_load_correct_diff"]]$V8,temp_plot_data$omnibus_span_no_DFR_MRI)

cor.test(individual_trial_averages_probs[["low_correct"]]$V8,temp_plot_data$XDFR_MRI_ACC_L3)
cor.test(individual_trial_averages_probs[["low_load_correct_diff"]]$V8,temp_plot_data$XDFR_MRI_ACC_L3)


cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V8[temp_plot_data$BPRS_TOT < 70],temp_plot_data$BPRS_TOT[temp_plot_data$BPRS_TOT < 70])
cor.test(individual_trial_averages_probs[["high_incorrect"]]$V8[temp_plot_data$BPRS_TOT < 70],temp_plot_data$BPRS_TOT[temp_plot_data$BPRS_TOT < 70])


``` 

#### Probe

The only significant relationship here is in the difference between correct and incorrect trials at high load and high load accuracy. 

```{r plot specific time points from indiv - probe }

(plot_list[["omnibus"]][["probe"]][[1]] + plot_list[["omnibus"]][["probe"]][[2]]) /  
  (plot_list[["omnibus"]][["probe"]][[3]] + plot_list[["omnibus"]][["probe"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at probe Period")

(plot_list[["omnibus"]][["probe"]][[5]] + plot_list[["omnibus"]][["probe"]][[6]])  +
  plot_annotation(title = "Omnibus vs Classification at probe Period")

(plot_list[["L3_Acc"]][["probe"]][[1]] + plot_list[["L3_Acc"]][["probe"]][[2]]) /  
  (plot_list[["L3_Acc"]][["probe"]][[3]] + plot_list[["L3_Acc"]][["probe"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at probe Period")

(plot_list[["L3_Acc"]][["probe"]][[5]] + plot_list[["L3_Acc"]][["probe"]][[6]])  +
  plot_annotation(title = "L3_Acc vs Classification at probe Period")

(plot_list[["BPRS"]][["probe"]][[1]] + plot_list[["BPRS"]][["probe"]][[2]]) /  
  (plot_list[["BPRS"]][["probe"]][[3]] + plot_list[["BPRS"]][["probe"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at probe Period")

(plot_list[["BPRS"]][["probe"]][[5]] + plot_list[["BPRS"]][["probe"]][[6]])  +
  plot_annotation(title = "BPRS vs Classification at probe Period")

cor.test(individual_trial_averages_probs[["low_incorrect"]]$V11,temp_plot_data$omnibus_span_no_DFR_MRI)
cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V11,temp_plot_data$omnibus_span_no_DFR_MRI)
cor.test(individual_trial_averages_probs[["low_load_correct_diff"]]$V11,temp_plot_data$omnibus_span_no_DFR_MRI)

cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V11,temp_plot_data$XDFR_MRI_ACC_L3)

cor.test(individual_trial_averages_probs[["low_correct"]]$V11[temp_plot_data$BPRS_TOT < 70],temp_plot_data$BPRS_TOT[temp_plot_data$BPRS_TOT < 70])
cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V11[temp_plot_data$BPRS_TOT < 70],temp_plot_data$BPRS_TOT[temp_plot_data$BPRS_TOT < 70])
cor.test(individual_trial_averages_probs[["low_load_correct_diff"]]$V11[temp_plot_data$BPRS_TOT < 70],temp_plot_data$BPRS_TOT[temp_plot_data$BPRS_TOT < 70])




```

```{r correlate behav to each indiv category TR for each group, warning=FALSE}

behav_classification_corr_list <- list()

for (trial_type in seq.int(1,6)){ 
  group_corrs_omnibus <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_omnibus) <- names(split_indiv_probs[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_omnibus) <- seq.int(1,14)
  
  group_corrs_acc <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_acc) <- names(split_indiv_probs[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_acc) <- seq.int(1,14)
  
  group_corrs_BPRS <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_BPRS) <- names(split_indiv_probs[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_BPRS) <- seq.int(1,14)
  
  for (level in seq.int(1,3)){ 
    temp_subj <- split_indiv_probs[["all_data"]][[trial_type]][[level]][order(split_indiv_probs[["all_data"]][[trial_type]][[level]]$PTID),]
    temp_data <- data_to_plot[data_to_plot$PTID %in% split_indiv_probs[["all_data"]][[trial_type]][[level]]$PTID,]
    
    for (TR in seq.int(1,14)){
      
      group_corrs_omnibus[level,TR] <- cor(temp_subj[,TR],temp_data$omnibus_span_no_DFR_MRI,use="pairwise.complete.obs")
      group_corrs_acc[level,TR] <- cor(temp_subj[,TR],temp_data$XDFR_MRI_ACC_L3,use="pairwise.complete.obs")
      group_corrs_BPRS[level,TR] <- cor(temp_subj[,TR],temp_data$BPRS_TOT.x,use="pairwise.complete.obs")
      
    }
    group_corrs_acc$level <- factor(rownames(group_corrs_acc))
    group_corrs_BPRS$level <- factor(rownames(group_corrs_acc))
    group_corrs_omnibus$level <- factor(rownames(group_corrs_acc))
    
  }
  
  behav_classification_corr_list[["omnibus"]][[names(split_indiv_probs[["all_data"]])[trial_type]]] <- group_corrs_omnibus
  behav_classification_corr_list[["BPRS"]][[names(split_indiv_probs[["all_data"]])[trial_type]]] <- group_corrs_BPRS
  behav_classification_corr_list[["L3_Acc"]][[names(split_indiv_probs[["all_data"]])[trial_type]]] <- group_corrs_acc
}

```

#### By Working Memory Capacity

```{r melt group vs behav indiv, warning=FALSE}

behav_classification_corr_melt <- list()
behav_split_plot_list <- list()

for (measure in seq.int(1,3)){
  for (trial_type in seq.int(1,6)){ 
    behav_classification_corr_melt[[names(behav_classification_corr_list)[measure]]][[names(behav_classification_corr_list[[measure]])[trial_type]]] <- melt(behav_classification_corr_list[[measure]][[trial_type]],id.vars="level")
    behav_classification_corr_melt[[measure]][[trial_type]]$variable <- as.numeric(as.character(behav_classification_corr_melt[[measure]][[trial_type]]$variable))
    behav_classification_corr_melt[[measure]][[trial_type]]$level <- factor(behav_classification_corr_melt[[measure]][[trial_type]]$level, levels=c("high","med","low"))
    
    behav_split_plot_list[[names(behav_classification_corr_melt)[measure]]][[names(behav_classification_corr_melt[[measure]])[trial_type]]] <- 
      ggplot(data = behav_classification_corr_melt[[measure]][[trial_type]],aes(x=variable,y=value))+
      geom_line(aes(color=level))+
      scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
      ggtitle(names(behav_classification_corr_list[[measure]])[trial_type])+
      xlab("TR")+
      ylab("Correlation")+
      theme_classic()
    
  }
}

```

```{r plot indiv prob vs behav by group}

(behav_split_plot_list[["omnibus"]][[1]] + behav_split_plot_list[["omnibus"]][[2]]) / 
  (behav_split_plot_list[["omnibus"]][[3]] + behav_split_plot_list[["omnibus"]][[4]])+
  plot_annotation("Omnibus Span Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["omnibus"]][[5]] + behav_split_plot_list[["omnibus"]][[6]]) + 
  plot_annotation("Omnibus Span Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["L3_Acc"]][[1]] + behav_split_plot_list[["L3_Acc"]][[2]]) / 
  (behav_split_plot_list[["L3_Acc"]][[3]] + behav_split_plot_list[["L3_Acc"]][[4]])+
  plot_annotation("High Load Acc Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["L3_Acc"]][[5]] + behav_split_plot_list[["L3_Acc"]][[6]]) +
  plot_annotation("High Load Acc Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["BPRS"]][[1]] + behav_split_plot_list[["BPRS"]][[2]]) / 
  (behav_split_plot_list[["BPRS"]][[3]] + behav_split_plot_list[["BPRS"]][[4]])+
  plot_annotation("BPRS Total Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["BPRS"]][[5]] + behav_split_plot_list[["BPRS"]][[6]]) +
  plot_annotation("BPRS Total Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

```

## Template

### Averaged over time

There are no relationships with individual differences from the templates averaged over time. 

```{r make plots to correlate template over time}

template_avg_over_time <- data.frame(high_correct = rowMeans(averages_from_template[["high_correct"]][,1:14]),
                                     high_incorrect = rowMeans(averages_from_template[["high_incorrect"]][,1:14]),
                                     low_correct = rowMeans(averages_from_template[["low_correct"]][,1:14]),
                                     low_incorrect = rowMeans(averages_from_template[["low_incorrect"]][,1:14],na.rm=TRUE), 
                                     high_load_diff_correct = rowMeans(averages_from_template[["high_load_correct_diff"]][,1:14]),
                                     low_load_diff_correct = rowMeans(averages_from_template[["low_load_correct_diff"]][,1:14]))

template_avg_over_time[is.na(template_avg_over_time)] <- NA 
template_avg_over_time <- data.frame(template_avg_over_time, omnibus_span = constructs_fMRI$omnibus_span_no_DFR_MRI, PTID = constructs_fMRI$PTID)
template_avg_over_time <- merge(template_avg_over_time, p200_data[,c("PTID","BPRS_TOT","XDFR_MRI_ACC_L3", "XDFR_MRI_ACC_L1")],by="PTID")


plot_list <- list()

for (i in seq.int(1,6)){
  plot_data <- template_avg_over_time[,c(i+1,8:11)]
  colnames(plot_data)[1] <- "prob"
  plot_list[["omnibus"]][[i]] <- ggplot(data = plot_data,aes(y=prob,x=omnibus_span))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(template_avg_over_time)[i+1])+
    theme_classic()
  
  plot_list[["DFR_Acc"]][[i]] <- ggplot(data = plot_data,aes(y=prob,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(template_avg_over_time)[i+1])+
    theme_classic()
  
  plot_list[["BPRS"]][[i]] <- ggplot(data = plot_data,aes(y=prob,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(template_avg_over_time)[i+1])+
    theme_classic()
  
}

(plot_list[["omnibus"]][[1]] + plot_list[["omnibus"]][[2]]) /
  (plot_list[["omnibus"]][[3]] + plot_list[["omnibus"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and Omnibus Span")

(plot_list[["omnibus"]][[5]] + plot_list[["omnibus"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and Omnibus Span")

(plot_list[["DFR_Acc"]][[1]] + plot_list[["DFR_Acc"]][[2]]) /
  (plot_list[["DFR_Acc"]][[3]] + plot_list[["DFR_Acc"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and DFR High Load Accuracy")

(plot_list[["DFR_Acc"]][[5]] + plot_list[["DFR_Acc"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and DFR High Load Accuracy")

(plot_list[["BPRS"]][[1]] + plot_list[["BPRS"]][[2]]) /
  (plot_list[["BPRS"]][[3]] + plot_list[["BPRS"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and BPRS")
(plot_list[["BPRS"]][[5]] + plot_list[["BPRS"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and BPRS")


```

### All subjects

#### Over time 

```{r make template correlations with behav across time for all subj, warning = FALSE}

data_to_plot <- merge(constructs_fMRI,p200_data,by="PTID")
data_to_plot <- merge(data_to_plot,p200_clinical_zscores,by="PTID")

data_to_plot <- data_to_plot[,c(1,7,14,15,41,42)]
data_to_plot$ACC_LE <- data_to_plot$XDFR_MRI_ACC_L3 - data_to_plot$XDFR_MRI_ACC_L1

corr_to_behav_plots <- list()


for (i in seq.int(1,6)){
  measure_by_time <- data.frame(matrix(nrow=4,ncol=14))
  
  for (measure in seq.int(2,5)){
    for (TR in seq.int(1,14)){
      measure_by_time[measure-1,TR] <- cor(data_to_plot[,measure],averages_from_template[[i]][,TR],use = "pairwise.complete.obs")
    }
  }
  
  measure_by_time <- data.frame(t(measure_by_time))
  measure_by_time$TR <- seq.int(1,14)
  
  colnames(measure_by_time)[1:4] <- colnames(data_to_plot)[2:5]
  
  melted_measure_by_time <- melt(measure_by_time,id.vars="TR")
  
  corr_to_behav_plots[[names(averages_from_template)[i]]] <- ggplot(data=melted_measure_by_time,aes(x=TR,y=value))+
    geom_line(aes(color=variable))+
    scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
    ggtitle(names(averages_from_template)[i])+
    theme_classic()
  
}


```

```{r print TR template correlation all subj plots}

(corr_to_behav_plots[[1]] + corr_to_behav_plots[[2]]) / (corr_to_behav_plots[[3]] + corr_to_behav_plots[[4]])+
  plot_layout(guides="collect")+
  plot_annotation(title = "Correlation between face classification and behavioral measures")


(corr_to_behav_plots[[5]] + corr_to_behav_plots[[6]])+
  plot_layout(guides="collect")+
  plot_annotation(title = "Correlation between face classification and behavioral measures")


```

```{r pull out specfic time points from template correlation}

plot_list <- list()

for(trial_type in seq.int(1,6)){ 
  temp_plot_data <- merge(p200_data, averages_from_template[[trial_type]],by="PTID")
  temp_plot_data <- merge(temp_plot_data,constructs_fMRI,by="PTID")
  
  plot_list[["omnibus"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["omnibus"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["omnibus"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  # Acc
  
  plot_list[["L3_Acc"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["L3_Acc"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["L3_Acc"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  # BPRS  
  plot_list[["BPRS"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["BPRS"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["BPRS"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  
}


```

#### Encoding 

```{r plot specific time points from template - encoding }

(plot_list[["omnibus"]][["cue"]][[1]] + plot_list[["omnibus"]][["cue"]][[2]]) /  
  (plot_list[["omnibus"]][["cue"]][[3]] + plot_list[["omnibus"]][["cue"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at Cue Period")

(plot_list[["omnibus"]][["cue"]][[5]] + plot_list[["omnibus"]][["cue"]][[6]]) +
  plot_annotation(title = "Omnibus vs Classification at Cue Period")

(plot_list[["L3_Acc"]][["cue"]][[1]] + plot_list[["L3_Acc"]][["cue"]][[2]]) /  
  (plot_list[["L3_Acc"]][["cue"]][[3]] + plot_list[["L3_Acc"]][["cue"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at Cue Period")

(plot_list[["L3_Acc"]][["cue"]][[5]] + plot_list[["L3_Acc"]][["cue"]][[6]]) +
  plot_annotation(title = "L3_Acc vs Classification at Cue Period")

(plot_list[["BPRS"]][["cue"]][[1]] + plot_list[["BPRS"]][["cue"]][[2]]) /  
  (plot_list[["BPRS"]][["cue"]][[3]] + plot_list[["BPRS"]][["cue"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at Cue Period")

(plot_list[["BPRS"]][["cue"]][[5]] + plot_list[["BPRS"]][["cue"]][[6]]) +
  plot_annotation(title = "BPRS vs Classification at Cue Period")



``` 

#### Delay 

There are no significant relationships.  

``` {r plot specific time points from template - delay }

(plot_list[["omnibus"]][["delay"]][[1]] + plot_list[["omnibus"]][["delay"]][[2]]) /  
  (plot_list[["omnibus"]][["delay"]][[3]] + plot_list[["omnibus"]][["delay"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at delay Period")

(plot_list[["omnibus"]][["delay"]][[5]] + plot_list[["omnibus"]][["delay"]][[6]]) +
  plot_annotation(title = "Omnibus vs Classification at delay Period")

(plot_list[["L3_Acc"]][["delay"]][[1]] + plot_list[["L3_Acc"]][["delay"]][[2]]) /  
  (plot_list[["L3_Acc"]][["delay"]][[3]] + plot_list[["L3_Acc"]][["delay"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at delay Period")

(plot_list[["L3_Acc"]][["delay"]][[5]] + plot_list[["L3_Acc"]][["delay"]][[6]]) +
  plot_annotation(title = "L3_Acc vs Classification at delay Period")

(plot_list[["BPRS"]][["delay"]][[1]] + plot_list[["BPRS"]][["delay"]][[2]]) /  
  (plot_list[["BPRS"]][["delay"]][[3]] + plot_list[["BPRS"]][["delay"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at delay Period")

(plot_list[["BPRS"]][["delay"]][[5]] + plot_list[["BPRS"]][["delay"]][[6]]) +
  plot_annotation(title = "BPRS vs Classification at delay Period")

``` 

#### Probe

There is a negative relationship between classification probability at low load correct trials and omnibus span. 

```{r plot specific time points from template - probe }
(plot_list[["omnibus"]][["probe"]][[1]] + plot_list[["omnibus"]][["probe"]][[2]]) /  
  (plot_list[["omnibus"]][["probe"]][[3]] + plot_list[["omnibus"]][["probe"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at probe Period")

(plot_list[["omnibus"]][["probe"]][[5]] + plot_list[["omnibus"]][["probe"]][[6]]) +
  plot_annotation(title = "Omnibus vs Classification at probe Period")

(plot_list[["L3_Acc"]][["probe"]][[1]] + plot_list[["L3_Acc"]][["probe"]][[2]]) /  
  (plot_list[["L3_Acc"]][["probe"]][[3]] + plot_list[["L3_Acc"]][["probe"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at probe Period")

(plot_list[["L3_Acc"]][["probe"]][[5]] + plot_list[["L3_Acc"]][["probe"]][[6]]) +
  plot_annotation(title = "L3_Acc vs Classification at probe Period")

(plot_list[["BPRS"]][["probe"]][[1]] + plot_list[["BPRS"]][["probe"]][[2]]) /  
  (plot_list[["BPRS"]][["probe"]][[3]] + plot_list[["BPRS"]][["probe"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at probe Period")

(plot_list[["BPRS"]][["probe"]][[5]] + plot_list[["BPRS"]][["probe"]][[6]]) +
  plot_annotation(title = "BPRS vs Classification at probe Period")

cor.test(averages_from_template[["low_correct"]]$V11,temp_plot_data$omnibus_span_no_DFR_MRI)

cor.test(averages_from_template[["high_correct"]]$V11[temp_plot_data$BPRS_TOT < 70],temp_plot_data$BPRS_TOT[temp_plot_data$BPRS_TOT < 70])


```

```{r correlate behav to each template TR for each group, warning=FALSE}

behav_classification_corr_list <- list()

for (trial_type in seq.int(1,6)){ 
  group_corrs_omnibus <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_omnibus) <- names(split_template[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_omnibus) <- seq.int(1,14)
  
  group_corrs_acc <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_acc) <- names(split_template[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_acc) <- seq.int(1,14)
  
  group_corrs_BPRS <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_BPRS) <- names(split_template[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_BPRS) <- seq.int(1,14)
  
  for (level in seq.int(1,3)){ 
    temp_subj <- split_template[["all_data"]][[trial_type]][[level]][order(split_template[["all_data"]][[trial_type]][[level]]$PTID),]
    temp_data <- data_to_plot[data_to_plot$PTID %in% split_template[["all_data"]][[trial_type]][[level]]$PTID,]
    
    for (TR in seq.int(1,14)){
      
      group_corrs_omnibus[level,TR] <- cor(temp_subj[,TR],temp_data$omnibus_span_no_DFR_MRI,use="pairwise.complete.obs")
      group_corrs_acc[level,TR] <- cor(temp_subj[,TR],temp_data$XDFR_MRI_ACC_L3,use="pairwise.complete.obs")
      group_corrs_BPRS[level,TR] <- cor(temp_subj[,TR],temp_data$BPRS_TOT.x,use="pairwise.complete.obs")
      
    }
    group_corrs_acc$level <- factor(rownames(group_corrs_acc))
    group_corrs_BPRS$level <- factor(rownames(group_corrs_acc))
    group_corrs_omnibus$level <- factor(rownames(group_corrs_acc))
    
  }
  
  behav_classification_corr_list[["omnibus"]][[names(split_template[["all_data"]])[trial_type]]] <- group_corrs_omnibus
  behav_classification_corr_list[["BPRS"]][[names(split_template[["all_data"]])[trial_type]]] <- group_corrs_BPRS
  behav_classification_corr_list[["L3_Acc"]][[names(split_template[["all_data"]])[trial_type]]] <- group_corrs_acc
}

```

#### By Working Memory Capacity

```{r melt group vs behav template, warning = FALSE}

behav_classification_corr_melt <- list()
behav_split_plot_list <- list()

for (measure in seq.int(1,3)){
  for (trial_type in seq.int(1,6)){ 
    behav_classification_corr_melt[[names(behav_classification_corr_list)[measure]]][[names(behav_classification_corr_list[[measure]])[trial_type]]] <- melt(behav_classification_corr_list[[measure]][[trial_type]],id.vars="level")
    behav_classification_corr_melt[[measure]][[trial_type]]$variable <- as.numeric(as.character(behav_classification_corr_melt[[measure]][[trial_type]]$variable))
    behav_classification_corr_melt[[measure]][[trial_type]]$level <- factor(behav_classification_corr_melt[[measure]][[trial_type]]$level, levels=c("high","med","low"))
    
    behav_split_plot_list[[names(behav_classification_corr_melt)[measure]]][[names(behav_classification_corr_melt[[measure]])[trial_type]]] <- 
      ggplot(data = behav_classification_corr_melt[[measure]][[trial_type]],aes(x=variable,y=value))+
      geom_line(aes(color=level))+
      scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
      ggtitle(names(behav_classification_corr_list[[measure]])[trial_type])+
      xlab("TR")+
      ylab("Correlation")+
      theme_classic()
    
  }
}

```

```{r plot template prob vs behav by group}

(behav_split_plot_list[["omnibus"]][[1]] + behav_split_plot_list[["omnibus"]][[2]]) / 
  (behav_split_plot_list[["omnibus"]][[3]] + behav_split_plot_list[["omnibus"]][[4]])+
  plot_annotation("Omnibus Span Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["omnibus"]][[5]] + behav_split_plot_list[["omnibus"]][[6]]) + 
  plot_annotation("Omnibus Span Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["L3_Acc"]][[1]] + behav_split_plot_list[["L3_Acc"]][[2]]) / 
  (behav_split_plot_list[["L3_Acc"]][[3]] + behav_split_plot_list[["L3_Acc"]][[4]])+
  plot_annotation("High Load Acc Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["L3_Acc"]][[5]] + behav_split_plot_list[["L3_Acc"]][[6]]) + 
  plot_annotation("High Load Acc Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")


(behav_split_plot_list[["BPRS"]][[1]] + behav_split_plot_list[["BPRS"]][[2]]) / 
  (behav_split_plot_list[["BPRS"]][[3]] + behav_split_plot_list[["BPRS"]][[4]])+
  plot_annotation("BPRS Total Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["BPRS"]][[5]] + behav_split_plot_list[["BPRS"]][[6]]) + 
  plot_annotation("BPRS Total with Face Classification Probability by Group")+
  plot_layout(guides="collect")

```