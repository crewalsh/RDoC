---
title: "Prediction Analyses"
author: "Catherine Walsh"
date: "5/1/2020"
output:
  html_document:
    toc: true 
    toc_float: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

When looking at the time course data, we noticed an interesting pattern: it seemed as though it would be possible to predict an individual's group from the difference between their load effect during encoding and their load effect during delay. It seemed as though low capacity subjects had small load effects at both encoding and delay, medium capacity subjects had large load effects at both encoding and delay and high capacity subjects had large load effects at encoding but small ones at delay. As such, we wanted to create a model that used this information to predict span. 

To do so, we extracted data from TR 6 for the encoding period and TR 8 for the delay period. This represented 1 TR's worth of data in the middle of where we'd expect activity from for each period (from our model of the task convolved with a hemodynamic delay function) and where we see maximal differences between group. In addition to the raw load effects, we created two composite variables that we expected to capture the differences between groups. The first was simply the difference between load effects at encoding and delay, and the second was the sum of that difference and the load effect effect at encoding. These measures allow us to create a series of regression models to predict span, BPRS total score and accuracy at high load. 

In addition to the univariate load effects, we have also seen a relationship with various measures reflecting multivariate representation across and within trial, including the probability of a MVPA classifer predicting a face at any given point in a trial and the similarity of multivariate representations across and within trials. Both of these measures were taken at each individual trial and averaged, in addition to taken from the average over many trials (which served as a template for the canonical trial type). We added these multivariate measures to see if they improved model performance when added to regression models that only contained variables based on univariate load effects.  

Overll, we saw some cross-over in which measures predicted each behavioral variable. Principal components related to encoding-delay in the PFC regions and similarity within TR in low load correct trials in DFR/individual to template across TR in high load correct in fusiform were related to both span and accuracy at high load, while univariate effects in right hemisphere parietal regions in during delay and the encoding + (encoding-delay) measure related to BPRS and accuracy. 

In contrast, delay load effect and similarity within TR in low load correct trials in DFR, individual to template across TR in high load correct in fusiform were only related to span; similarity of correct trials (regardless of load) in fusiform, face representation during delay and probe in mostly indiv trials in the fusiform, high incorrect and low correct in fusiform across individual trial were related to BPRS and fusiform similarity during encoding (regardless of accuracy), delay similarity in DFR,  how similar high load incorrect trials are to the template correct trials and low load correct trials in fusiform, face representation in DFR encoding and delay for mostly indiv trials and representation during low correct and high incorrect in fusiform averages from template related uniquely to accuracy. 

```{r load libraries and data}

library(tidyverse)
library(psych)
library(reshape2)
library(rmatio)
library(factoextra)
library(patchwork)
library(MASS)
library(caret)
library(glmnet)

load('data/behav.RData')
load('data/split_groups_info.RData')
load('data/ITC_fusiform.RData')
similarity_fusiform <- similarity_temp
load('data/ITC_DFR_delay.RData')
similarity_DFR <- similarity_temp 
load("data/MVPA_fusiform.RData")
individual_trial_probs_fusiform <- individual_trial_averages_probs
averages_from_template_fusiform <- averages_from_template
load("data/MVPA_DFR_delay_mask.RData")
individual_trial_probs_DFR <- individual_trial_averages_probs
averages_from_template_DFR <- averages_from_template
load("data/MVPA_HPC.RData")
individual_trial_probs_HPC <- individual_trial_averages_probs
averages_from_template_HPC <- averages_from_template

DFR_ROIs <- c("L aMFG","L dlPFC","L dMFG","L IPS","L preSMA","R dlPFC","R IPS","R medParietal","all delay ROIs")

```

# Prep data

First, we're going to load in the time courses of the activity from the DFR regions. We're doing this a little differently from last time, because we don't want the interpolated data, we just want the one with 14 TRs. 

We're going to remove the subjects that aren't included in the split group analysis, and put the data in a slightly easier to use format. 

```{r load in time course data in TRs}

temp <- read.mat('data/RSA_DFR_trials.mat')
factors <- matrix(nrow=170)

for (idx in seq.int(1,170)){
  if (constructs_fMRI$PTID[idx] %in% WM_groups[["high"]]$PTID){
    factors[idx] <- "high"
  }else if (constructs_fMRI$PTID[idx] %in% WM_groups[["med"]]$PTID){
    factors[idx] <- "med"
  }else if (constructs_fMRI$PTID[idx] %in% WM_groups[["low"]]$PTID){
    factors[idx] <- "low"
  }else{
    factors[idx] <- "not_incl"
  }
}

factors <- factor(factors, levels=c("low","med","high","not_incl"))
trial_activity_high <- temp[["trial_avg_activity_high"]]
trial_activity_low <- temp[["trial_avg_activity_low"]]

all_data <- list(subjs=constructs_fMRI$PTID,
                 WMC = factors, 
                 L_aMFG = list(
                   high = data.frame(trial_activity_high[,,1,1]),
                   low = data.frame(trial_activity_low[,,1,1])
                 ),
                 L_dlPFC = list(
                   high = data.frame(trial_activity_high[,,1,2]),
                   low = data.frame(trial_activity_low[,,1,2])
                 ),
                 L_dMFG = list(
                   high = data.frame(trial_activity_high[,,1,3]),
                   low = data.frame(trial_activity_low[,,1,3])
                 ), 
                 L_IPS = list(
                   high = data.frame(trial_activity_high[,,1,4]),
                   low = data.frame(trial_activity_low[,,1,4])
                 ), 
                 L_preSMA = list(
                   high = data.frame(trial_activity_high[,,1,5]),
                   low = data.frame(trial_activity_low[,,1,5])
                 ), 
                 R_dlPFC = list(
                   high = data.frame(trial_activity_high[,,1,6]),
                   low = data.frame(trial_activity_low[,,1,6])
                 ),
                 R_IPS = list(
                   high = data.frame(trial_activity_high[,,1,7]),
                   low = data.frame(trial_activity_low[,,1,7])
                 ),
                 R_medParietal = list(
                   high = data.frame(trial_activity_high[,,1,8]),
                   low = data.frame(trial_activity_low[,,1,8])
                 ),
                 all_delay = list(
                   high = data.frame(trial_activity_high[,,1,9]),
                   low = data.frame(trial_activity_low[,,1,9])
                 )
)

```

Now, we're going to calculate load effects for each ROI at every time point. 

```{r calculate load effects}

for (ROI in seq.int(3,11)){
  all_data[[ROI]][["load_effect"]] <- all_data[[ROI]][["high"]]-all_data[[ROI]][["low"]]
  temp <- data.frame(group = all_data[["WMC"]], all_data[[ROI]][["load_effect"]])
  all_data[[ROI]][["SVM"]] <- temp
}

```

Now, let's pull out thhe encoding and delay values - we're also going to calculate the difference between encoding and delay, and encoding + (encoding-delay), because we think that this is going to be useful. We're going to include all these measures, plus span, in a convenient dataframe. 

```{r calculate encoding and delay values}

for (ROI in seq.int(3,11)){
  temp <- data.frame(matrix(nrow=170, ncol=6))
  colnames(temp) <- c("group","encoding","delay","encoding_delay","encoding_delay_comb" ,"span")
  temp$group <- all_data[["WMC"]]
  temp$span <- constructs_fMRI$omnibus_span_no_DFR_MRI
  
  temp$encoding <- all_data[[ROI]][["load_effect"]][,6]
  #temp$delay <- rowMeans(all_data[[ROI]][["load_effect"]][,8:9])
  
  temp$delay <- all_data[[ROI]][["load_effect"]][,8]
  temp$encoding_delay <- temp$encoding - temp$delay
  temp$encoding_delay_comb <- temp$encoding + temp$encoding_delay 
  temp$high_acc <- p200_data$XDFR_MRI_ACC_L3[p200_data$PTID %in% constructs_fMRI$PTID]
  
  temp$BPRS <- p200_clinical_zscores$BPRS_TOT[p200_clinical_zscores$PTID %in% constructs_fMRI$PTID]
  
  all_data[[ROI]][["SVM_2"]] <- temp
  
}

```

# Relationship between Span and Encoding - Delay 

All regions except for L aMFG have significant relationships 

```{r make plots}

ROI_plot_list <- list()

for (ROI in seq.int(3,11)){
  correlation_test <- cor.test(all_data[[ROI]][["SVM_2"]]$span,all_data[[ROI]][["SVM_2"]]$encoding_delay)
  
  ROI_plot_list[[DFR_ROIs[ROI-2]]] <- ggplot(data=all_data[[ROI]][["SVM_2"]])+
    geom_point(aes(x=span,y=encoding_delay_comb,color=group))+
    stat_smooth(aes(x=span,y=encoding_delay_comb),method="lm",color="black")+
    ggtitle(paste(DFR_ROIs[ROI-2], ", r = ",round(correlation_test$estimate,digits=3)))+
    xlab("WM Span")+
    ylab("LE Difference")+
    theme_classic()
  
}

(ROI_plot_list[[1]] + ROI_plot_list[[2]]) /
  (ROI_plot_list[[3]] + ROI_plot_list[[4]]) +  
  plot_annotation(title = "Correlation between (encoding LE + encoding/delay LE difference) and span ")+
  plot_layout(guides="collect")

(ROI_plot_list[[5]] + ROI_plot_list[[6]]) /
  (ROI_plot_list[[7]] + ROI_plot_list[[8]]) +
  plot_layout(guides="collect")

ROI_plot_list[[9]]   


```

# Explore data 

```{r create data frame with all info for regression}

data_for_reg <- data.frame(span = all_data[["all_delay"]][["SVM_2"]]$span,
                           high_acc = all_data[["all_delay"]][["SVM_2"]]$high_acc, BPRS = all_data[["all_delay"]][["SVM_2"]]$BPRS,
                           L_aMFG_enc = all_data[[3]][["SVM_2"]]$encoding, L_aMFG_delay = all_data[[3]][["SVM_2"]]$delay, 
                           L_dlPFC_enc = all_data[[4]][["SVM_2"]]$encoding, L_dlPFC_delay = all_data[[4]][["SVM_2"]]$delay,
                           L_dMFG_enc = all_data[[5]][["SVM_2"]]$encoding, L_dMFG_delay = all_data[[5]][["SVM_2"]]$delay,
                           L_IPS_enc = all_data[[6]][["SVM_2"]]$encoding, L_IPS_delay = all_data[[6]][["SVM_2"]]$delay,
                           L_preSMA_enc = all_data[[7]][["SVM_2"]]$encoding, L_preSMA_delay = all_data[[7]][["SVM_2"]]$delay,
                           R_dlPFC_enc = all_data[[8]][["SVM_2"]]$encoding, R_dlPFC_delay = all_data[[8]][["SVM_2"]]$delay,
                           R_IPS_enc = all_data[[9]][["SVM_2"]]$encoding, R_IPS_delay = all_data[[9]][["SVM_2"]]$delay,
                           R_medPar_enc = all_data[[10]][["SVM_2"]]$encoding, R_medPar_delay = all_data[[10]][["SVM_2"]]$delay,
                           all_delay_enc = all_data[[11]][["SVM_2"]]$encoding, all_delay_delay = all_data[[11]][["SVM_2"]]$delay,
                           L_aMFG_enc_delay = all_data[[3]][["SVM_2"]]$encoding_delay, 
                           L_dlPFC_enc_delay = all_data[[4]][["SVM_2"]]$encoding_delay, 
                           L_dMFG_enc_delay = all_data[[5]][["SVM_2"]]$encoding_delay,
                           L_IPS_enc_delay = all_data[[6]][["SVM_2"]]$encoding_delay, 
                           L_preSMA_enc_delay = all_data[[7]][["SVM_2"]]$encoding_delay, 
                           R_dlPFC_enc_delay = all_data[[8]][["SVM_2"]]$encoding_delay, 
                           R_IPS_enc_delay = all_data[[9]][["SVM_2"]]$encoding_delay,
                           R_medPar_enc_delay = all_data[[10]][["SVM_2"]]$encoding_delay,
                           L_aMFG_enc_delay_comb = all_data[[3]][["SVM_2"]]$encoding_delay_comb, 
                           L_dlPFC_enc_delay_comb = all_data[[4]][["SVM_2"]]$encoding_delay_comb, 
                           L_dMFG_enc_delay_comb = all_data[[5]][["SVM_2"]]$encoding_delay_comb,
                           L_IPS_enc_delay_comb = all_data[[6]][["SVM_2"]]$encoding_delay_comb, 
                           L_preSMA_enc_delay_comb = all_data[[7]][["SVM_2"]]$encoding_delay_comb, 
                           R_dlPFC_enc_delay_comb = all_data[[8]][["SVM_2"]]$encoding_delay_comb, 
                           R_IPS_enc_delay_comb = all_data[[9]][["SVM_2"]]$encoding_delay_comb,
                           R_medPar_enc_delay_comb = all_data[[10]][["SVM_2"]]$encoding_delay_comb, 
                           R_all_delay_enc_delay_comb = all_data[[11]][["SVM_2"]]$encoding_delay_comb, 
                           high_corr_fus_enc = similarity_fusiform[["high_correct_avg"]]$X6, 
                           high_corr_fus_delay = similarity_fusiform[["high_correct_avg"]]$X8, 
                           high_incorr_fus_enc = similarity_fusiform[["high_incorrect_avg"]]$X6,
                           high_incorr_fus_del = similarity_fusiform[["high_incorrect_avg"]]$X8,
                           low_corr_fus_enc = similarity_fusiform[["low_correct_avg"]]$X6,
                           low_corr_fus_del = similarity_fusiform[["low_correct_avg"]]$X8, 
                           correct_encoding_to_correct_delay_fus = similarity_fusiform[["correct_encoding_to_correct_delay"]],
                           correct_enc_to_delay_fus_high_corr = similarity_fusiform[["correct_encoding_to_delay_avg"]][,4],
                           enc_to_correct_delay_fus_high_corr = similarity_fusiform[["encoding_to_correct_delay_avg"]][,4],
                           high_corr_DFR_enc = similarity_DFR[["high_correct_avg"]]$X6, 
                           high_corr_DFR_delay = similarity_DFR[["high_correct_avg"]]$X8, 
                           high_incorr_DFR_enc = similarity_DFR[["high_incorrect_avg"]]$X6,
                           high_incorr_DFR_del = similarity_DFR[["high_incorrect_avg"]]$X8,
                           low_corr_DFR_enc = similarity_DFR[["low_correct_avg"]]$X6,
                           low_corr_DFR_del = similarity_DFR[["low_correct_avg"]]$X8, 
                           correct_encoding_to_correct_delay_DFR = similarity_DFR[["correct_encoding_to_correct_delay"]],
                           correct_enc_to_delay_DFR_high_corr = similarity_DFR[["correct_encoding_to_delay_avg"]][,4],
                           enc_to_correct_delay_DFR_high_corr = similarity_DFR[["encoding_to_correct_delay_avg"]][,4],
                           indiv_trial_avgs_high_correct_fusiform_enc = individual_trial_probs_fusiform[["high_correct"]]$V6,
                           indiv_trial_avgs_high_correct_fusiform_delay = individual_trial_probs_fusiform[["high_correct"]]$V8,
                           indiv_trial_avgs_high_correct_fusiform_probe = individual_trial_probs_fusiform[["high_correct"]]$V11,
                           indiv_trial_avgs_high_correct_DFR_enc = individual_trial_probs_DFR[["high_correct"]]$V6,
                           indiv_trial_avgs_high_correct_DFR_delay = individual_trial_probs_DFR[["high_correct"]]$V8,
                           indiv_trial_avgs_high_correct_DFR_probe = individual_trial_probs_DFR[["high_correct"]]$V11,
                           indiv_trial_avgs_high_incorrect_fusiform_enc = individual_trial_probs_fusiform[["high_incorrect"]]$V6,
                           indiv_trial_avgs_high_incorrect_fusiform_delay = individual_trial_probs_fusiform[["high_incorrect"]]$V8,
                           indiv_trial_avgs_high_incorrect_fusiform_probe = individual_trial_probs_fusiform[["high_incorrect"]]$V11,
                           indiv_trial_avgs_high_incorrect_DFR_enc = individual_trial_probs_DFR[["high_incorrect"]]$V6,
                           indiv_trial_avgs_high_incorrect_DFR_delay = individual_trial_probs_DFR[["high_incorrect"]]$V8,
                           indiv_trial_avgs_high_incorrect_DFR_probe = individual_trial_probs_DFR[["high_incorrect"]]$V11,
                           indiv_trial_avgs_low_correct_fusiform_enc = individual_trial_probs_fusiform[["low_correct"]]$V6,
                           indiv_trial_avgs_low_correct_fusiform_delay = individual_trial_probs_fusiform[["low_correct"]]$V8,
                           indiv_trial_avgs_low_correct_fusiform_probe = individual_trial_probs_fusiform[["low_correct"]]$V11,
                           indiv_trial_avgs_low_correct_DFR_enc = individual_trial_probs_DFR[["low_correct"]]$V6,
                           indiv_trial_avgs_low_correct_DFR_delay = individual_trial_probs_DFR[["low_correct"]]$V8,
                           indiv_trial_avgs_low_correct_DFR_probe = individual_trial_probs_DFR[["low_correct"]]$V11,
                           averages_from_template_high_correct_fusiform_enc = averages_from_template_fusiform[["high_correct"]]$V6,
                           averages_from_template_high_correct_fusiform_delay = averages_from_template_fusiform[["high_correct"]]$V8,
                           averages_from_template_high_correct_fusiform_probe = averages_from_template_fusiform[["high_correct"]]$V11,
                           averages_from_template_high_correct_DFR_enc = averages_from_template_DFR[["high_correct"]]$V6,
                           averages_from_template_high_correct_DFR_delay = averages_from_template_DFR[["high_correct"]]$V8,
                           averages_from_template_high_correct_DFR_probe = averages_from_template_DFR[["high_correct"]]$V11,
                           averages_from_template_high_incorrect_fusiform_enc = averages_from_template_fusiform[["high_incorrect"]]$V6,
                           averages_from_template_high_incorrect_fusiform_delay = averages_from_template_fusiform[["high_incorrect"]]$V8,
                           averages_from_template_high_incorrect_fusiform_probe = averages_from_template_fusiform[["high_incorrect"]]$V11,
                           averages_from_template_high_incorrect_DFR_enc = averages_from_template_DFR[["high_incorrect"]]$V6,
                           averages_from_template_high_incorrect_DFR_delay = averages_from_template_DFR[["high_incorrect"]]$V8,
                           averages_from_template_high_incorrect_DFR_probe = averages_from_template_DFR[["high_incorrect"]]$V11,
                           averages_from_template_low_correct_fusiform_enc = averages_from_template_fusiform[["low_correct"]]$V6,
                           averages_from_template_low_correct_fusiform_delay = averages_from_template_fusiform[["low_correct"]]$V8,
                           averages_from_template_low_correct_fusiform_probe = averages_from_template_fusiform[["low_correct"]]$V11,
                           averages_from_template_low_correct_DFR_enc = averages_from_template_DFR[["low_correct"]]$V6,
                           averages_from_template_low_correct_DFR_delay = averages_from_template_DFR[["low_correct"]]$V8,
                           averages_from_template_low_correct_DFR_probe = averages_from_template_DFR[["low_correct"]]$V11
)

```

From these plots, we can see that our measeures are high correlated. 

## Within encoding load effects

```{r correlations between univariate measures - encoding}
pairs.panels(data_for_reg[,c(4,6,8,10,12,14,16,18)], density=TRUE)

``` 

## Within delay load effects 

```{r correlations between univariate measures - delay }
pairs.panels(data_for_reg[,c(5,7,9,11,13,15,17,19)], density=TRUE)

``` 

## Encoding - Delay

```{r corelationsfor encoding-delay}
pairs.panels(data_for_reg[,c(22:29)], density= TRUE)

```

## Within TR Similarity

```{r correlation between similarity measures within TR}
pairs.panels(data_for_reg[,c(39:44,49:53)])

``` 

## Across TR Similarity

```{r correlation across TR similarity}
pairs.panels(data_for_reg[,c(45:47,53:56)])
```

## Within Inidivdual MPVA trials - fusiform 

```{r within MVPA fusiform indiv trials}
pairs.panels(data_for_reg[,c(57:59,63:65,69:71)])
```

## Within Inidivdual MPVA trials - delay

```{r within MVPA DFR indiv trials}
pairs.panels(data_for_reg[,c(60:62,66:68,72:74)])
```

## Within MPVA templates - fusiform 

```{r within MVPA fusiform templates}
pairs.panels(data_for_reg[,c(75:77,81:83,87:89)])
```

## Within MPVA templates - delay

```{r within MVPA DFR templates}
pairs.panels(data_for_reg[,c(78:80,84:86,90:92)])
```


# Run PCAs 

## Univariate effects

We know that our variables are highly correlated, so to deal with multi-collinearity, we're going to try to run a PCA on all the encoding load effects, delay load effects and encoding - delay. It looks like the first 3 dimensions carry most of the variance (77%), so we're going to stick with those three. 

The first variable loads on encoding load effects and the combined encoding+encoding-delay in the PFC regions, load effect during delay, the second on delay load effect and the third on encoding - delay in parietal regions. 


```{r univariate analyses PCA}

res.pca <- prcomp(data_for_reg[,c(4:19, 22:37)], scale = TRUE)
fviz_eig(res.pca)

summary(res.pca)

res.var <- get_pca_var(res.pca)
res.var$contrib        # Contributions to the PCs

# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 15)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC3
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)

fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)

```

## Similarity measures

We're going to the same thing for the similarity measures, since we have the same issue (though not quite as badly). 

We cover 78% of the variance by PC5, so we'll focus on those. 

_PC 1: mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform_

* similarity of high load correct trials to a correct template at encoding in DFR 
* similarity of high load correct trials to a correct template at delay in the fusiform
* similarity of high load correct trials in the fusiform at encoding
* similarity of high load incorrect trials to a correct template at encoding in DFR
* similarity of low load correct trials in the fusiform at delay 
* individual trial encoding similarity to correct template delay period at high load correct trials in the fusiform 
* correct template encoding similarity to individual trial delay period at high load correct trials in the fusiform 
* template encoding to template delay in the fusiform ROI 

_PC 2: similarity within TR in low load correct trials in DFR, individual to template across TR in high load correct in fusiform_

* similarity of high load incorrect trials in the DFR at delay 
* similarity of low load correct trials in the DFR at delay 
* similarity of low load correct trials in the DFR at encoding 
* correct template encoding similarity to individual trial delay period at high load correct trials in the fusiform 
* individual trial encoding similarity to correct template delay period at high load correct trials in the fusiform 
* template encoding to template delay in the fusiform ROI 

_PC 3: fusiform similarity during encoding (regardless of accuracy), delay similarity in DFR_ 

* similarity of high load incorrect trials in the fusiform during encoding 
* similarity of high load correct trials in fusiform during encoding 
* similarity of low load correct trials in fusiform during encoding
* similarity of high load incorrect trials during delay in the DFR 
* similarity of low load correct trials during delay in the DFR 

_PC 4: how similar high load incorrect trials are to the template correct trials and low load correct trials in fusiform_

* similarity of high load incorrect trials during delay in the DFR
* similarity of high load incorrect trials in the fusiform during delay 
* similarity of high load incorrect trials during encoding in the DFR
* similarity of low load correct trials in encoding in DFR 
* similarity of low load correct trials during delay in DFR 

_PC 5: mostly related to correct trials (regardless of load) in fusiform_

* similarity of high load incorrect trials in the fusiform during delay 
* similarity of high load correct trials in the fusiform during delay 
* similarity of high load correct trials in the DFR during encoding
* similarity of low load correct trials in the fusiform during delay 
* similarity of low load correct trials in the fusiform during encoding
* template encoding to template delay in the fusiform ROI 

```{r pca for sim}

res_sim.pca <- prcomp(data_for_reg[,c(31:48)], scale = TRUE)
fviz_eig(res_sim.pca)

summary(res_sim.pca)

res_sim.var <- get_pca_var(res_sim.pca)
res_sim.var$contrib      # Contributions to the PCs

# Contributions of variables to PC1
fviz_contrib(res_sim.pca, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
fviz_contrib(res_sim.pca, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC3
fviz_contrib(res_sim.pca, choice = "var", axes = 3, top = 10)
# Contributions of variables to PC4
fviz_contrib(res_sim.pca, choice = "var", axes = 4, top = 10)
# Contributions of variables to PC5
fviz_contrib(res_sim.pca, choice = "var", axes = 5, top = 10)

fviz_pca_var(res_sim.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)


```

## MVPA 

Now, let's do the same for the MVPA measures. 

- PC1: fusiform during encoding/probe for both template and indiv trials 
- PC2: DFR encoding and delay for mostly indiv trials
- PC3: DFR encoding and probe (mostly averages from template)
- PC4: fusiform delay and probe, mostly indiv trials 
- PC5: fusiform, averages from template, all trial types, mostly delay and encoding 
- PC6: template averages for high load trials 
- PC7: high incorrect and low correct in fusiform across trial, mostly in individual trials
- PC8: low correct trials, particularly for DFR 
- PC9: incorrect high load trials across region, mostly in probe and encoding 
- PC10: low correct and high incorrect in fusiform averages from template
- PC11: all trial types, mostly geared towards DFR (regardless of individual or template) during probe and delay
- PC12: loads really strongly on the template average on low correct trials from the delay period in the fusiform, but otherwise, tends to lean towards delay period, from the DFR, low correct trials

```{r pca for MVPA}

res_MVPA.pca <- prcomp(data_for_reg[,c(57:92)], scale = TRUE)
fviz_eig(res_MVPA.pca)

summary(res_MVPA.pca)

res_MVPA.var <- get_pca_var(res_MVPA.pca)
#res_MVPA.var$contrib      # Contributions to the PCs

# Contributions of variables to PC1
fviz_contrib(res_MVPA.pca, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
fviz_contrib(res_MVPA.pca, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC3
fviz_contrib(res_MVPA.pca, choice = "var", axes = 3, top = 10)
# Contributions of variables to PC4
fviz_contrib(res_MVPA.pca, choice = "var", axes = 4, top = 10)
# Contributions of variables to PC5
fviz_contrib(res_MVPA.pca, choice = "var", axes = 5, top = 10)
# Contributions of variables to PC6
fviz_contrib(res_MVPA.pca, choice = "var", axes = 6, top = 10)
# Contributions of variables to PC7
fviz_contrib(res_MVPA.pca, choice = "var", axes = 7, top = 10)
# Contributions of variables to PC8
fviz_contrib(res_MVPA.pca, choice = "var", axes = 8, top = 10)
# Contributions of variables to PC9
fviz_contrib(res_MVPA.pca, choice = "var", axes = 9, top = 10)
# Contributions of variables to PC10
fviz_contrib(res_MVPA.pca, choice = "var", axes = 10, top = 10)
# Contributions of variables to PC11
fviz_contrib(res_MVPA.pca, choice = "var", axes = 11, top = 10)
# Contributions of variables to PC12
fviz_contrib(res_MVPA.pca, choice = "var", axes = 12, top = 10)


fviz_pca_var(res_MVPA.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)



```

# Predicting Span

Now that we've got our PCs, we're going to use them to try to predict span. 

## Only Univariate

It seems like it's actually just including both the encoding and the delay that relates to span, because it's the first PC that relates. 

```{r try regression of univariate on span}

data_reg_span <- data.frame(span = data_for_reg$span, PC1 = res.pca[["x"]][,1], PC2 = res.pca[["x"]][,2],PC3 = res.pca[["x"]][,3] )
span_univ.lm <- lm(span ~ .,data=data_reg_span)
summary(span_univ.lm)
step_univ_span <- stepAIC(span_univ.lm)
summary(step_univ_span)


```

## Add similarity

We can add in similarity measures and they have a significant relation with span. 

```{r add in sim PCA to regression}

data_reg3 <- data.frame(data_reg_span[,1:4],res_sim.pca[["x"]][,1:5])
colnames(data_reg3)[2:4] <-  paste(colnames(data_reg3)[2:4],"_univariate", sep="")
colnames(data_reg3)[5:9] <- paste(colnames(data_reg3)[5:9],"_similarity", sep="")

univariate_similarity_pca.lm <- lm(span ~ ., data = data_reg3)
summary(univariate_similarity_pca.lm)

step_model_univ_sim <- stepAIC(univariate_similarity_pca.lm)
summary(step_model_univ_sim)

```

However, adding in similarity does not necessarily create a better model predicting span. 

```{r statistically compare models -- span}

anova(step_univ_span,step_model_univ_sim)


```

## Add MVPA

Let's see if adding in MVPA makes it better. It does not. 

```{r add MVPA to univ - span}

data_reg4 <- data.frame(data_reg_span[,1:4],res_MVPA.pca[["x"]][,1:12])
colnames(data_reg4)[2:4] <-  paste(colnames(data_reg4)[2:4],"_univariate", sep="")
colnames(data_reg4)[5:12] <- paste(colnames(data_reg4)[5:12],"_MVPA", sep="")

univariate_MVPA_pca.lm <- lm(span ~ ., data = data_reg4)
summary(univariate_MVPA_pca.lm)

step_model_univ_MPVA <- stepAIC(univariate_MVPA_pca.lm)
summary(step_model_univ_MPVA)

```

# Predicting BPRS 

## Only Univariate 

The univariate data does not predict BPRS. 

```{r bprs with just univariate}

data_reg5 <- data.frame(BPRS = data_for_reg$BPRS,PC1_univ = res.pca[["x"]][,1], PC2_univ = res.pca[["x"]][,2], 
                        PC3_univ=res.pca[["x"]][,3])

full_BPRS_univ.lm <- lm(BPRS ~ ., data=data_reg5)
summary(full_BPRS_univ.lm)
step_BPRS_univ <- stepAIC(full_BPRS_univ.lm)
summary(step_BPRS_univ)


```

## Only Similarity

Now, let's try with similarity. These are able to predict BPRS! We're focusing on PC2 (similarity within TR in low load correct trials in DFR, individual to template across TR in high load correct in fusiform), with PCs 1 (mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform) and 5 (mostly related to correct trials (regardless of load) in fusiform) trending towards significance. 

```{r BPRS with similarity}

data_reg6 <- data.frame(BPRS = data_for_reg$BPRS,  PC3_univ=res.pca[["x"]][,3], res_sim.pca[["x"]][,1:5]) 

full_sim_BPRS.lm <- lm(BPRS ~.,data=data_reg6)
summary(full_sim_BPRS.lm)
step_sim_BPRS.lm <- stepAIC(full_sim_BPRS.lm)
summary(step_sim_BPRS.lm)

```

Statistically comparing shows that we do indeed see an improvement in the model when we include the similarity measures. 

```{r statistically compare models- BPRS}

anova(step_BPRS_univ,step_sim_BPRS.lm)

```

## Add MVPA

Now, let's add the MVPA PCs in. 

```{r}

data_reg7 <- data.frame(BPRS = data_for_reg$BPRS,  PC3_univ=res.pca[["x"]][,3], PC1_sim=res_sim.pca[["x"]][,1], PC5_sim=res_sim.pca[["x"]][,5], res_MVPA.pca[["x"]][,1:12])
colnames(data_reg7)[5:16] <- paste(colnames(data_reg7)[5:16],"_MVPA", sep="")

full_sim_MVPA_BPRS.lm <- lm(BPRS ~.,data=data_reg7)
summary(full_sim_MVPA_BPRS.lm)
step_sim_MVPA_BPRS.lm <- stepAIC(full_sim_MVPA_BPRS.lm)
summary(step_sim_MVPA_BPRS.lm)


```

Adding in MVPA, we see that there is a sigificant relationship between BPRS and PC4 (fusiform delay and probe, mostly indiv trials), and a trending one with PC7 (high incorrect and low correct in fusiform across trial, mostly in individual trials). Now, let's see if the model is actually better. We can't run an ANOVA, but including the MVPA variables increases the adjusted R^2 value. 

```{r compare anova models - BPRS with MVPA}

anova(step_sim_BPRS.lm,step_sim_MVPA_BPRS.lm)

```

# Predicting Accuracy 

Finally, lets try to predict accuracy, and see if adding in similarity adds to that analysis. 

## Only univariate

It's the first PC (load effect at encoding/encoding+encoding-delay) and second PC (load effect at delay) that predicts accuracy, though the encoding - delay does trend. 

```{r acc with just univariate}

data_reg8 <- data.frame(high_acc = data_for_reg$high_acc,PC1_univ = res.pca[["x"]][,1], PC2_univ = res.pca[["x"]][,2], PC3_univ = res.pca[["x"]][,3])

full_acc_univ.lm <- lm(high_acc ~ ., data=data_reg8 )
summary(full_acc_univ.lm)
step_acc_univ <- stepAIC(full_acc_univ.lm)
summary(step_acc_univ)

```

## Add similarity

When we add in similarity PCs, we see that similarity PC1 (mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform), 3 (fusiform similarity during encoding (regardless of accuracy), delay similarity in DFR) and 4 (how similar high load incorrect trials are to the template correct trials and low load correct trials in fusiform) have a significant relationships with accuracy. We see that PCs 2 (delay load effect) and 3 (encoding - delay) from the univariate analysis 

```{r add in similarity for acc }

data_reg9 <- data.frame(high_acc = data_for_reg$high_acc,PC1_univ = res.pca[["x"]][,1], PC2_univ = res.pca[["x"]][,2], PC3_univ = res.pca[["x"]][,3], res_sim.pca[["x"]][,1:5])

full_acc_univ_sim.lm <- lm(high_acc ~ ., data=data_reg9)
summary(full_acc_univ_sim.lm)
step_acc_univ_sim <- stepAIC(full_acc_univ_sim.lm)
summary(step_acc_univ_sim)

```

When we formally compare models, we can see that adding in the principal components for similarity do indeed improve the model. 

```{r statistically compare models -accuracy}

anova(step_acc_univ,step_acc_univ_sim)

```

## Add MVPA

Now, let's add the MVPA principal components. 

```{r add MVPA to acc} 

data_reg10 <- data.frame(high_acc = data_for_reg$high_acc,PC1_univ = res.pca[["x"]][,1], PC2_univ = res.pca[["x"]][,2], PC3_univ = res.pca[["x"]][,3],PC2_sim=res_sim.pca[["x"]][,2], PC3_sim=res_sim.pca[["x"]][,3], PC4_sim=res_sim.pca[["x"]][,4], res_MVPA.pca[["x"]][,1:12])
colnames(data_reg10)[8:19] <- paste(colnames(data_reg10)[8:19],"_MVPA", sep="")

full_acc_univ_sim_MVPA.lm <- lm(high_acc ~ ., data=data_reg10)
summary(full_acc_univ_sim_MVPA.lm)
step_acc_univ_sim_MVPA <- stepAIC(full_acc_univ_sim_MVPA.lm)
summary(step_acc_univ_sim_MVPA)

```

We see that MVPA PCs 2 (DFR encoding and delay for mostly indiv trials) and 10 (low correct and high incorrect in fusiform averages from template) have significant relationships, with PC4 (fusiform delay and probe, mostly indiv trials) and 11 (all trial types, mostly geared towards DFR (regardless of individual or template) during probe and delay) have trending relationships. The algorithm still included PC8, which doesn't have a significant relationship, so let's remove this and then compare models. 

We saw that PC 4 also had a relationship with BPRS. 

Adding in the MVPA data does provide a significant increase in explained variance! 

```{r compare models for acc with and without MVPA}

acc_univ_sim_MVPA.lm <- lm(high_acc ~ PC1_univ + PC3_univ+PC2_sim+PC3_sim+PC4_sim+PC2_MVPA+PC4_MVPA+PC10_MVPA+PC11_MVPA, data = data_reg10)

anova(acc_univ_sim_MVPA.lm,step_acc_univ_sim)

```

# Regularized Regression 

## Span

```{r prep data - predict span}
reg_data <- data.frame(span = data_for_reg$span, 
                       high_acc = data_for_reg$high_acc,
                       BPRS = data_for_reg$BPRS,
                       res.pca[["x"]][,1:3],
                       res_sim.pca[["x"]][,1:5], 
                       res_MVPA.pca[["x"]][,1:12])

colnames(reg_data)[4:6] <- paste("PC",c(1:3),"_univ",sep="")
colnames(reg_data)[7:11] <- paste("PC",c(1:5),"_sim",sep="")
colnames(reg_data)[12:23] <- paste("PC",c(1:12),"_MVPA",sep="")

set.seed(123)
```


```{r prep data - predict span}
training.samples_span <- reg_data$span %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data_span  <- reg_data[training.samples_span, c(1, 4:23)]
test.data_span <- reg_data[-training.samples_span, c(1, 4:23)]


# Predictor variables
x.span <- model.matrix(span~., train.data_span)[,-1]
# Outcome variable
y.span <- train.data_span$span

lambda <- 10^seq(-3, 3, length = 100)


```

```{r stepwise - span}

step.span <- train(span ~., data = train.data_span,
                    method = "lmStepAIC", 
                    trControl = trainControl("cv", number = 10),
                    trace = FALSE
                    )
# Model accuracy
step.span$results
# Final model coefficients
step.span$finalModel
# Summary of the model
summary(step.span$finalModel)

```


```{r ridge - span}

ridge.span <- train(
  span ~., data = train.data_span, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 0, lambda = lambda)
  )
# Model coefficients
coef(ridge.span$finalModel, ridge.span$bestTune$lambda)
# Make predictions
predictions.ridge.span <- ridge.span %>% predict(test.data_span)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.ridge.span, test.data_span$span),
  Rsquare = R2(predictions.ridge.span, test.data_span$span)
)

```

```{r lasso - span}

lasso.span <- train(
  span ~., data = train.data_span, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 1, lambda = lambda)
  )
# Model coefficients
coef(lasso.span$finalModel, lasso.span$bestTune$lambda)
# Make predictions
predictions.lasso.span <- lasso.span %>% predict(test.data_span)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.lasso.span, test.data_span$span),
  Rsquare = R2(predictions.lasso.span, test.data_span$span)
)

```

```{r elastic net - span}

elastic.span <- train(
  span ~., data = train.data_span, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )
# Model coefficients
coef(elastic.span$finalModel, elastic.span$bestTune$lambda)
# Make predictions
predictions.elastic.span <- elastic.span %>% predict(test.data_span)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.elastic.span, test.data_span$span),
  Rsquare = R2(predictions.elastic.span, test.data_span$span)
)
```
```{r compare models - span}

models.span <- list(ridge = ridge.span, lasso = lasso.span, elastic = elastic.span, stepwise = step.span)
resamples(models.span) %>% summary( metric = "RMSE")

resamples(models.span) %>% summary( metric = "Rsquared")

```

## BPRS

```{r prep data - predict BPRS}

set.seed(123)

training.samples_BPRS <- reg_data$BPRS %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data_BPRS  <- reg_data[training.samples_BPRS, c(3, 4:23)]
test.data_BPRS <- reg_data[-training.samples_BPRS, c(3, 4:23)]


# Predictor variables
x.BPRS <- model.matrix(BPRS~., train.data_BPRS)[,-1]
# Outcome variable
y.BPRS <- train.data_BPRS$BPRS

lambda <- 10^seq(-3, 3, length = 100)


```

```{r stepwise - BPRS}

step.BPRS <- train(BPRS ~., data = train.data_BPRS,
                    method = "lmStepAIC", 
                    trControl = trainControl("cv", number = 10),
                    trace = FALSE
                    )
# Model accuracy
step.BPRS$results
# Final model coefficients
step.BPRS$finalModel
# Summary of the model
summary(step.BPRS$finalModel)

```

```{r ridge - BPRS}

ridge.BPRS <- train(
  BPRS ~., data = train.data_BPRS, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 0, lambda = lambda)
)
# Model coefficients
coef(ridge.BPRS$finalModel, ridge.BPRS$bestTune$lambda)
# Make predictions
predictions.ridge.BPRS <- ridge.BPRS %>% predict(test.data_BPRS)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.ridge.BPRS, test.data_BPRS$BPRS),
  Rsquare = R2(predictions.ridge.BPRS, test.data_BPRS$BPRS)
)
```

```{r lasso - BPRS}

lasso.BPRS <- train(
  BPRS ~., data = train.data_BPRS, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 1, lambda = lambda)
)
# Model coefficients
coef(lasso.BPRS$finalModel, lasso.BPRS$bestTune$lambda)
# Make predictions
predictions.lasso.BPRS <- lasso.BPRS %>% predict(test.data_BPRS)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.lasso.BPRS, test.data_BPRS$BPRS),
  Rsquare = R2(predictions.lasso.BPRS, test.data_BPRS$BPRS)
)

```

```{r elastic net - BPRS}

elastic.BPRS <- train(
  BPRS ~., data = train.data_BPRS, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
)
# Model coefficients
coef(elastic.BPRS$finalModel, elastic.BPRS$bestTune$lambda)
# Make predictions
predictions.elastic.BPRS <- elastic.BPRS %>% predict(test.data_BPRS)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.elastic.BPRS, test.data_BPRS$BPRS),
  Rsquare = R2(predictions.elastic.BPRS, test.data_BPRS$BPRS)
)
```
```{r compare models - BPRS}

models.BPRS <- list(ridge = ridge.BPRS, lasso = lasso.BPRS, elastic = elastic.BPRS, stepwise = step.BPRS)
resamples(models.BPRS) %>% summary( metric = "RMSE")

resamples(models.BPRS) %>% summary( metric = "Rsquared")


```

## L3 Accuracy

```{r prep data - predict high_acc}

set.seed(123)

training.samples_high_acc <- reg_data$high_acc %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data_high_acc  <- reg_data[training.samples_high_acc, c(2, 4:23)]
test.data_high_acc <- reg_data[-training.samples_high_acc, c(2, 4:23)]


# Predictor variables
x.high_acc <- model.matrix(high_acc~., train.data_high_acc)[,-1]
# Outcome variable
y.high_acc <- train.data_high_acc$high_acc

lambda <- 10^seq(-3, 3, length = 100)


```

```{r stepwise - high acc}

step.high_acc <- train(high_acc ~., data = train.data_high_acc,
                    method = "lmStepAIC", 
                    trControl = trainControl("cv", number = 10),
                    trace = FALSE
                    )
# Model accuracy
step.high_acc$results
# Final model coefficients
step.high_acc$finalModel
# Summary of the model
summary(step.high_acc$finalModel)

```

```{r ridge - high_acc}

ridge.high_acc <- train(
  high_acc ~., data = train.data_high_acc, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 0, lambda = lambda)
)
# Model coefficients
coef(ridge.high_acc$finalModel, ridge.high_acc$bestTune$lambda)
# Make predictions
predictions.ridge.high_acc <- ridge.high_acc %>% predict(test.data_high_acc)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.ridge.high_acc, test.data_high_acc$high_acc),
  Rsquare = R2(predictions.ridge.high_acc, test.data_high_acc$high_acc)
)
```

```{r lasso - high_acc}

lasso.high_acc <- train(
  high_acc ~., data = train.data_high_acc, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 1, lambda = lambda)
)
# Model coefficients
coef(lasso.high_acc$finalModel, lasso.high_acc$bestTune$lambda)
# Make predictions
predictions.lasso.high_acc <- lasso.high_acc %>% predict(test.data_high_acc)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.lasso.high_acc, test.data_high_acc$high_acc),
  Rsquare = R2(predictions.lasso.high_acc, test.data_high_acc$high_acc)
)

```

```{r elastic net - high_acc}

elastic.high_acc <- train(
  high_acc ~., data = train.data_high_acc, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
)
# Model coefficients
coef(elastic.high_acc$finalModel, elastic.high_acc$bestTune$lambda)
# Make predictions
predictions.elastic.high_acc <- elastic.high_acc %>% predict(test.data_high_acc)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.elastic.high_acc, test.data_high_acc$high_acc),
  Rsquare = R2(predictions.elastic.high_acc, test.data_high_acc$high_acc)
)
```
```{r compare models - high_acc}

models.high_acc <- list(ridge = ridge.high_acc, lasso = lasso.high_acc, elastic = elastic.high_acc, stepwise = step.high_acc)
resamples(models.high_acc) %>% summary( metric = "RMSE")

resamples(models.high_acc) %>% summary( metric = "Rsquared")

```

