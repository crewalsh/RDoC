---
title: "Prediction Analyses"
author: "Catherine Walsh"
date: "5/1/2020"
output:
  html_document:
    toc: true 
    toc_float: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

When looking at the time course data, we noticed an interesting pattern: it seemed as though it would be possible to predict an individual's group from the difference between their load effect during encoding and their load effect during delay. It seemed as though low capacity subjects had small load effects at both encoding and delay, medium capacity subjects had large load effects at both encoding and delay and high capacity subjects had large load effects at encoding but small ones at delay. As such, we wanted to create a model that used this information to predict span. 

To do so, we extracted data from TR 6 for the encoding period and TR 8 for the delay period. This represented 1 TR's worth of data in the middle of where we'd expect activity from for each period (from our model of the task convolved with a hemodynamic delay function) and where we see maximal differences between group. In addition to the raw load effects, we created two composite variables that we expected to capture the differences between groups. The first was simply the difference between load effects at encoding and delay, and the second was the sum of that difference and the load effect effect at encoding. These measures allow us to create a series of regression models to predict span, BPRS total score and accuracy at high load. 

In addition to the univariate load effects, we have also seen a relationship with various measures reflecting multivariate representation across and within trial, including the probability of a MVPA classifer predicting a face at any given point in a trial and the similarity of multivariate representations across and within trials. Both of these measures were taken at each individual trial and averaged, in addition to taken from the average over many trials (which served as a template for the canonical trial type). We added these multivariate measures to see if they improved model performance when added to regression models that only contained variables based on univariate load effects.  

Overall, we were best able to explain variance in high load accuracy, with our best model able to explain 40% of the variance. In contrast, we were only able to explain 12% of the variance in span, and 7% of the variance in BPRS scores. 

The individual components related to each of these measures will be discussed further below, but one interesting thing to note is that there is largely not much overlap. The first PC of the similarity measures (which mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform), was important for predicting both span and accuracy, while the encoding - delay difference in parietal regions was important in both accuracy and BPRS scores. There was no overlap between components implicated in span and BPRS. 

```{r load libraries and data}

library(tidyverse)
library(psych)
library(reshape2)
library(rmatio)
library(factoextra)
library(patchwork)
library(MASS)
library(caret)
library(glmnet)

load('data/behav.RData')
load('data/split_groups_info.RData')
load('data/ITC_fusiform.RData')
similarity_fusiform <- similarity_temp
load('data/ITC_DFR_delay.RData')
similarity_DFR <- similarity_temp 
load("data/MVPA_fusiform.RData")
individual_trial_probs_fusiform <- individual_trial_averages_probs
averages_from_template_fusiform <- averages_from_template
load("data/MVPA_DFR_delay_mask.RData")
individual_trial_probs_DFR <- individual_trial_averages_probs
averages_from_template_DFR <- averages_from_template
load("data/MVPA_HPC.RData")
individual_trial_probs_HPC <- individual_trial_averages_probs
averages_from_template_HPC <- averages_from_template

DFR_ROIs <- c("L aMFG","L dlPFC","L dMFG","L IPS","L preSMA","R dlPFC","R IPS","R medParietal","all delay ROIs")

```

# Prep data

First, we're going to load in the time courses of the activity from the DFR regions. We're doing this a little differently from last time, because we don't want the interpolated data, we just want the one with 14 TRs. 

We're going to remove the subjects that aren't included in the split group analysis, and put the data in a slightly easier to use format. 

```{r load in time course data in TRs}

temp <- read.mat('data/RSA_DFR_trials.mat')
factors <- matrix(nrow=170)

for (idx in seq.int(1,170)){
  if (constructs_fMRI$PTID[idx] %in% WM_groups[["high"]]$PTID){
    factors[idx] <- "high"
  }else if (constructs_fMRI$PTID[idx] %in% WM_groups[["med"]]$PTID){
    factors[idx] <- "med"
  }else if (constructs_fMRI$PTID[idx] %in% WM_groups[["low"]]$PTID){
    factors[idx] <- "low"
  }else{
    factors[idx] <- "not_incl"
  }
}

factors <- factor(factors, levels=c("low","med","high","not_incl"))
trial_activity_high <- temp[["trial_avg_activity_high"]]
trial_activity_low <- temp[["trial_avg_activity_low"]]

all_data <- list(subjs=constructs_fMRI$PTID,
                 WMC = factors, 
                 L_aMFG = list(
                   high = data.frame(trial_activity_high[,,1,1]),
                   low = data.frame(trial_activity_low[,,1,1])
                 ),
                 L_dlPFC = list(
                   high = data.frame(trial_activity_high[,,1,2]),
                   low = data.frame(trial_activity_low[,,1,2])
                 ),
                 L_dMFG = list(
                   high = data.frame(trial_activity_high[,,1,3]),
                   low = data.frame(trial_activity_low[,,1,3])
                 ), 
                 L_IPS = list(
                   high = data.frame(trial_activity_high[,,1,4]),
                   low = data.frame(trial_activity_low[,,1,4])
                 ), 
                 L_preSMA = list(
                   high = data.frame(trial_activity_high[,,1,5]),
                   low = data.frame(trial_activity_low[,,1,5])
                 ), 
                 R_dlPFC = list(
                   high = data.frame(trial_activity_high[,,1,6]),
                   low = data.frame(trial_activity_low[,,1,6])
                 ),
                 R_IPS = list(
                   high = data.frame(trial_activity_high[,,1,7]),
                   low = data.frame(trial_activity_low[,,1,7])
                 ),
                 R_medParietal = list(
                   high = data.frame(trial_activity_high[,,1,8]),
                   low = data.frame(trial_activity_low[,,1,8])
                 ),
                 all_delay = list(
                   high = data.frame(trial_activity_high[,,1,9]),
                   low = data.frame(trial_activity_low[,,1,9])
                 )
)

```

Now, we're going to calculate load effects for each ROI at every time point. 

```{r calculate load effects}

for (ROI in seq.int(3,11)){
  all_data[[ROI]][["load_effect"]] <- all_data[[ROI]][["high"]]-all_data[[ROI]][["low"]]
  temp <- data.frame(group = all_data[["WMC"]], all_data[[ROI]][["load_effect"]])
  all_data[[ROI]][["SVM"]] <- temp
}

```

Now, let's pull out thhe encoding and delay values - we're also going to calculate the difference between encoding and delay, and encoding + (encoding-delay), because we think that this is going to be useful. We're going to include all these measures, plus span, in a convenient dataframe. 

```{r calculate encoding and delay values}

for (ROI in seq.int(3,11)){
  temp <- data.frame(matrix(nrow=170, ncol=6))
  colnames(temp) <- c("group","encoding","delay","encoding_delay","encoding_delay_comb" ,"span")
  temp$group <- all_data[["WMC"]]
  temp$span <- constructs_fMRI$omnibus_span_no_DFR_MRI
  
  temp$encoding <- all_data[[ROI]][["load_effect"]][,6]
  #temp$delay <- rowMeans(all_data[[ROI]][["load_effect"]][,8:9])
  
  temp$delay <- all_data[[ROI]][["load_effect"]][,8]
  temp$encoding_delay <- temp$encoding - temp$delay
  temp$encoding_delay_comb <- temp$encoding + temp$encoding_delay 
  temp$high_acc <- p200_data$XDFR_MRI_ACC_L3[p200_data$PTID %in% constructs_fMRI$PTID]
  
  temp$BPRS <- p200_clinical_zscores$BPRS_TOT[p200_clinical_zscores$PTID %in% constructs_fMRI$PTID]
  
  all_data[[ROI]][["SVM_2"]] <- temp
  
}

```

# Relationship between Span and Encoding - Delay 

All regions except for L aMFG have significant relationships 

```{r make plots}

ROI_plot_list <- list()

for (ROI in seq.int(3,11)){
  correlation_test <- cor.test(all_data[[ROI]][["SVM_2"]]$span,all_data[[ROI]][["SVM_2"]]$encoding_delay)
  
  ROI_plot_list[[DFR_ROIs[ROI-2]]] <- ggplot(data=all_data[[ROI]][["SVM_2"]])+
    geom_point(aes(x=span,y=encoding_delay_comb,color=group))+
    stat_smooth(aes(x=span,y=encoding_delay_comb),method="lm",color="black")+
    ggtitle(paste(DFR_ROIs[ROI-2], ", r = ",round(correlation_test$estimate,digits=3)))+
    xlab("WM Span")+
    ylab("LE Difference")+
    theme_classic()
  
}

(ROI_plot_list[[1]] + ROI_plot_list[[2]]) /
  (ROI_plot_list[[3]] + ROI_plot_list[[4]]) +  
  plot_annotation(title = "Correlation between (encoding LE + encoding/delay LE difference) and span ")+
  plot_layout(guides="collect")

(ROI_plot_list[[5]] + ROI_plot_list[[6]]) /
  (ROI_plot_list[[7]] + ROI_plot_list[[8]]) +
  plot_layout(guides="collect")

ROI_plot_list[[9]]   


```

# Explore data 

```{r create data frame with all info for regression}

data_for_reg <- data.frame(span = all_data[["all_delay"]][["SVM_2"]]$span,
                           high_acc = all_data[["all_delay"]][["SVM_2"]]$high_acc, BPRS = all_data[["all_delay"]][["SVM_2"]]$BPRS,
                           L_aMFG_enc = all_data[[3]][["SVM_2"]]$encoding, L_aMFG_delay = all_data[[3]][["SVM_2"]]$delay, 
                           L_dlPFC_enc = all_data[[4]][["SVM_2"]]$encoding, L_dlPFC_delay = all_data[[4]][["SVM_2"]]$delay,
                           L_dMFG_enc = all_data[[5]][["SVM_2"]]$encoding, L_dMFG_delay = all_data[[5]][["SVM_2"]]$delay,
                           L_IPS_enc = all_data[[6]][["SVM_2"]]$encoding, L_IPS_delay = all_data[[6]][["SVM_2"]]$delay,
                           L_preSMA_enc = all_data[[7]][["SVM_2"]]$encoding, L_preSMA_delay = all_data[[7]][["SVM_2"]]$delay,
                           R_dlPFC_enc = all_data[[8]][["SVM_2"]]$encoding, R_dlPFC_delay = all_data[[8]][["SVM_2"]]$delay,
                           R_IPS_enc = all_data[[9]][["SVM_2"]]$encoding, R_IPS_delay = all_data[[9]][["SVM_2"]]$delay,
                           R_medPar_enc = all_data[[10]][["SVM_2"]]$encoding, R_medPar_delay = all_data[[10]][["SVM_2"]]$delay,
                           all_delay_enc = all_data[[11]][["SVM_2"]]$encoding, all_delay_delay = all_data[[11]][["SVM_2"]]$delay,
                           L_aMFG_enc_delay = all_data[[3]][["SVM_2"]]$encoding_delay, 
                           L_dlPFC_enc_delay = all_data[[4]][["SVM_2"]]$encoding_delay, 
                           L_dMFG_enc_delay = all_data[[5]][["SVM_2"]]$encoding_delay,
                           L_IPS_enc_delay = all_data[[6]][["SVM_2"]]$encoding_delay, 
                           L_preSMA_enc_delay = all_data[[7]][["SVM_2"]]$encoding_delay, 
                           R_dlPFC_enc_delay = all_data[[8]][["SVM_2"]]$encoding_delay, 
                           R_IPS_enc_delay = all_data[[9]][["SVM_2"]]$encoding_delay,
                           R_medPar_enc_delay = all_data[[10]][["SVM_2"]]$encoding_delay,
                           L_aMFG_enc_delay_comb = all_data[[3]][["SVM_2"]]$encoding_delay_comb, 
                           L_dlPFC_enc_delay_comb = all_data[[4]][["SVM_2"]]$encoding_delay_comb, 
                           L_dMFG_enc_delay_comb = all_data[[5]][["SVM_2"]]$encoding_delay_comb,
                           L_IPS_enc_delay_comb = all_data[[6]][["SVM_2"]]$encoding_delay_comb, 
                           L_preSMA_enc_delay_comb = all_data[[7]][["SVM_2"]]$encoding_delay_comb, 
                           R_dlPFC_enc_delay_comb = all_data[[8]][["SVM_2"]]$encoding_delay_comb, 
                           R_IPS_enc_delay_comb = all_data[[9]][["SVM_2"]]$encoding_delay_comb,
                           R_medPar_enc_delay_comb = all_data[[10]][["SVM_2"]]$encoding_delay_comb, 
                           R_all_delay_enc_delay_comb = all_data[[11]][["SVM_2"]]$encoding_delay_comb, 
                           high_corr_fus_enc = similarity_fusiform[["high_correct_avg"]]$X6, 
                           high_corr_fus_delay = similarity_fusiform[["high_correct_avg"]]$X8, 
                           high_incorr_fus_enc = similarity_fusiform[["high_incorrect_avg"]]$X6,
                           high_incorr_fus_del = similarity_fusiform[["high_incorrect_avg"]]$X8,
                           low_corr_fus_enc = similarity_fusiform[["low_correct_avg"]]$X6,
                           low_corr_fus_del = similarity_fusiform[["low_correct_avg"]]$X8, 
                           correct_encoding_to_correct_delay_fus = similarity_fusiform[["correct_encoding_to_correct_delay"]],
                           correct_enc_to_delay_fus_high_corr = similarity_fusiform[["correct_encoding_to_delay_avg"]][,4],
                           enc_to_correct_delay_fus_high_corr = similarity_fusiform[["encoding_to_correct_delay_avg"]][,4],
                           high_corr_DFR_enc = similarity_DFR[["high_correct_avg"]]$X6, 
                           high_corr_DFR_delay = similarity_DFR[["high_correct_avg"]]$X8, 
                           high_incorr_DFR_enc = similarity_DFR[["high_incorrect_avg"]]$X6,
                           high_incorr_DFR_del = similarity_DFR[["high_incorrect_avg"]]$X8,
                           low_corr_DFR_enc = similarity_DFR[["low_correct_avg"]]$X6,
                           low_corr_DFR_del = similarity_DFR[["low_correct_avg"]]$X8, 
                           correct_encoding_to_correct_delay_DFR = similarity_DFR[["correct_encoding_to_correct_delay"]],
                           correct_enc_to_delay_DFR_high_corr = similarity_DFR[["correct_encoding_to_delay_avg"]][,4],
                           enc_to_correct_delay_DFR_high_corr = similarity_DFR[["encoding_to_correct_delay_avg"]][,4],
                           indiv_trial_avgs_high_correct_fusiform_enc = individual_trial_probs_fusiform[["high_correct"]]$V6,
                           indiv_trial_avgs_high_correct_fusiform_delay = individual_trial_probs_fusiform[["high_correct"]]$V8,
                           indiv_trial_avgs_high_correct_fusiform_probe = individual_trial_probs_fusiform[["high_correct"]]$V11,
                           indiv_trial_avgs_high_correct_DFR_enc = individual_trial_probs_DFR[["high_correct"]]$V6,
                           indiv_trial_avgs_high_correct_DFR_delay = individual_trial_probs_DFR[["high_correct"]]$V8,
                           indiv_trial_avgs_high_correct_DFR_probe = individual_trial_probs_DFR[["high_correct"]]$V11,
                           indiv_trial_avgs_high_incorrect_fusiform_enc = individual_trial_probs_fusiform[["high_incorrect"]]$V6,
                           indiv_trial_avgs_high_incorrect_fusiform_delay = individual_trial_probs_fusiform[["high_incorrect"]]$V8,
                           indiv_trial_avgs_high_incorrect_fusiform_probe = individual_trial_probs_fusiform[["high_incorrect"]]$V11,
                           indiv_trial_avgs_high_incorrect_DFR_enc = individual_trial_probs_DFR[["high_incorrect"]]$V6,
                           indiv_trial_avgs_high_incorrect_DFR_delay = individual_trial_probs_DFR[["high_incorrect"]]$V8,
                           indiv_trial_avgs_high_incorrect_DFR_probe = individual_trial_probs_DFR[["high_incorrect"]]$V11,
                           indiv_trial_avgs_low_correct_fusiform_enc = individual_trial_probs_fusiform[["low_correct"]]$V6,
                           indiv_trial_avgs_low_correct_fusiform_delay = individual_trial_probs_fusiform[["low_correct"]]$V8,
                           indiv_trial_avgs_low_correct_fusiform_probe = individual_trial_probs_fusiform[["low_correct"]]$V11,
                           indiv_trial_avgs_low_correct_DFR_enc = individual_trial_probs_DFR[["low_correct"]]$V6,
                           indiv_trial_avgs_low_correct_DFR_delay = individual_trial_probs_DFR[["low_correct"]]$V8,
                           indiv_trial_avgs_low_correct_DFR_probe = individual_trial_probs_DFR[["low_correct"]]$V11,
                           averages_from_template_high_correct_fusiform_enc = averages_from_template_fusiform[["high_correct"]]$V6,
                           averages_from_template_high_correct_fusiform_delay = averages_from_template_fusiform[["high_correct"]]$V8,
                           averages_from_template_high_correct_fusiform_probe = averages_from_template_fusiform[["high_correct"]]$V11,
                           averages_from_template_high_correct_DFR_enc = averages_from_template_DFR[["high_correct"]]$V6,
                           averages_from_template_high_correct_DFR_delay = averages_from_template_DFR[["high_correct"]]$V8,
                           averages_from_template_high_correct_DFR_probe = averages_from_template_DFR[["high_correct"]]$V11,
                           averages_from_template_high_incorrect_fusiform_enc = averages_from_template_fusiform[["high_incorrect"]]$V6,
                           averages_from_template_high_incorrect_fusiform_delay = averages_from_template_fusiform[["high_incorrect"]]$V8,
                           averages_from_template_high_incorrect_fusiform_probe = averages_from_template_fusiform[["high_incorrect"]]$V11,
                           averages_from_template_high_incorrect_DFR_enc = averages_from_template_DFR[["high_incorrect"]]$V6,
                           averages_from_template_high_incorrect_DFR_delay = averages_from_template_DFR[["high_incorrect"]]$V8,
                           averages_from_template_high_incorrect_DFR_probe = averages_from_template_DFR[["high_incorrect"]]$V11,
                           averages_from_template_low_correct_fusiform_enc = averages_from_template_fusiform[["low_correct"]]$V6,
                           averages_from_template_low_correct_fusiform_delay = averages_from_template_fusiform[["low_correct"]]$V8,
                           averages_from_template_low_correct_fusiform_probe = averages_from_template_fusiform[["low_correct"]]$V11,
                           averages_from_template_low_correct_DFR_enc = averages_from_template_DFR[["low_correct"]]$V6,
                           averages_from_template_low_correct_DFR_delay = averages_from_template_DFR[["low_correct"]]$V8,
                           averages_from_template_low_correct_DFR_probe = averages_from_template_DFR[["low_correct"]]$V11
)

```

From these plots, we can see that our measeures are high correlated. 

## Within encoding load effects

```{r correlations between univariate measures - encoding}
pairs.panels(data_for_reg[,c(4,6,8,10,12,14,16,18)], density=TRUE)

``` 

## Within delay load effects 

```{r correlations between univariate measures - delay }
pairs.panels(data_for_reg[,c(5,7,9,11,13,15,17,19)], density=TRUE)

``` 

## Encoding - Delay

```{r corelationsfor encoding-delay}
pairs.panels(data_for_reg[,c(22:29)], density= TRUE)

```

## Within TR Similarity

```{r correlation between similarity measures within TR}
pairs.panels(data_for_reg[,c(39:44,49:53)])

``` 

## Across TR Similarity

```{r correlation across TR similarity}
pairs.panels(data_for_reg[,c(45:47,53:56)])
```

## Within Inidivdual MPVA trials - fusiform 

```{r within MVPA fusiform indiv trials}
pairs.panels(data_for_reg[,c(57:59,63:65,69:71)])
```

## Within Inidivdual MPVA trials - delay

```{r within MVPA DFR indiv trials}
pairs.panels(data_for_reg[,c(60:62,66:68,72:74)])
```

## Within MPVA templates - fusiform 

```{r within MVPA fusiform templates}
pairs.panels(data_for_reg[,c(75:77,81:83,87:89)])
```

## Within MPVA templates - delay

```{r within MVPA DFR templates}
pairs.panels(data_for_reg[,c(78:80,84:86,90:92)])
```


# Run PCAs 

## Univariate effects

We know that our variables are highly correlated, so to deal with multi-collinearity, we're going to try to run a PCA on all the encoding load effects, delay load effects and encoding - delay. It looks like the first 3 dimensions carry most of the variance (77%), so we're going to stick with those three. 

The first variable loads on encoding load effects and the combined encoding+encoding-delay in the PFC regions, load effect during delay, the second on delay load effect and the third on encoding - delay in parietal regions. 


```{r univariate analyses PCA}

res.pca <- prcomp(data_for_reg[,c(4:19, 22:37)], scale = TRUE)
fviz_eig(res.pca)

summary(res.pca)

res.var <- get_pca_var(res.pca)
res.var$contrib        # Contributions to the PCs

# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 15)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC3
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)

fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)

```

## Similarity measures

We're going to the same thing for the similarity measures, since we have the same issue (though not quite as badly). 

We cover 78% of the variance by PC5, so we'll focus on those. 

_PC 1: mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform_

* similarity of high load correct trials to a correct template at encoding in DFR 
* similarity of high load correct trials to a correct template at delay in the fusiform
* similarity of high load correct trials in the fusiform at encoding
* similarity of high load incorrect trials to a correct template at encoding in DFR
* similarity of low load correct trials in the fusiform at delay 
* individual trial encoding similarity to correct template delay period at high load correct trials in the fusiform 
* correct template encoding similarity to individual trial delay period at high load correct trials in the fusiform 
* template encoding to template delay in the fusiform ROI 

_PC 2: similarity within TR in low load correct trials in DFR, individual to template across TR in high load correct in fusiform_

* similarity of high load incorrect trials in the DFR at delay 
* similarity of low load correct trials in the DFR at delay 
* similarity of low load correct trials in the DFR at encoding 
* correct template encoding similarity to individual trial delay period at high load correct trials in the fusiform 
* individual trial encoding similarity to correct template delay period at high load correct trials in the fusiform 
* template encoding to template delay in the fusiform ROI 

_PC 3: fusiform similarity during encoding (regardless of accuracy), delay similarity in DFR_ 

* similarity of high load incorrect trials in the fusiform during encoding 
* similarity of high load correct trials in fusiform during encoding 
* similarity of low load correct trials in fusiform during encoding
* similarity of high load incorrect trials during delay in the DFR 
* similarity of low load correct trials during delay in the DFR 

_PC 4: how similar high load incorrect trials are to the template correct trials and low load correct trials in fusiform_

* similarity of high load incorrect trials during delay in the DFR
* similarity of high load incorrect trials in the fusiform during delay 
* similarity of high load incorrect trials during encoding in the DFR
* similarity of low load correct trials in encoding in DFR 
* similarity of low load correct trials during delay in DFR 

_PC 5: mostly related to correct trials (regardless of load) in fusiform_

* similarity of high load incorrect trials in the fusiform during delay 
* similarity of high load correct trials in the fusiform during delay 
* similarity of high load correct trials in the DFR during encoding
* similarity of low load correct trials in the fusiform during delay 
* similarity of low load correct trials in the fusiform during encoding
* template encoding to template delay in the fusiform ROI 

```{r pca for sim}

res_sim.pca <- prcomp(data_for_reg[,c(31:48)], scale = TRUE)
fviz_eig(res_sim.pca)

summary(res_sim.pca)

res_sim.var <- get_pca_var(res_sim.pca)
res_sim.var$contrib      # Contributions to the PCs

# Contributions of variables to PC1
fviz_contrib(res_sim.pca, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
fviz_contrib(res_sim.pca, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC3
fviz_contrib(res_sim.pca, choice = "var", axes = 3, top = 10)
# Contributions of variables to PC4
fviz_contrib(res_sim.pca, choice = "var", axes = 4, top = 10)
# Contributions of variables to PC5
fviz_contrib(res_sim.pca, choice = "var", axes = 5, top = 10)

fviz_pca_var(res_sim.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)


```

## MVPA 

Now, let's do the same for the MVPA measures. 

- PC1: fusiform during encoding/probe for both template and indiv trials 
- PC2: DFR encoding and delay for mostly indiv trials
- PC3: DFR encoding and probe (mostly averages from template)
- PC4: fusiform delay and probe, mostly indiv trials 
- PC5: fusiform, averages from template, all trial types, mostly delay and encoding 
- PC6: template averages for high load trials 
- PC7: high incorrect and low correct in fusiform across trial, mostly in individual trials
- PC8: low correct trials, particularly for DFR 
- PC9: incorrect high load trials across region, mostly in probe and encoding 
- PC10: low correct and high incorrect in fusiform averages from template
- PC11: all trial types, mostly geared towards DFR (regardless of individual or template) during probe and delay
- PC12: loads really strongly on the template average on low correct trials from the delay period in the fusiform, but otherwise, tends to lean towards delay period, from the DFR, low correct trials

```{r pca for MVPA}

res_MVPA.pca <- prcomp(data_for_reg[,c(57:92)], scale = TRUE)
fviz_eig(res_MVPA.pca)

summary(res_MVPA.pca)

res_MVPA.var <- get_pca_var(res_MVPA.pca)
#res_MVPA.var$contrib      # Contributions to the PCs

# Contributions of variables to PC1
fviz_contrib(res_MVPA.pca, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
fviz_contrib(res_MVPA.pca, choice = "var", axes = 2, top = 10)
# Contributions of variables to PC3
fviz_contrib(res_MVPA.pca, choice = "var", axes = 3, top = 10)
# Contributions of variables to PC4
fviz_contrib(res_MVPA.pca, choice = "var", axes = 4, top = 10)
# Contributions of variables to PC5
fviz_contrib(res_MVPA.pca, choice = "var", axes = 5, top = 10)
# Contributions of variables to PC6
fviz_contrib(res_MVPA.pca, choice = "var", axes = 6, top = 10)
# Contributions of variables to PC7
fviz_contrib(res_MVPA.pca, choice = "var", axes = 7, top = 10)
# Contributions of variables to PC8
fviz_contrib(res_MVPA.pca, choice = "var", axes = 8, top = 10)
# Contributions of variables to PC9
fviz_contrib(res_MVPA.pca, choice = "var", axes = 9, top = 10)
# Contributions of variables to PC10
fviz_contrib(res_MVPA.pca, choice = "var", axes = 10, top = 10)
# Contributions of variables to PC11
fviz_contrib(res_MVPA.pca, choice = "var", axes = 11, top = 10)
# Contributions of variables to PC12
fviz_contrib(res_MVPA.pca, choice = "var", axes = 12, top = 10)


fviz_pca_var(res_MVPA.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)



```

Now that we have our PCs to reduce overlapping variance, we can use these in a series of regressions to predict span, BPRS and accuracy at high load. We will use a number of different methods to select features: stepwise regression, ridge regression, LASSO regression and ElasticNet regression. A brief description of the methods are as follows: 

**Stepwise Regression:** Initially takes all parameters and sequentially removes parameters to minimize the AIC of the model overall. At each step, it calculates what the AIC would be if it removed each individual parameter and then removes the one that makes the most difference. Stops when model converges at a minimal AIC. 

**Ridge Regression:** A type of penalized linear regression (uses L2 norm - minimizes the sum of the squared coefficients). Shrinks the values of unimportant coefficients close to zero, but does not remove them. 

**LASSO Regression:** Another type of penalized linear regression (uses L1 norm - minimizes the sum of the absolute value of the coefficients). Forces coefficients that are unimportant to the model to be zero, creating a sparse model. 

**ElasticNet Regression:** Uses both L1- and L2-norm penalties with regression, so shrinks some coefficients close to zero and some to exactly zero. 

# Predicting Span

## Prep data

```{r create data df}
reg_data <- data.frame(span = data_for_reg$span, 
                       high_acc = data_for_reg$high_acc,
                       BPRS = data_for_reg$BPRS,
                       res.pca[["x"]][,1:3],
                       res_sim.pca[["x"]][,1:5], 
                       res_MVPA.pca[["x"]][,1:12])

colnames(reg_data)[4:6] <- paste("PC",c(1:3),"_univ",sep="")
colnames(reg_data)[7:11] <- paste("PC",c(1:5),"_sim",sep="")
colnames(reg_data)[12:23] <- paste("PC",c(1:12),"_MVPA",sep="")

set.seed(123)
```

```{r prep data - predict span}
training.samples_span <- reg_data$span %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data_span  <- reg_data[training.samples_span, c(1, 4:23)]
test.data_span <- reg_data[-training.samples_span, c(1, 4:23)]

# standardize, because that is important for ridge regression 
train.data_span <- sapply(train.data_span, scale)
test.data_span <- sapply(test.data_span, scale)
test.data_span <- data.frame(test.data_span)

lambda <- 10^seq(-3, 3, length = 100)


```

## Stepwise Regression 

While the final stepwise model is significant overall, we see significant effects of: 

+ __PC1_univ:__ encoding load effects and the combined encoding+encoding-delay in the PFC regions. This value is negative, suggesting that stronger load effects is related to lower span
+ __PC2_univ:__ delay load effect. This term is also negative, again suggesting stronger load effect is related to lower span
+ __PC1_sim:__ mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform. This term is negative
+ __PC2_univ:__ similarity within TR in low load correct trials in DFR, individual to template across TR in high load correct in fusiform. This term is positive, suggesting that higher similarity means higher span 


```{r stepwise - span}

step.span <- train(span ~., data = train.data_span,
                    method = "lmStepAIC", 
                    trControl = trainControl("cv", number = 10),
                    trace = FALSE
                    )
# Model accuracy
step.span$results
# Final model coefficients
step.span$finalModel
# Summary of the model
summary(step.span$finalModel)

```
## Ridge Regression 

The most important PCs for the Ridge regression predicting span are: 

+ __PC1_univ:__ encoding load effects and the combined encoding+encoding-delay in the PFC regions. This value is negative, suggesting that stronger load effects is related to lower span
+ __PC1_sim:__ mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform (which we saw in the stepwise model)
+ __PC3_MVPA:__ DFR encoding and probe (mostly averages from template)
+ __PC5_MVPA:__ fusiform, averages from template, all trial types, mostly delay and encoding
+ __PC7_MVPA:__ high incorrect and low correct in fusiform across trial, mostly in individual trials
+ __PC10_MVPA:__ low correct and high incorrect in fusiform averages from template
+ __PC11_MVPA:__ all trial types, mostly geared towards DFR (regardless of individual or template) during probe and delay

```{r ridge - span}

ridge.span <- train(
  span ~., data = train.data_span, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 0, lambda = lambda)
  )
# Model coefficients
coef(ridge.span$finalModel, ridge.span$bestTune$lambda)
# Make predictions
predictions.ridge.span <- ridge.span %>% predict(test.data_span)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.ridge.span, test.data_span$span),
  Rsquare = R2(predictions.ridge.span, test.data_span$span)
)

```

## LASSO Regression

In the LASSO regression, we see that only PC1 from the univariate information and PC1 from the similarity measures are kept. 

```{r lasso - span}

lasso.span <- train(
  span ~., data = train.data_span, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 1, lambda = lambda)
  )
# Model coefficients
coef(lasso.span$finalModel, lasso.span$bestTune$lambda)
# Make predictions
predictions.lasso.span <- lasso.span %>% predict(test.data_span)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.lasso.span, test.data_span$span),
  Rsquare = R2(predictions.lasso.span, test.data_span$span)
)

```

## ElasticNet

Same with ElasticNet

```{r elastic net - span}

elastic.span <- train(
  span ~., data = train.data_span, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )
# Model coefficients
coef(elastic.span$finalModel, elastic.span$bestTune$lambda)
# Make predictions
predictions.elastic.span <- elastic.span %>% predict(test.data_span)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.elastic.span, test.data_span$span),
  Rsquare = R2(predictions.elastic.span, test.data_span$span)
)
```

## Compare Models

When comparing models, ElasticNet seems to be our best model - it explains ~12% of variance in span, and has the lowest median RMSE. 

```{r compare models - span}

models.span <- list(ridge = ridge.span, lasso = lasso.span, elastic = elastic.span, stepwise = step.span)
resamples(models.span) %>% summary( metric = "RMSE")

resamples(models.span) %>% summary( metric = "Rsquared")

```

# Predicting BPRS

## Prep data

```{r prep data - predict BPRS}

set.seed(123)

training.samples_BPRS <- reg_data$BPRS %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data_BPRS  <- reg_data[training.samples_BPRS, c(3, 4:23)]
test.data_BPRS <- reg_data[-training.samples_BPRS, c(3, 4:23)]

# standardize, because that is important for ridge regression 
train.data_BPRS <- sapply(train.data_BPRS, scale)
test.data_BPRS <- sapply(test.data_BPRS, scale)
test.data_BPRS <- data.frame(test.data_BPRS)

lambda <- 10^seq(-3, 3, length = 100)


```

## Stepwise regression

To predict BPRS, we see the PCs that contain important information are: 

+ __PC3_univ:__ encoding - delay in parietal regions
+ __PC2_sim:__ similarity within TR in low load correct trials in DFR, individual to template across TR in high load correct in fusiform
+ __PC5_sim:__ mostly related to correct trials (regardless of load) in fusiform. This is the only term here that shows a negative relationship, such that lower similarity relates to higher BPRS scores. 
+ __PC4_MVPA:__ fusiform delay and probe, mostly indiv trials
+ __PC7_MVPA:__ high incorrect and low correct in fusiform across trial, mostly in individual trials

```{r stepwise - BPRS}

step.BPRS <- train(BPRS ~., data = train.data_BPRS,
                    method = "lmStepAIC", 
                    trControl = trainControl("cv", number = 10),
                    trace = FALSE
                    )
# Model accuracy
step.BPRS$results
# Final model coefficients
step.BPRS$finalModel
# Summary of the model
summary(step.BPRS$finalModel)

```

## Ridge Regression

Ridge regression gives us the following important PCs (similar to above) : 

+ __PC3_sim:__ fusiform similarity during encoding (regardless of accuracy), delay similarity in DFR - term is negative
+ __PC5_sim:__ mostly related to correct trials (regardless of load) in fusiform. This is the only term here that shows a negative relationship, such that lower similarity relates to higher BPRS scores.
+ __PC4_MVPA:__ fusiform delay and probe, mostly indiv trials
+ __PC7_MVPA:__ high incorrect and low correct in fusiform across trial, mostly in individual trials

```{r ridge - BPRS}

ridge.BPRS <- train(
  BPRS ~., data = train.data_BPRS, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 0, lambda = lambda)
)
# Model coefficients
coef(ridge.BPRS$finalModel, ridge.BPRS$bestTune$lambda)
# Make predictions
predictions.ridge.BPRS <- ridge.BPRS %>% predict(test.data_BPRS)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.ridge.BPRS, test.data_BPRS$BPRS),
  Rsquare = R2(predictions.ridge.BPRS, test.data_BPRS$BPRS)
)
```

## LASSO Regression

LASSO gives us almost a combination of the above analyses: 

+ __PC3_univ:__ encoding - delay in parietal regions
+ __PC3_sim:__ fusiform similarity during encoding (regardless of accuracy), delay similarity in DFR - term is negative
+ __PC5_sim:__ mostly related to correct trials (regardless of load) in fusiform. This is the only term here that shows a negative relationship, such that lower similarity relates to higher BPRS scores. 
+ __PC4_MVPA:__ fusiform delay and probe, mostly indiv trials
+ __PC7_MVPA:__ high incorrect and low correct in fusiform across trial, mostly in individual trials
+ __PC9_MVPA:__ incorrect high load trials across region, mostly in probe and encoding

```{r lasso - BPRS}

lasso.BPRS <- train(
  BPRS ~., data = train.data_BPRS, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 1, lambda = lambda)
)
# Model coefficients
coef(lasso.BPRS$finalModel, lasso.BPRS$bestTune$lambda)
# Make predictions
predictions.lasso.BPRS <- lasso.BPRS %>% predict(test.data_BPRS)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.lasso.BPRS, test.data_BPRS$BPRS),
  Rsquare = R2(predictions.lasso.BPRS, test.data_BPRS$BPRS)
)

```

## ElasticNet

ElasticNet ends up mostly the same as LASSO, but adds in one additional parameter. 

+ __PC3_univ:__ encoding - delay in parietal regions
+ __PC2_sim:__ similarity within TR in low load correct trials in DFR, individual to template across TR in high load correct in fusiform
+ __PC3_sim:__ fusiform similarity during encoding (regardless of accuracy), delay similarity in DFR - term is negative
+ __PC4_sim:__ how similar high load incorrect trials are to the template correct trials and low load correct trials in fusiform
+ __PC5_sim:__ mostly related to correct trials (regardless of load) in fusiform. This is the only term here that shows a negative relationship, such that lower similarity relates to higher BPRS scores. 
+ __PC4_MVPA:__ fusiform delay and probe, mostly indiv trials
+ __PC7_MVPA:__ high incorrect and low correct in fusiform across trial, mostly in individual trials
+ __PC9_MVPA:__ incorrect high load trials across region, mostly in probe and encoding

```{r elastic net - BPRS}

elastic.BPRS <- train(
  BPRS ~., data = train.data_BPRS, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
)
# Model coefficients
coef(elastic.BPRS$finalModel, elastic.BPRS$bestTune$lambda)
# Make predictions
predictions.elastic.BPRS <- elastic.BPRS %>% predict(test.data_BPRS)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.elastic.BPRS, test.data_BPRS$BPRS),
  Rsquare = R2(predictions.elastic.BPRS, test.data_BPRS$BPRS)
)
```

## Compare Models

These models can explain less variance than in span - only about 3-7%. It seems as though LASSO is doing the best, with the 2nd highest explained variance but the lowest RMSE. 

```{r compare models - BPRS}

models.BPRS <- list(ridge = ridge.BPRS, lasso = lasso.BPRS, elastic = elastic.BPRS, stepwise = step.BPRS)
resamples(models.BPRS) %>% summary( metric = "RMSE")

resamples(models.BPRS) %>% summary( metric = "Rsquared")


```

# Predicting Accuracy 

## Prep data

```{r prep data - predict high_acc}

set.seed(123)

training.samples_high_acc <- reg_data$high_acc %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data_high_acc  <- reg_data[training.samples_high_acc, c(2, 4:23)]
test.data_high_acc <- reg_data[-training.samples_high_acc, c(2, 4:23)]

train.data_high_acc <- sapply(train.data_high_acc, scale)
test.data_high_acc <- sapply(test.data_high_acc, scale)
test.data_high_acc <- data.frame(test.data_high_acc)

lambda <- 10^seq(-3, 3, length = 100)


```

## Stepwise regression

+ __PC3_univ:__ encoding - delay in parietal regions
+ __PC1_sim:__ mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform. This term is negative
+ __PC3_sim:__ fusiform similarity during encoding (regardless of accuracy), delay similarity in DFR 
+ __PC4_sim:__ how similar high load incorrect trials are to the template correct trials and low load correct trials in fusiform - term is negative
+ __PC2_MVPA:__ DFR encoding and delay for mostly indiv trials - term is negative
+ __PC4_MVPA:__ fusiform delay and probe, mostly indiv trials  - term is negative
+ __PC10_MVPA:__ low correct and high incorrect in fusiform averages from template - term is negative
+ __PC11_MVPA:__ all trial types, mostly geared towards DFR (regardless of individual or template) during probe and delay - term is negative


```{r stepwise - high acc}

step.high_acc <- train(high_acc ~., data = train.data_high_acc,
                    method = "lmStepAIC", 
                    trControl = trainControl("cv", number = 10),
                    trace = FALSE
                    )
# Model accuracy
step.high_acc$results
# Final model coefficients
step.high_acc$finalModel
# Summary of the model
summary(step.high_acc$finalModel)

```

## Ridge regression

In this one, it's hard to interpret since all of the coefficients have more or less the same magnitude. 

```{r ridge - high_acc}

ridge.high_acc <- train(
  high_acc ~., data = train.data_high_acc, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 0, lambda = lambda)
)
# Model coefficients
coef(ridge.high_acc$finalModel, ridge.high_acc$bestTune$lambda)
# Make predictions
predictions.ridge.high_acc <- ridge.high_acc %>% predict(test.data_high_acc)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.ridge.high_acc, test.data_high_acc$high_acc),
  Rsquare = R2(predictions.ridge.high_acc, test.data_high_acc$high_acc)
)
```

## LASSO Regression

+ __PC2_univ:__ delay load effect. This term is also negative, again suggesting stronger load effect is related to lower span. Term is negative
+ __PC1_sim:__ mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform. This term is negative
+ __PC3_sim:__ fusiform similarity during encoding (regardless of accuracy), delay similarity in DFR 
+ __PC4_sim:__ how similar high load incorrect trials are to the template correct trials and low load correct trials in fusiform - term is negative
+ __PC5_sim:__ mostly related to correct trials (regardless of load) in fusiform
+ __PC2_MVPA:__ DFR encoding and delay for mostly indiv trials 
+ __PC3_MVPA:__ DFR encoding and probe (mostly averages from template) - term is negative
+ __PC4_MVPA:__ fusiform delay and probe, mostly indiv trials  - term is negative
+ __PC6_MVPA:__ template averages for high load trials
+ __PC8_MVPA:__ low correct trials, particularly for DFR
+ __PC9_MVPA:__ incorrect high load trials across region, mostly in probe and encoding
+ __PC10_MVPA:__ low correct and high incorrect in fusiform averages from template - term is negative
+ __PC11_MVPA:__ all trial types, mostly geared towards DFR (regardless of individual or template) during probe and delay - term is negative

```{r lasso - high_acc}

lasso.high_acc <- train(
  high_acc ~., data = train.data_high_acc, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneGrid = expand.grid(alpha = 1, lambda = lambda)
)
# Model coefficients
coef(lasso.high_acc$finalModel, lasso.high_acc$bestTune$lambda)
# Make predictions
predictions.lasso.high_acc <- lasso.high_acc %>% predict(test.data_high_acc)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.lasso.high_acc, test.data_high_acc$high_acc),
  Rsquare = R2(predictions.lasso.high_acc, test.data_high_acc$high_acc)
)

```

## Elastic Net

When we look at ElasticNet, all coefficients play a role. The most important ones seem to be: 

+ __PC3_univ:__ encoding - delay in parietal regions
+ __PC1_sim:__ mostly related to within TR high load correct trials (regardless of area) and across TR similarity at high load in the fusiform. This term is negative
+ __PC4_sim:__ how similar high load incorrect trials are to the template correct trials and low load correct trials in fusiform - term is negative


```{r elastic net - high_acc}

elastic.high_acc <- train(
  high_acc ~., data = train.data_high_acc, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
)
# Model coefficients
coef(elastic.high_acc$finalModel, elastic.high_acc$bestTune$lambda)
# Make predictions
predictions.elastic.high_acc <- elastic.high_acc %>% predict(test.data_high_acc)
# Model prediction performance
data.frame(
  RMSE = RMSE(predictions.elastic.high_acc, test.data_high_acc$high_acc),
  Rsquare = R2(predictions.elastic.high_acc, test.data_high_acc$high_acc)
)
```

## Compare models

These models explain much more variance than either span or BPRS - on the level of 25-40% of the variance. ElasticNet drastically outperforms the other methods, with 40% variance explained and the second lowest RMSE. 

```{r compare models - high_acc}

models.high_acc <- list(ridge = ridge.high_acc, lasso = lasso.high_acc, elastic = elastic.high_acc, stepwise = step.high_acc)
resamples(models.high_acc) %>% summary( metric = "RMSE")

resamples(models.high_acc) %>% summary( metric = "Rsquared")

```

