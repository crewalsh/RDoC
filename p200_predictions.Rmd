---
title: "Prediction Analyses"
author: "Catherine Walsh"
date: "5/1/2020"
output:
  html_document:
    toc: true 
    toc_float: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

When looking at the time course data, we noticed an interesting pattern: it seemed as though it would be possible to predict an individual's group from the difference between their load effect during encoding and their load effect during delay. It seemed as though low capacity subjects had small load effects at both encoding and delay, medium capacity subjects had large load effects at both encoding and delay and high capacity subjects had large load effects at encoding but small ones at delay. As such, we wanted to create a model that used this information to predict span. 

To do so, we extracted data from TR 6 for the encoding period and TR 8 for the delay period. This represented 1 TR's worth of data in the middle of where we'd expect activity from for each period (from our model of the task convolved with a hemodynamic delay function) and where we see maximal differences between group. In addition to the raw load effects, we created two composite variables that we expected to capture the differences between groups. The first was simply the difference between load effects at encoding and delay, and the second was the sum of that difference and the load effect effect at encoding. These measures allow us to create a series of regression models to predict span, BPRS total score and accuracy at high load. 

In addition to the univariate load effects, we have also seen a relationship with various measures reflecting multivariate representation across and within trial, including the probability of a MVPA classifer predicting a face at any given point in a trial and the similarity of multivariate representations across and within trials. Both of these measures were taken at each individual trial and averaged, in addition to taken from the average over many trials (which served as a template for the canonical trial type). We added these multivariate measures to see if they improved model performance when added to regression models that only contained variables based on univariate load effects.  

Finally, we added in structural measures, resting state measures and EEG measures to try to explain variance at multiple different levels/modalities. 

Overall, we were best able to explain variance in high load accuracy, with our best model able to explain 26% of the variance. In contrast, we were only able to explain 21% of the variance in span, and 12% of the variance in BPRS scores. 

The individual components related to each of these measures will be discussed further below, but one interesting thing to note is that there is largely not much overlap. There is some overlap in the EEG measures between BPRS and span, but no overlap between span and accuracy or accuracy and BPRS. Another interesting thing to note is that when comparing PCs related to accuracy and span, those related to accuracy seem to be very much driven by the encoding and measures related to visual processing, while PCs related to span include more connectivity/multivariate measures and are also driven by delay period, or processing in DFR regions. 

```{r load libraries and data}

library(tidyverse)
library(psych)
library(reshape2)
library(rmatio)
library(factoextra)
library(patchwork)
library(MASS)
library(caret)
library(glmnet)
library(tidymodels)

load('data/behav.RData')
load('data/structural_measures.RData')
FA_Data <- read.csv("data/RDoC_DTI_FA_JHU_ICBM.csv")
load('data/EEG_for_PCs.RData')
load('data/connectivity_data.RData')
load('data/load_effects_DFR.RData')
load('data/split_groups_info.RData')
load('data/ITC_fusiform.RData')
similarity_fusiform <- similarity_temp
load('data/ITC_DFR_delay.RData')
similarity_DFR <- similarity_temp 
load("data/MVPA_fusiform.RData")
individual_trial_probs_fusiform <- individual_trial_averages_probs
averages_from_template_fusiform <- averages_from_template
load("data/MVPA_DFR_delay_mask.RData")
individual_trial_probs_DFR <- individual_trial_averages_probs
averages_from_template_DFR <- averages_from_template
load("data/MVPA_HPC.RData")
individual_trial_probs_HPC <- individual_trial_averages_probs
averages_from_template_HPC <- averages_from_template

DFR_ROIs <- c("L aMFG","L dlPFC","L dMFG","L IPS","L preSMA","R dlPFC","R IPS","R medParietal","all delay ROIs")

source("helper_fxns/select_period_average.R")
source("helper_fxns/calc_r_squared.R")


```

# Prep data

First, we're going to load in the time courses of the activity from the DFR regions. We're doing this a little differently from last time, because we don't want the interpolated data, we just want the one with 14 TRs. 

We're going to remove the subjects that aren't included in the split group analysis, and put the data in a slightly easier to use format. 

```{r load in time course data in TRs}

temp <- read.mat('data/RSA_DFR_trials.mat')
factors <- matrix(nrow=170)

for (idx in seq.int(1,170)){
  if (constructs_fMRI$PTID[idx] %in% WM_groups[["high"]]$PTID){
    factors[idx] <- "high"
  }else if (constructs_fMRI$PTID[idx] %in% WM_groups[["med"]]$PTID){
    factors[idx] <- "med"
  }else if (constructs_fMRI$PTID[idx] %in% WM_groups[["low"]]$PTID){
    factors[idx] <- "low"
  }else{
    factors[idx] <- "not_incl"
  }
}

factors <- factor(factors, levels=c("low","med","high","not_incl"))
trial_activity_high <- temp[["trial_avg_activity_high"]]
trial_activity_low <- temp[["trial_avg_activity_low"]]

all_data <- list(subjs=constructs_fMRI$PTID,
                 WMC = factors, 
                 L_aMFG = list(
                   high = data.frame(trial_activity_high[,,1,1]),
                   low = data.frame(trial_activity_low[,,1,1])
                 ),
                 L_dlPFC = list(
                   high = data.frame(trial_activity_high[,,1,2]),
                   low = data.frame(trial_activity_low[,,1,2])
                 ),
                 L_dMFG = list(
                   high = data.frame(trial_activity_high[,,1,3]),
                   low = data.frame(trial_activity_low[,,1,3])
                 ), 
                 L_IPS = list(
                   high = data.frame(trial_activity_high[,,1,4]),
                   low = data.frame(trial_activity_low[,,1,4])
                 ), 
                 L_preSMA = list(
                   high = data.frame(trial_activity_high[,,1,5]),
                   low = data.frame(trial_activity_low[,,1,5])
                 ), 
                 R_dlPFC = list(
                   high = data.frame(trial_activity_high[,,1,6]),
                   low = data.frame(trial_activity_low[,,1,6])
                 ),
                 R_IPS = list(
                   high = data.frame(trial_activity_high[,,1,7]),
                   low = data.frame(trial_activity_low[,,1,7])
                 ),
                 R_medParietal = list(
                   high = data.frame(trial_activity_high[,,1,8]),
                   low = data.frame(trial_activity_low[,,1,8])
                 ),
                 all_delay = list(
                   high = data.frame(trial_activity_high[,,1,9]),
                   low = data.frame(trial_activity_low[,,1,9])
                 )
)

```

Now, we're going to calculate load effects for each ROI at every time point. 

```{r calculate load effects}

for (ROI in seq.int(3,11)){
  all_data[[ROI]][["load_effect"]] <- all_data[[ROI]][["high"]]-all_data[[ROI]][["low"]]
  temp <- data.frame(group = all_data[["WMC"]], all_data[[ROI]][["load_effect"]])
  all_data[[ROI]][["SVM"]] <- temp
}

```

Now, let's pull out the encoding and delay values - we're also going to calculate the difference between encoding and delay, and encoding + (encoding-delay), because we think that this is going to be useful. We're going to include all these measures, plus span, in a convenient dataframe. 

```{r calculate encoding and delay values}

for (ROI in seq.int(3,11)){
  temp <- data.frame(matrix(nrow=170, ncol=6))
  colnames(temp) <- c("group","encoding","delay","encoding_delay","encoding_delay_comb" ,"span")
  temp$group <- all_data[["WMC"]]
  temp$span <- constructs_fMRI$omnibus_span_no_DFR_MRI
  
  temp$encoding <- all_data[[ROI]][["load_effect"]][,6]
  #temp$delay <- rowMeans(all_data[[ROI]][["load_effect"]][,8:9])
  
  temp$delay <- all_data[[ROI]][["load_effect"]][,8]
  temp$encoding_delay <- temp$encoding - temp$delay
  temp$encoding_delay_comb <- temp$encoding + temp$encoding_delay 
  temp$high_acc <- p200_data$XDFR_MRI_ACC_L3[p200_data$PTID %in% constructs_fMRI$PTID]
  
  temp$BPRS <- p200_clinical_zscores$BPRS_TOT[p200_clinical_zscores$PTID %in% constructs_fMRI$PTID]
  
  all_data[[ROI]][["SVM_2"]] <- temp
  
}

```

# Relationship between Span and Encoding - Delay 

All regions except for L aMFG have significant relationships 

```{r make plots}

ROI_plot_list <- list()

for (ROI in seq.int(3,11)){
  correlation_test <- cor.test(all_data[[ROI]][["SVM_2"]]$span,all_data[[ROI]][["SVM_2"]]$encoding_delay)
  
  ROI_plot_list[[DFR_ROIs[ROI-2]]] <- ggplot(data=all_data[[ROI]][["SVM_2"]])+
    geom_point(aes(x=span,y=encoding_delay_comb,color=group))+
    stat_smooth(aes(x=span,y=encoding_delay_comb),method="lm",color="black")+
    ggtitle(paste(DFR_ROIs[ROI-2], ", r = ",round(correlation_test$estimate,digits=3)))+
    xlab("WM Span")+
    ylab("LE Difference")+
    theme_classic()
  
}

(ROI_plot_list[[1]] + ROI_plot_list[[2]]) /
  (ROI_plot_list[[3]] + ROI_plot_list[[4]]) +  
  plot_annotation(title = "Correlation between (encoding LE + encoding/delay LE difference) and span ")+
  plot_layout(guides="collect")

(ROI_plot_list[[5]] + ROI_plot_list[[6]]) /
  (ROI_plot_list[[7]] + ROI_plot_list[[8]]) +
  plot_layout(guides="collect")

ROI_plot_list[[9]]   


```

# Explore data 

```{r create data frame with all info for regression}

data_for_reg <- data.frame(span = all_data[["all_delay"]][["SVM_2"]]$span,
                           high_acc = all_data[["all_delay"]][["SVM_2"]]$high_acc, 
                           BPRS = all_data[["all_delay"]][["SVM_2"]]$BPRS,
                           L_aMFG_enc = all_data[[3]][["SVM_2"]]$encoding, 
                           L_aMFG_delay = all_data[[3]][["SVM_2"]]$delay, 
                           L_dlPFC_enc = all_data[[4]][["SVM_2"]]$encoding, 
                           L_dlPFC_delay = all_data[[4]][["SVM_2"]]$delay,
                           L_dMFG_enc = all_data[[5]][["SVM_2"]]$encoding, 
                           L_dMFG_delay = all_data[[5]][["SVM_2"]]$delay,
                           L_IPS_enc = all_data[[6]][["SVM_2"]]$encoding, 
                           L_IPS_delay = all_data[[6]][["SVM_2"]]$delay,
                           L_preSMA_enc = all_data[[7]][["SVM_2"]]$encoding, 
                           L_preSMA_delay = all_data[[7]][["SVM_2"]]$delay,
                           R_dlPFC_enc = all_data[[8]][["SVM_2"]]$encoding, 
                           R_dlPFC_delay = all_data[[8]][["SVM_2"]]$delay,
                           R_IPS_enc = all_data[[9]][["SVM_2"]]$encoding, 
                           R_IPS_delay = all_data[[9]][["SVM_2"]]$delay,
                           R_medPar_enc = all_data[[10]][["SVM_2"]]$encoding, 
                           R_medPar_delay = all_data[[10]][["SVM_2"]]$delay,
                           all_delay_enc = all_data[[11]][["SVM_2"]]$encoding, 
                           all_delay_delay = all_data[[11]][["SVM_2"]]$delay,
                           L_aMFG_enc_delay = all_data[[3]][["SVM_2"]]$encoding_delay, 
                           L_dlPFC_enc_delay = all_data[[4]][["SVM_2"]]$encoding_delay, 
                           L_dMFG_enc_delay = all_data[[5]][["SVM_2"]]$encoding_delay,
                           L_IPS_enc_delay = all_data[[6]][["SVM_2"]]$encoding_delay, 
                           L_preSMA_enc_delay = all_data[[7]][["SVM_2"]]$encoding_delay, 
                           R_dlPFC_enc_delay = all_data[[8]][["SVM_2"]]$encoding_delay, 
                           R_IPS_enc_delay = all_data[[9]][["SVM_2"]]$encoding_delay,
                           R_medPar_enc_delay = all_data[[10]][["SVM_2"]]$encoding_delay,
                           L_aMFG_enc_delay_comb = all_data[[3]][["SVM_2"]]$encoding_delay_comb, 
                           L_dlPFC_enc_delay_comb = all_data[[4]][["SVM_2"]]$encoding_delay_comb, 
                           L_dMFG_enc_delay_comb = all_data[[5]][["SVM_2"]]$encoding_delay_comb,
                           L_IPS_enc_delay_comb = all_data[[6]][["SVM_2"]]$encoding_delay_comb, 
                           L_preSMA_enc_delay_comb = all_data[[7]][["SVM_2"]]$encoding_delay_comb, 
                           R_dlPFC_enc_delay_comb = all_data[[8]][["SVM_2"]]$encoding_delay_comb, 
                           R_IPS_enc_delay_comb = all_data[[9]][["SVM_2"]]$encoding_delay_comb,
                           R_medPar_enc_delay_comb = all_data[[10]][["SVM_2"]]$encoding_delay_comb, 
                           R_all_delay_enc_delay_comb = all_data[[11]][["SVM_2"]]$encoding_delay_comb, 
                           high_corr_fus_enc = similarity_fusiform[["high_correct_avg"]]$X6, 
                           high_corr_fus_delay = similarity_fusiform[["high_correct_avg"]]$X8, 
                           high_incorr_fus_enc = similarity_fusiform[["high_incorrect_avg"]]$X6,
                           high_incorr_fus_del = similarity_fusiform[["high_incorrect_avg"]]$X8,
                           low_corr_fus_enc = similarity_fusiform[["low_correct_avg"]]$X6,
                           low_corr_fus_del = similarity_fusiform[["low_correct_avg"]]$X8, 
                           correct_encoding_to_correct_delay_fus = similarity_fusiform[["correct_encoding_to_correct_delay"]],
                           correct_enc_to_delay_fus_high_corr = similarity_fusiform[["correct_encoding_to_delay_avg"]][,4],
                           enc_to_correct_delay_fus_high_corr = similarity_fusiform[["encoding_to_correct_delay_avg"]][,4],
                           high_corr_DFR_enc = similarity_DFR[["high_correct_avg"]]$X6, 
                           high_corr_DFR_delay = similarity_DFR[["high_correct_avg"]]$X8, 
                           high_incorr_DFR_enc = similarity_DFR[["high_incorrect_avg"]]$X6,
                           high_incorr_DFR_del = similarity_DFR[["high_incorrect_avg"]]$X8,
                           low_corr_DFR_enc = similarity_DFR[["low_correct_avg"]]$X6,
                           low_corr_DFR_del = similarity_DFR[["low_correct_avg"]]$X8, 
                           correct_encoding_to_correct_delay_DFR = similarity_DFR[["correct_encoding_to_correct_delay"]],
                           correct_enc_to_delay_DFR_high_corr = similarity_DFR[["correct_encoding_to_delay_avg"]][,4],
                           enc_to_correct_delay_DFR_high_corr = similarity_DFR[["encoding_to_correct_delay_avg"]][,4],
                           indiv_trial_avgs_high_correct_fusiform_enc = individual_trial_probs_fusiform[["high_correct"]]$V6,
                           indiv_trial_avgs_high_correct_fusiform_delay = individual_trial_probs_fusiform[["high_correct"]]$V8,
                           indiv_trial_avgs_high_correct_fusiform_probe = individual_trial_probs_fusiform[["high_correct"]]$V11,
                           indiv_trial_avgs_high_correct_DFR_enc = individual_trial_probs_DFR[["high_correct"]]$V6,
                           indiv_trial_avgs_high_correct_DFR_delay = individual_trial_probs_DFR[["high_correct"]]$V8,
                           indiv_trial_avgs_high_correct_DFR_probe = individual_trial_probs_DFR[["high_correct"]]$V11,
                           indiv_trial_avgs_high_incorrect_fusiform_enc = individual_trial_probs_fusiform[["high_incorrect"]]$V6,
                           indiv_trial_avgs_high_incorrect_fusiform_delay = individual_trial_probs_fusiform[["high_incorrect"]]$V8,
                           indiv_trial_avgs_high_incorrect_fusiform_probe = individual_trial_probs_fusiform[["high_incorrect"]]$V11,
                           indiv_trial_avgs_high_incorrect_DFR_enc = individual_trial_probs_DFR[["high_incorrect"]]$V6,
                           indiv_trial_avgs_high_incorrect_DFR_delay = individual_trial_probs_DFR[["high_incorrect"]]$V8,
                           indiv_trial_avgs_high_incorrect_DFR_probe = individual_trial_probs_DFR[["high_incorrect"]]$V11,
                           indiv_trial_avgs_low_correct_fusiform_enc = individual_trial_probs_fusiform[["low_correct"]]$V6,
                           indiv_trial_avgs_low_correct_fusiform_delay = individual_trial_probs_fusiform[["low_correct"]]$V8,
                           indiv_trial_avgs_low_correct_fusiform_probe = individual_trial_probs_fusiform[["low_correct"]]$V11,
                           indiv_trial_avgs_low_correct_DFR_enc = individual_trial_probs_DFR[["low_correct"]]$V6,
                           indiv_trial_avgs_low_correct_DFR_delay = individual_trial_probs_DFR[["low_correct"]]$V8,
                           indiv_trial_avgs_low_correct_DFR_probe = individual_trial_probs_DFR[["low_correct"]]$V11,
                           averages_from_template_high_correct_fusiform_enc = averages_from_template_fusiform[["high_correct"]]$V6,
                           averages_from_template_high_correct_fusiform_delay = averages_from_template_fusiform[["high_correct"]]$V8,
                           averages_from_template_high_correct_fusiform_probe = averages_from_template_fusiform[["high_correct"]]$V11,
                           averages_from_template_high_correct_DFR_enc = averages_from_template_DFR[["high_correct"]]$V6,
                           averages_from_template_high_correct_DFR_delay = averages_from_template_DFR[["high_correct"]]$V8,
                           averages_from_template_high_correct_DFR_probe = averages_from_template_DFR[["high_correct"]]$V11,
                           averages_from_template_high_incorrect_fusiform_enc = averages_from_template_fusiform[["high_incorrect"]]$V6,
                           averages_from_template_high_incorrect_fusiform_delay = averages_from_template_fusiform[["high_incorrect"]]$V8,
                           averages_from_template_high_incorrect_fusiform_probe = averages_from_template_fusiform[["high_incorrect"]]$V11,
                           averages_from_template_high_incorrect_DFR_enc = averages_from_template_DFR[["high_incorrect"]]$V6,
                           averages_from_template_high_incorrect_DFR_delay = averages_from_template_DFR[["high_incorrect"]]$V8,
                           averages_from_template_high_incorrect_DFR_probe = averages_from_template_DFR[["high_incorrect"]]$V11,
                           averages_from_template_low_correct_fusiform_enc = averages_from_template_fusiform[["low_correct"]]$V6,
                           averages_from_template_low_correct_fusiform_delay = averages_from_template_fusiform[["low_correct"]]$V8,
                           averages_from_template_low_correct_fusiform_probe = averages_from_template_fusiform[["low_correct"]]$V11,
                           averages_from_template_low_correct_DFR_enc = averages_from_template_DFR[["low_correct"]]$V6,
                           averages_from_template_low_correct_DFR_delay = averages_from_template_DFR[["low_correct"]]$V8,
                           averages_from_template_low_correct_DFR_probe = averages_from_template_DFR[["low_correct"]]$V11, 
                           PTID = constructs_fMRI$PTID
)

data_for_reg <- merge(data_for_reg, p200_FFA, all = TRUE)
data_for_reg <- data_for_reg[,c(2:111,1)]

```

```{r make one df for EEG measures}

name_list <- c("alpha_cue_Favg", "alpha_cue_Oz", "alpha_delay_Favg", "alpha_delay_Oz",  "alpha_probe_Favg", "alpha_probe_Oz", "beta_cue_Favg", "beta_cue_Oz", "beta_delay_Favg", "beta_delay_Oz", "beta_probe_Favg", "beta_probe_Oz",  "theta_cue_Favg", "theta_cue_Oz",  "theta_delay_Favg", "theta_delay_Oz", "theta_probe_Favg", "theta_probe_Oz", "low_gamma_cue_Favg", "low_gamma_cue_Oz",  "low_gamma_delay_Favg", "low_gamma_delay_Oz",  "low_gamma_probe_Favg", "low_gamma_probe_Oz", "cue_O_n170", "probe_O_n170", "cue_P3", "probe_P3")

EEG_list <- list(alpha_cue_average_Favg, alpha_cue_average_Oz,alpha_delay_average_Favg, alpha_delay_average_Oz, alpha_probe_average_Favg, alpha_probe_average_Oz,beta_cue_average_Favg, beta_cue_average_Oz, beta_delay_average_Favg, beta_delay_average_Oz, beta_probe_average_Favg, beta_probe_average_Oz,theta_cue_average_Favg, theta_cue_average_Oz, theta_delay_average_Favg, theta_delay_average_Oz, theta_probe_average_Favg, theta_probe_average_Oz,low_gamma_cue_average_Favg, low_gamma_cue_average_Oz,low_gamma_delay_average_Favg, low_gamma_delay_average_Oz,  low_gamma_probe_average_Favg, low_gamma_probe_average_Oz,cue_average_O_n170, probe_average_O_n170, cue_average_P3, probe_average_P3 )

for (idx in seq.int(1,length(EEG_list))){
  colnames(EEG_list[[idx]])[2:3] <- paste0(name_list[idx],"_",colnames(EEG_list[[idx]][2:3]),sep="") 
  EEG_list[[idx]] <- EEG_list[[idx]][1:3]
}

EEG_df <- Reduce(function(x,y) merge(x = x, y = y, all=TRUE), EEG_list)
EEG_df <- merge(EEG_df, CDA[,1:10], all.x=TRUE, by.x="PTID", by.y="subID")

```

```{r put all structural measures in one df}

colnames(aparc_LH_MTHICK)[2:37] <- paste0(colnames(aparc_LH_MTHICK)[2:37],"_LH", sep="")
colnames(aparc_RH_MTHICK)[2:37] <- paste0(colnames(aparc_RH_MTHICK)[2:37],"_RH", sep="")
colnames(FA_Data)[1] <- "ID"

struc_df <- Reduce(function(x,y) merge(x = x, y = y, by="ID"),
                   list(aparc_LH_MTHICK, aparc_RH_MTHICK,aseg))

# remove STD from FA 
FA_Data <- FA_Data[,1:21]
FA_Data <- data.frame(FA_Data)


```

```{r put all RS measures in one df}

RS_df <- Reduce(function(x,y) merge(x=x, y=y, by = "PTID"), 
                list(p200_BCT_forCorr,p200_indiv_network_ParticCoeff, p200_all_RS))
RS_df <- data.frame(RS_df)

```

From these plots, we can see that our measures are high correlated. 

## Within encoding load effects

```{r correlations between univariate measures - encoding}
pairs.panels(data_for_reg[,c(4,6,8,10,12,14,16,18)], density=TRUE)

``` 

## Within delay load effects 

```{r correlations between univariate measures - delay }
pairs.panels(data_for_reg[,c(5,7,9,11,13,15,17,19)], density=TRUE)

``` 

## Encoding - Delay

```{r corelationsfor encoding-delay}
pairs.panels(data_for_reg[,c(22:29)], density= TRUE)

```

## Within TR Similarity

```{r correlation between similarity measures within TR}
pairs.panels(data_for_reg[,c(39:44,49:53)])

``` 

## Across TR Similarity

```{r correlation across TR similarity}
pairs.panels(data_for_reg[,c(45:47,53:56)])
```

## Within Inidivdual MPVA trials - fusiform 

```{r within MVPA fusiform indiv trials}
pairs.panels(data_for_reg[,c(57:59,63:65,69:71)])
```

## Within Inidivdual MPVA trials - delay

```{r within MVPA DFR indiv trials}
pairs.panels(data_for_reg[,c(60:62,66:68,72:74)])
```

## Within MPVA templates - fusiform 

```{r within MVPA fusiform templates}
pairs.panels(data_for_reg[,c(75:77,81:83,87:89)])
```

## Within MPVA templates - delay

```{r within MVPA DFR templates}
pairs.panels(data_for_reg[,c(78:80,84:86,90:92)])
```


# Run PCAs 

## Univariate effects

We know that our variables are highly correlated, so to deal with multi-collinearity, we're going to try to run a PCA on all the encoding load effects, delay load effects and encoding - delay. It looks like the first 3 dimensions carry most of the variance (77%), so we're going to stick with those three. 

_PC1:_ encoding load effects and the combined encoding+encoding-delay in the PFC regions and load effect during delay
_PC2:_ delay load effect
_PC3:_ encoding - delay in parietal regions and fusiform activity during delay 


```{r univariate analyses PCA}

res.pca <- prcomp(data_for_reg[!is.na(data_for_reg$L_CUE_LE),c(4:19, 22:37, 106:110)], scale = TRUE)
fviz_eig(res.pca)

summary(res.pca)

res.var <- get_pca_var(res.pca)
res.var$contrib        # Contributions to the PCs

for (axis in seq.int(1,3)){
  print(fviz_contrib(res.pca, choice = "var", axes = axis, top = 10))
}

fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)

```

## Similarity measures

We're going to the same thing for the similarity measures, since we have the same issue (though not quite as badly). 

We cover 78% of the variance by PC5, so we'll focus on those. 

_PC1:_ Similarity within trial 
_PC2:_ Individual to template DFR trials - particularly correct trials 
_PC3:_ High load correct trials in DFR, encoding to correct delay trials in high load correct trials in fusiform 
_PC4:_ Similarity within high load incorrect trials during delay and encoding 
_PC5:_ Correlation within low correct and high incorrect trials in DFR mask 

```{r pca for sim}

res_sim.pca <- prcomp(data_for_reg[,c(39:56)], scale = TRUE)
fviz_eig(res_sim.pca)

summary(res_sim.pca)

res_sim.var <- get_pca_var(res_sim.pca)
#res_sim.var$contrib      # Contributions to the PCs

for (axis in seq.int(1,5)){
  print(fviz_contrib(res_sim.pca, choice = "var", axes = axis, top = 10))
}
fviz_pca_var(res_sim.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)


```

## MVPA 

Now, let's do the same for the MVPA measures. We end up needing 12 PCs to reflect 75% of the variance.  

_PC1:_ Fusiform during encoding and probe 
_PC2:_ DFR during encoding 
_PC3:_ DFR during probe, averages from template across trial type
_PC4:_ Delay period decoding 
_PC5:_ Fusiform encoding during template -- most variance comes from high incorrect trials during individual trials
_PC6:_ Individual trials in fusiform, mostly during delay - mostly high incorrect individual trials 
_PC7:_ Individual trials, low correct and high incorrect, but most variance comes from high incorect trials in fusiform during delay from averages 
_PC8:_ High incorrect DFR across entire trial from individual trials 
_PC9:_ DFR decoding during correct trials in encoding and probe 
_PC10:_ Correct averaged from template trials during delay and probe - mostly DFR during probe 
_PC11:_ Low correct trials, mostly delay period after largest variance explained from fusiform during encoding
_PC12:_ Mostly correct trials from templates in the fusiform - most variance explained by encoding and probe 


```{r pca for MVPA}

res_MVPA.pca <- prcomp(data_for_reg[,c(57:92)], scale = TRUE)
fviz_eig(res_MVPA.pca)

summary(res_MVPA.pca)

res_MVPA.var <- get_pca_var(res_MVPA.pca)
#res_MVPA.var$contrib      # Contributions to the PCs

for (axis in seq.int(1,12)){
  print(fviz_contrib(res_MVPA.pca, choice = "var", axes = axis, top = 10))
}

fviz_pca_var(res_MVPA.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)



```

## Structural Data

For the structural data, we see that 19 PCs are necessary to explain 75% of the variance. There was a lot of overlap in these, so it was kind of tough to describe/classify them 

_PC1:_ Parietal lobe structures and some superior frontal structures
_PC2:_ Subcortical structures (including cerebellum)
_PC3:_ Cuneus, pericalcarine, superior parietal, lingual 
_PC4:_ Temporal pole, entorhinal 
_PC5:_ Lingual, perihippocampal, pericalcarine
_PC6:_ corpus callosum, caudate
_PC7:_ More subcortical
_PC8:_ Frontal pole (and other frontal regions)
_PC9:_ corpus callosum, hippocampus and surrounding regions
_PC10:_ Cerebellum, frontal 
_PC11:_ Parahippocampal and lateral occipital 
_PC12:_ Temporal, entorhinal, parahippocampal
_PC13:_ Temporal pole, temporal cortex, amygdala and HPC
_PC14:_ pars orbitalis, cingulate, accumbens
_PC15:_ left hemisphere subcortical, pars triangularis
_PC16:_ Temporal, orbitofrontal , frontal pole
_PC17:_ banks sts, some temporal and parietal cortex
_PC18:_ Cingulate, frontal
_PC19:_ HPC, lateral orbitofrontal poles 

```{r pca for structural data}

res_struct.pca <- prcomp(struc_df[,c(4:37, 40:96)], scale = TRUE)
fviz_eig(res_struct.pca)

summary(res_struct.pca)

res_struct.var <- get_pca_var(res_struct.pca)

for (axis in seq.int(1,19)){
  print(fviz_contrib(res_struct.pca, choice = "var", axes = axis, top = 10))
}

fviz_pca_var(res_struct.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)



```

## FA data 

For the FA data, we need 5 PCs to explain 75% of the variance: 

_PC1:_ Inferior frontal occipital fasiculus, forceps, anterior thalamic radiation (but really captures a lot of variance from a lot of structures)
_PC2:_ Cingulum/hippocampus 
_PC3:_ cingulum 
_PC4:_ Superior longitudinal fasiculus in temporal lobe in the left hemisphere and cortcospinal tract 
_PC5:_ Superior longitudinal fasiculus in temporal lobe in the right hemisphere and cingulum

```{r pca for FA data}

res_FA.pca <- prcomp(FA_Data[,2:21], scale = TRUE)
fviz_eig(res_FA.pca)

summary(res_FA.pca)

res_FA.var <- get_pca_var(res_FA.pca)

for (axis in seq.int(1,5)){
  print(fviz_contrib(res_FA.pca, choice = "var", axes = axis, top = 10))
}

fviz_pca_var(res_FA.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)



```

## EEG Data

For the EEG data, we see that 11 PCs are necessary to explain 75% of the variance. 

_PC1:_ Alpha and beta at high load during probe 
_PC2:_ ERSPs at probe during low load trials; specifically, low gamma  
_PC3:_ Alpha and beta power at delay, cue P3
_PC4:_ Low gamma 
_PC5:_ Theta power, n170 amplitude
_PC6:_ Theta power during cue, probe P3 
_PC7:_ CDA across lower load conditions (mostly 1 dot, some 3 dots), P3
_PC8:_ CDA across higher load conditions (mostly 5 dot, some 3 dots), n170 at high load
_PC9:_ P3 component
_PC10:_ CDA - 5 dot condition has the most variance, really a mix 
_PC11:_ CDA - 1 dot condition and also 5 dot condition (but high load has less contributions)

```{r pca for EEG data}

res_EEG.pca <- prcomp(EEG_df[complete.cases(EEG_df),2:66], scale = TRUE)
fviz_eig(res_EEG.pca)

summary(res_EEG.pca)

res_EEG.var <- get_pca_var(res_EEG.pca)

for (axis in seq.int(1,11)){
  print(fviz_contrib(res_EEG.pca, choice = "var", axes = axis, top = 10))
}

fviz_pca_var(res_EEG.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)



```


## RS Data

For the resting state data, we see that 8 PCs are necessary to explain 75% of the variance. 

_PC1:_ Participation coefficients across network (both average and individual network)
_PC2:_ FPCN connectivity with other networks, within connectivity for DMN and DAN 
_PC3:_ Within connectivity for DMN, FPCN connectivity with visual, CO, DMN, DANA networks 
_PC4:_ Global efficiency, within CO connectivity, participation coefficients
_PC5:_ Within visual connectivity and participation coefficient, within CO connectivity 
_PC6:_ Louvain modularity, within DAN connectivity 
_PC7:_ Within network VAN connectivity 
_PC8:_ Global efficiency, FPCN connectivity with DMN, FPCN and DAN, VAN intranetwork connectivity 

```{r pca for RS data}

res_RS.pca <- prcomp(RS_df[complete.cases(RS_df),2:21], scale = TRUE)
fviz_eig(res_RS.pca)

summary(res_RS.pca)

res_RS.var <- get_pca_var(res_RS.pca)

for (axis in seq.int(1,8)){
  print(fviz_contrib(res_RS.pca, choice = "var", axes = axis, top = 10))
}

fviz_pca_var(res_RS.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)



```

Now that we have our PCs to reduce overlapping variance, we can use these in a series of regressions to predict span, BPRS and accuracy at high load. We will use a number of different methods to select features: stepwise regression, ridge regression, LASSO regression and ElasticNet regression. A brief description of the methods are as follows: 

**Stepwise Regression:** Initially takes all parameters and sequentially removes parameters to minimize the AIC of the model overall. At each step, it calculates what the AIC would be if it removed each individual parameter and then removes the one that makes the most difference. Stops when model converges at a minimal AIC. 

**Ridge Regression:** A type of penalized linear regression (uses L2 norm - minimizes the sum of the squared coefficients). Shrinks the values of unimportant coefficients close to zero, but does not remove them. 

**LASSO Regression:** Another type of penalized linear regression (uses L1 norm - minimizes the sum of the absolute value of the coefficients). Forces coefficients that are unimportant to the model to be zero, creating a sparse model. 

**ElasticNet Regression:** Uses both L1- and L2-norm penalties with regression, so shrinks some coefficients close to zero and some to exactly zero. 

Each model is performed in a 10 fold cross validation, with inner hyperparameter tuning. There are 10% of subjects held out over each of the CV loops, so R squared is calculated using predictions on the held out data and from the best model for each cross validation, meaning that every subject gets a prediction. 

When listing the measures that occur in each model after feature selection, the features listed are those that show up in 7 or more cross validation iterations. 

Across the three potential feature selection procedures, a different model explains the most variance for each behavioral measure. However, across all three, ElasticNet performs consistently the best across the measures (2nd best [roughly the same] for span, second best for BPRS and best for high load accuracy), so we will use that as the model to compare across behavioral measure. 

# Predicting Span

## Prep data

```{r create data df}
reg_data <- data.frame(PTID = constructs_fMRI$PTID, 
                       span = data_for_reg$span, 
                       high_acc = data_for_reg$high_acc,
                       BPRS = data_for_reg$BPRS) 

univ_PCs <- data.frame(PTID = constructs_fMRI$PTID[!is.na(data_for_reg$L_CUE_LE)], res.pca[["x"]][,1:3])
colnames(univ_PCs)[2:4] <- paste("PC",c(1:3),"_univ",sep="")
sim_PCs <- data.frame(PTID = constructs_fMRI$PTID, res_sim.pca[["x"]][,1:5])
colnames(sim_PCs)[2:6] <- paste("PC",c(1:5),"_sim",sep="")
MVPA_PCs <- data.frame(PTID = constructs_fMRI$PTID, res_MVPA.pca[["x"]][,1:12])
colnames(MVPA_PCs)[2:13] <- paste("PC",c(1:12),"_MVPA",sep="")
EEG_PCs <- data.frame(PTID = EEG_df$PTID[complete.cases(EEG_df)], res_EEG.pca[["x"]][,1:11])
colnames(EEG_PCs)[2:12] <- paste("PC",c(1:11),"_EEG",sep="")
RS_PCs <- data.frame(PTID = RS_df$PTID, res_RS.pca[["x"]][,1:8])
colnames(RS_PCs)[2:9] <- paste("PC",c(1:8),"_RS",sep="")
struc_PCs <- data.frame(PTID=struc_df$ID, res_struct.pca[["x"]][,1:19])
colnames(struc_PCs)[2:20] <- paste("PC",c(1:19),"_struc",sep="")
FA_PCs <- data.frame(PTID = FA_Data$ID, res_FA.pca[["x"]][,1:5])
colnames(FA_PCs)[2:6] <- paste("PC", c(1:5), "_FA", sep="")

reg_data <- Reduce(function(x,y) merge(x=x, y=y, by = "PTID", all.x = TRUE), 
                   list(reg_data, univ_PCs, sim_PCs, MVPA_PCs, EEG_PCs, RS_PCs, struc_PCs, FA_PCs))

#add scanner, age, gender (won't include CS/NCS in regression) and dummy code 
reg_data <- merge(reg_data, p200_demographics, by = "PTID")
reg_data$SCANNER <- reg_data$SCANNER - 1
reg_data$GENDER <- reg_data$GENDER - 1

reg_data <- reg_data[complete.cases(reg_data),1:70]

set.seed(123)
lambda <- 10^seq(-3, 3, length = 100)

# save(list = c("univ_PCs", "sim_PCs", "MVPA_PCs", "EEG_PCs", "RS_PCs", "struc_PCs", "FA_PCs"), file = "~/Documents/Code/RDoC_for_GitHub/data/PCs.RData")

```


## Stepwise Regression 

While the final stepwise model is significant overall, we see significant effects of: 

+ __PC3_univ:__ encoding - delay in parietal regions and fusiform activity during delay 
+ __PC5_MVPA:__ Fusiform encoding during template -- most variance comes from high incorrect trials during individual trials
+ __PC8_MVPA:__ High incorrect DFR across entire trial from individual trials 
+ __PC12_MVPA:__ Mostly correct trials from templates in the fusiform - most variance explained by encoding and probe 
+ __PC2_EEG:__ ERSPs at probe during low load trials; specifically, low gamma  
+ __PC3_EEG:__ Alpha power at delay, beta during cue 
+ __PC6_EEG:__ N170 amplitude and high load Oz power across frequency band 
+ __PC8_EEG:__ Low gamma in mid occipital component 
+ __PC9_EEG:__ P3 component
+ __PC1_RS:__ Participation coefficients across network (both average and individual network)
+ __PC2_RS:__ FPCN connectivity with other networks, within connectivity for DMN and DAN 
+ __PC2_FA:__ Cingulum/hippocampus 
+ __PC4_struct:__ Temporal pole, entorhinal 
+ __PC6_struct:__ corpus callosum, caudate
+ __PC12_struct:__ Temporal, entorhinal, parahippocampal
+ __PC15_struct:__ left hemisphere subcortical, pars triangularis
+ Scanner
+ Gender
+ Age


```{r stepwise - span}

# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_step_span <- list()
RMSE_cv_step_span <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(2, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(2, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  
  step.span <- train(span ~., data = train_data,
                     method = "lmStepAIC", 
                     trControl = trainControl("cv", number = 10),
                     trace = FALSE
  )
  best_models_step_span[[fold]] <- step.span$finalModel
  preds <- step.span %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_step_span <- data.frame(true = test_data$span, pred = preds)
  }else{ 
    cv_preds_step_span <- rbind(cv_preds_step_span, data.frame(true = test_data$span, pred = preds))}
  
  RMSE_cv_step_span[fold] <- RMSE(preds, test_data$span)
  
}

```

```{r set up model coefficient comparison list}

model_comparison_template <- list(univ = data.frame(matrix(nrow=10, ncol=3)), 
                                  sim = data.frame(matrix(nrow=10, ncol=5)), 
                                  MVPA = data.frame(matrix(nrow=10, ncol=12)), 
                                  EEG = data.frame(matrix(nrow=10, ncol=11)), 
                                  RS = data.frame(matrix(nrow=10, ncol=8)), 
                                  FA = data.frame(matrix(nrow=10, ncol=5)), 
                                  struc = data.frame(matrix(nrow=10, ncol=19)), 
                                  demo = data.frame(matrix(nrow=10, ncol=3)))

colnames(model_comparison_template[["univ"]]) <- paste("PC",c(1:3),"_univ",sep="")
colnames(model_comparison_template[["sim"]]) <- paste("PC",c(1:5),"_sim",sep="")
colnames(model_comparison_template[["MVPA"]]) <- paste("PC",c(1:12),"_MVPA",sep="")
colnames(model_comparison_template[["EEG"]]) <- paste("PC",c(1:11),"_EEG",sep="")
colnames(model_comparison_template[["RS"]]) <- paste("PC",c(1:8),"_RS",sep="")
colnames(model_comparison_template[["struc"]]) <- paste("PC",c(1:19),"_struc",sep="")
colnames(model_comparison_template[["FA"]]) <- paste("PC", c(1:5), "_FA", sep="")
colnames(model_comparison_template[["demo"]]) <- c("GENDER", "AGE", "SCANNER")


```


```{r compare model comparison - step span}

step_span_best_coeffs <- model_comparison_template

for (fold in seq.int(1,10)){ 
  coefs <- rownames(data.frame(best_models_step_span[[fold]]$coefficients))
  split_coef <- strsplit(coefs, split="_")
  for (row in seq.int(2,length(coefs))){
    if (length(split_coef[[row]]) > 1){
      PC <- as.numeric(strsplit(split_coef[[row]][[1]], split="PC")[[1]][[2]])
      step_span_best_coeffs[[split_coef[[row]][[2]]]][fold,PC] <- "x"
    }
  }
  
  if ("GENDER" %in% coefs){
    step_span_best_coeffs[["demo"]]$GENDER <- "x"
  }
  if ("AGE" %in% coefs){
    step_span_best_coeffs[["demo"]]$AGE <- "x"
  }
  if ("SCANNER" %in% coefs){
    step_span_best_coeffs[["demo"]]$SCANNER <- "x"
  }
}

```


```{r create comparisons - span}

compare_span <- data.frame(matrix(nrow=2, ncol=4))
colnames(compare_span) <- c("stepwise", "ridge", "lasso", "elastic")
rownames(compare_span) <- c("RMSE", "Rsquared")

compare_span$stepwise[1] <- rowMeans(RMSE_cv_step_span)
compare_span$stepwise[2] <- cor(cv_preds_step_span$true, cv_preds_step_span$pred)^2

```


## Ridge Regression 

```{r ridge - span}

# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_ridge_span <- list()
RMSE_cv_ridge_span <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(2, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(2, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  ridge.span <- train(
    span ~., data = train_data, method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneGrid = expand.grid(alpha = 0, lambda = lambda)
  )
  best_models_ridge_span[[fold]] <- coef(ridge.span$finalModel, ridge.span$bestTune$lambda)
  preds <- ridge.span %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_ridge_span <- data.frame(true = test_data$span, pred = preds)
  }else{ 
    cv_preds_ridge_span <- rbind(cv_preds_ridge_span, data.frame(true = test_data$span, pred = preds))}
  
  RMSE_cv_ridge_span[fold] <- RMSE(preds, test_data$span)
  
}

compare_span$ridge[1] <- rowMeans(RMSE_cv_ridge_span)
compare_span$ridge[2] <- cor(cv_preds_ridge_span$true, cv_preds_ridge_span$pred)^2


```

## LASSO Regression

In the LASSO regression, we see: 

+ __PC1_univ:__ encoding load effects and the combined encoding+encoding-delay in the PFC regions. This value is negative, suggesting that stronger load effects is related to lower span
+ __PC1_sim:__ Similarity within trial 
+ __PC3_MVPA:__ DFR during probe, averages from template across trial type
+ __PC2_EEG:__ ERSPs at probe during low load trials; specifically, low gamma  
+ __PC3_EEG:__ Alpha power at delay, beta during cue 
+ __PC6_EEG:__ N170 amplitude and high load Oz power across frequency band 
+ __PC9_EEG:__ P3 component
+ __PC2_FA:__ Cingulum/hippocampus 
+ __PC5_FA:__ Superior longitudinal fasiculus in temporal lobe in the right hemisphere and cingulum
+ __PC13_struct:__ Temporal pole, temporal cortex, amygdala and HPC
+ __PC15_struct:__ left hemisphere subcortical, pars triangularis
+ Scanner
+ Age
+ Gender


```{r lasso - span}

# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_lasso_span <- list()
RMSE_cv_lasso_span <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(2, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(2, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  lasso.span <- train(
    span ~., data =train_data, method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneGrid = expand.grid(alpha = 1, lambda = lambda)
  )
  best_models_lasso_span[[fold]] <- coef(lasso.span$finalModel, lasso.span$bestTune$lambda)
  preds <- lasso.span %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_lasso_span <- data.frame(true = test_data$span, pred = preds)
  }else{ 
    cv_preds_lasso_span <- rbind(cv_preds_lasso_span, data.frame(true = test_data$span, pred = preds))}
  
  RMSE_cv_lasso_span[fold] <- RMSE(preds, test_data$span)
  
}

compare_span$lasso[1] <- rowMeans(RMSE_cv_lasso_span)
compare_span$lasso[2] <- cor(cv_preds_lasso_span$true, cv_preds_lasso_span$pred)^2


```

```{r compare model comparison - lasso span}

lasso_span_best_coeffs <- model_comparison_template

for (fold in seq.int(1,10)){ 
  coefs <- rownames(best_models_lasso_span[[fold]])
  split_coef <- strsplit(coefs, split="_")
  for (row in seq.int(2,length(coefs))){
    if (length(split_coef[[row]]) > 1){
      PC <- as.numeric(strsplit(split_coef[[row]][[1]], split="PC")[[1]][[2]])
      if (best_models_lasso_span[[fold]][row]!= 0){
        lasso_span_best_coeffs[[split_coef[[row]][[2]]]][fold,PC] <- "x"
      }
    }
  }
  
  if ("GENDER" %in% coefs){
    lasso_span_best_coeffs[["demo"]]$GENDER <- "x"
  }
  if ("AGE" %in% coefs){
    lasso_span_best_coeffs[["demo"]]$AGE <- "x"
  }
  if ("SCANNER" %in% coefs){
    lasso_span_best_coeffs[["demo"]]$SCANNER <- "x"
  }
}

```


## ElasticNet

+ __PC1_univ:__ encoding load effects and the combined encoding+encoding-delay in the PFC regions. This value is negative, suggesting that stronger load effects is related to lower span
+ __PC1_sim:__ Similarity within trial 
+ __PC3_sim:__ High load correct trials in DFR, encoding to correct delay trials in high load correct trials in fusiform
+ __PC3_MVPA:__ DFR during probe, averages from template across trial type
+ __PC4_MVPA:__ Delay period decoding 
+ __PC11_MVPA:__ Low correct trials, mostly delay period after largest variance explained from fusiform during encoding
+ __PC12_MVPA:__ Mostly correct trials from templates in the fusiform - most variance explained by encoding and probe 
+ __PC2_EEG:__ ERSPs at probe during low load trials; specifically, low gamma  
+ __PC3_EEG:__ Alpha power at delay, beta during cue 
+ __PC5_EEG:__ Theta power 
+ __PC6_EEG:__ N170 amplitude and high load Oz power across frequency band 
+ __PC9_EEG:__ P3 component
+ __PC1_RS:__ Participation coefficients across network (both average and individual network)
+ __PC4_RS:__ Global efficiency, within CO connectivity, participation coefficients
+ __PC2_FA:__ Cingulum/hippocampus 
+ __PC5_FA:__ Superior longitudinal fasiculus in temporal lobe in the right hemisphere and cingulum
+ __PC13_struct:__ Temporal pole, temporal cortex, amygdala and HPC
+ __PC15_struct:__ left hemisphere subcortical, pars triangularis
+ __PC16_struct__ Temporal, orbitofrontal , frontal pole
+ Scanner
+ Age
+ Gender

It seems as though these are particularly weighted towards encoding and regions associated with visual processing. Structural seems to show some HPC involvement. While accuracy seems to be only weighted towards visual components, predicting span also includes measures at low load, from the delay period, and all modalities. 


```{r elastic net - span}

# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_elastic_span <- list()
RMSE_cv_elastic_span <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(2, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(2, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  
  elastic.span <- train(
    span ~., data = train_data, method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneLength = 10
  )
  best_models_elastic_span[[fold]] <- elastic.span$finalModel
  preds <- elastic.span %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_elastic_span <- data.frame(true = test_data$span, pred = preds)
  }else{ 
    cv_preds_elastic_span <- rbind(cv_preds_elastic_span, data.frame(true = test_data$span, pred = preds))}
  
  RMSE_cv_elastic_span[fold] <- RMSE(preds, test_data$span)
  
}

compare_span$elastic[1] <- rowMeans(RMSE_cv_elastic_span)
compare_span$elastic[2] <- cor(cv_preds_elastic_span$true, cv_preds_elastic_span$pred)^2

```

```{r compare model comparison - elastic span}

elastic_span_best_coeffs <- model_comparison_template

for (fold in seq.int(1,10)){ 
  coefs <- coef(best_models_elastic_span[[fold]], s = best_models_elastic_span[[fold]]$tuneValue$lambda)
  split_coef <- strsplit(rownames(coefs), split="_")
  for (row in seq.int(2,length(coefs))){
    if (length(split_coef[[row]]) > 1){
      PC <- as.numeric(strsplit(split_coef[[row]][[1]], split="PC")[[1]][[2]])
      if (coefs[row]!= 0){
        elastic_span_best_coeffs[[split_coef[[row]][[2]]]][fold,PC] <- "x"
      }
    }
  }
  
  if ("GENDER" %in% rownames(coefs)){
    elastic_span_best_coeffs[["demo"]]$GENDER <- "x"
  }
  if ("AGE" %in% rownames(coefs)){
    elastic_span_best_coeffs[["demo"]]$AGE <- "x"
  }
  if ("SCANNER" %in% rownames(coefs)){
    elastic_span_best_coeffs[["demo"]]$SCANNER <- "x"
  }
}

```

## Compare Models

When comparing models, LASSO is our best model that contains feature selection, explaining ~9% of the variance in span.
Ridge regression does slightly better, explaining 11% of the variance. 

```{r compare models - span}
compare_span
```

# Predicting BPRS

## Stepwise regression

To predict BPRS, we see the PCs that contain important information are: 

+ __PC3_univ:__ encoding - delay in parietal regions and fusiform activity during delay 
+ __PC1_sim:__ Similarity within trial 
+ __PC5_MVPA:__ Fusiform encoding during template -- most variance comes from high incorrect trials during individual trials
+ __PC1_EEG:__ Alpha and beta at high load during probe 
+ __PC7_EEG:__ P3, n170 amplitude; low gamma 
+ __PC11_EEG:__ Oz at low load, mid occipital at high load 
+ __PC4_RS:__ Global efficiency, within CO connectivity, participation coefficients
+ __PC2_FA:__ Cingulum/hippocampus 
+ __PC3_FA:__ cingulum 
+ __PC5_FA:__ Superior longitudinal fasiculus in temporal lobe in the right hemisphere and cingulum
+ __PC2_struct:__ Subcortical structures (including cerebellum)
+ __PC4_struct:__ Temporal pole, entorhinal 
+ __PC7_struct:__ More subcortical
+ __PC8_struct:__ Frontal pole (and other frontal regions)
+ __PC14_struct:__ pars orbitalis, cingulate, accumbens
+ __PC15_struct:__ left hemisphere subcortical, pars triangularis
+ Age
+ Scanner

```{r stepwise - BPRS}

# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_step_BPRS <- list()
RMSE_cv_step_BPRS <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(4, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(4, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  
  step.BPRS <- train(BPRS ~., data = train_data,
                     method = "lmStepAIC", 
                     trControl = trainControl("cv", number = 10),
                     trace = FALSE
  )
  best_models_step_BPRS[[fold]] <- step.BPRS$finalModel
  preds <- step.BPRS %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_step_BPRS <- data.frame(true = test_data$BPRS, pred = preds)
  }else{ 
    cv_preds_step_BPRS <- rbind(cv_preds_step_BPRS, data.frame(true = test_data$BPRS, pred = preds))}
  
  RMSE_cv_step_BPRS[fold] <- RMSE(preds, test_data$BPRS)
  
}

```

```{r compare model comparison - step BPRS}

step_BPRS_best_coeffs <- model_comparison_template

for (fold in seq.int(1,10)){ 
  coefs <- rownames(data.frame(best_models_step_BPRS[[fold]]$coefficients))
  split_coef <- strsplit(coefs, split="_")
  for (row in seq.int(2,length(coefs))){
    if (length(split_coef[[row]]) > 1){
      PC <- as.numeric(strsplit(split_coef[[row]][[1]], split="PC")[[1]][[2]])
      step_BPRS_best_coeffs[[split_coef[[row]][[2]]]][fold,PC] <- "x"
    }
  }
  
  if ("GENDER" %in% coefs){
    step_BPRS_best_coeffs[["demo"]]$GENDER <- "x"
  }
  if ("AGE" %in% coefs){
    step_BPRS_best_coeffs[["demo"]]$AGE <- "x"
  }
  if ("SCANNER" %in% coefs){
    step_BPRS_best_coeffs[["demo"]]$SCANNER <- "x"
  }
}

```

```{r create comparisons - BPRS}

compare_BPRS <- data.frame(matrix(nrow=2, ncol=4))
colnames(compare_BPRS) <- c("stepwise", "ridge", "lasso", "elastic")
rownames(compare_BPRS) <- c("RMSE", "Rsquared")

compare_BPRS$stepwise[1] <- rowMeans(RMSE_cv_step_BPRS)
compare_BPRS$stepwise[2] <- cor(cv_preds_step_BPRS$true, cv_preds_step_BPRS$pred)^2

```

## Ridge Regression

```{r ridge - BPRS}

# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_ridge_BPRS <- list()
RMSE_cv_ridge_BPRS <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(4, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(4, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  ridge.BPRS <- train(
    BPRS ~., data = train_data, method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneGrid = expand.grid(alpha = 0, lambda = lambda)
  )
  best_models_ridge_BPRS[[fold]] <- coef(ridge.BPRS$finalModel, ridge.BPRS$bestTune$lambda)
  preds <- ridge.BPRS %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_ridge_BPRS <- data.frame(true = test_data$BPRS, pred = preds)
  }else{ 
    cv_preds_ridge_BPRS <- rbind(cv_preds_ridge_BPRS, data.frame(true = test_data$BPRS, pred = preds))}
  
  RMSE_cv_ridge_BPRS[fold] <- RMSE(preds, test_data$BPRS)
  
}

compare_BPRS$ridge[1] <- rowMeans(RMSE_cv_ridge_BPRS)
compare_BPRS$ridge[2] <- cor(cv_preds_ridge_BPRS$true, cv_preds_ridge_BPRS$pred)^2

```

## LASSO Regression

LASSO gives us almost a combination of the above analyses: 

+ __PC7_EEG:__ P3, n170 amplitude; low gamma 
+ __PC5_RS:__ Within visual connectivity and participation coefficient, within CO connectivity 
+ __PC7_struct:__ More subcortical
+ __PC14_struct:__ pars orbitalis, cingulate, accumbens
+ __PC15_struct:__ left hemisphere subcortical, pars triangularis
+ Gender
+ Age
+ Scanner


```{r lasso - BPRS}


# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_lasso_BPRS <- list()
RMSE_cv_lasso_BPRS <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(4, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(4, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  lasso.BPRS <- train(
    BPRS ~., data =train_data, method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneGrid = expand.grid(alpha = 1, lambda = lambda)
  )
  best_models_lasso_BPRS[[fold]] <- coef(lasso.BPRS$finalModel, lasso.BPRS$bestTune$lambda)
  preds <- lasso.BPRS %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_lasso_BPRS <- data.frame(true = test_data$BPRS, pred = preds)
  }else{ 
    cv_preds_lasso_BPRS <- rbind(cv_preds_lasso_BPRS, data.frame(true = test_data$BPRS, pred = preds))}
  
  RMSE_cv_lasso_BPRS[fold] <- RMSE(preds, test_data$BPRS)
  
}

compare_BPRS$lasso[1] <- rowMeans(RMSE_cv_lasso_BPRS)
compare_BPRS$lasso[2] <- cor(cv_preds_lasso_BPRS$true, cv_preds_lasso_BPRS$pred)^2

```

```{r compare model comparison - lasso BPRS}

lasso_BPRS_best_coeffs <- model_comparison_template

for (fold in seq.int(1,10)){ 
  coefs <- rownames(best_models_lasso_BPRS[[fold]])
  split_coef <- strsplit(coefs, split="_")
  for (row in seq.int(2,length(coefs))){
    if (length(split_coef[[row]]) > 1){
      PC <- as.numeric(strsplit(split_coef[[row]][[1]], split="PC")[[1]][[2]])
      if (best_models_lasso_BPRS[[fold]][row]!= 0){
        lasso_BPRS_best_coeffs[[split_coef[[row]][[2]]]][fold,PC] <- "x"
      }
    }
  }
  
  if ("GENDER" %in% coefs){
    lasso_BPRS_best_coeffs[["demo"]]$GENDER <- "x"
  }
  if ("AGE" %in% coefs){
    lasso_BPRS_best_coeffs[["demo"]]$AGE <- "x"
  }
  if ("SCANNER" %in% coefs){
    lasso_BPRS_best_coeffs[["demo"]]$SCANNER <- "x"
  }
}

```

## ElasticNet

+ __PC3_sim:__ High load correct trials in DFR, encoding to correct delay trials in high load correct trials in fusiform
+ __PC7_MVPA:__ Individual trials, low correct and high incorrect, but most variance comes from high incorrect trials in fusiform during delay from averages 
+ __PC1_EEG:__ Alpha and beta at high load during probe 
+ __PC7_EEG:__ P3, n170 amplitude; low gamma 
+ __PC9_EEG:__ P3 component
+ __PC5_RS:__ Within visual connectivity and participation coefficient, within CO connectivity 
+ __PC4_struct:__ Temporal pole, entorhinal 
+ __PC7_struct:__ More subcortical
+ __PC14_struct:__ pars orbitalis, cingulate, accumbens
+ __PC15_struct:__ left hemisphere subcortical, pars triangularis
+ Gender
+ Age
+ Scanner

```{r elastic net - BPRS}
# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_elastic_BPRS <- list()
RMSE_cv_elastic_BPRS <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(4, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(4, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  
  elastic.BPRS <- train(
    BPRS ~., data = train_data, method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneLength = 10
  )
  best_models_elastic_BPRS[[fold]] <- elastic.BPRS$finalModel
  preds <- elastic.BPRS %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_elastic_BPRS <- data.frame(true = test_data$BPRS, pred = preds)
  }else{ 
    cv_preds_elastic_BPRS <- rbind(cv_preds_elastic_BPRS, data.frame(true = test_data$BPRS, pred = preds))}
  
  RMSE_cv_elastic_BPRS[fold] <- RMSE(preds, test_data$BPRS)
  
}

compare_BPRS$elastic[1] <- rowMeans(RMSE_cv_elastic_BPRS)
compare_BPRS$elastic[2] <- cor(cv_preds_elastic_BPRS$true, cv_preds_elastic_BPRS$pred)^2


```

```{r compare model comparison - elastic BPRS}

elastic_BPRS_best_coeffs <- model_comparison_template

for (fold in seq.int(1,10)){ 
  coefs <- coef(best_models_elastic_BPRS[[fold]], s = best_models_elastic_BPRS[[fold]]$tuneValue$lambda)
  split_coef <- strsplit(rownames(coefs), split="_")
  for (row in seq.int(2,length(coefs))){
    if (length(split_coef[[row]]) > 1){
      PC <- as.numeric(strsplit(split_coef[[row]][[1]], split="PC")[[1]][[2]])
      if (coefs[row]!= 0){
        elastic_BPRS_best_coeffs[[split_coef[[row]][[2]]]][fold,PC] <- "x"
      }
    }
  }
  
  if ("GENDER" %in% rownames(coefs)){
    elastic_BPRS_best_coeffs[["demo"]]$GENDER <- "x"
  }
  if ("AGE" %in% rownames(coefs)){
    elastic_BPRS_best_coeffs[["demo"]]$AGE <- "x"
  }
  if ("SCANNER" %in% rownames(coefs)){
    elastic_BPRS_best_coeffs[["demo"]]$SCANNER <- "x"
  }
}

```

## Compare Models

Here, stepwise regression is the best model that performs feature selection - it explains 9% of the variance in BPRS, although it does have the highest RMSE. Again, Ridge explains the most variance (10%). 

```{r compare models - BPRS}

compare_BPRS
```

# Predicting Accuracy 

## Stepwise regression

+ __PC1_univ:__ encoding load effects and the combined encoding+encoding-delay in the PFC regions
+ __PC2_univ:__ delay load effect
+ __PC3_univ:__ encoding - delay in parietal regions and fusiform activity during delay 
+ __PC1_sim:__ Similarity within trial 
+ __PC2_MVPA:__ DFR during encoding 
+ __PC4_EEG:__ Low gamma 
+ __PC6_EEG:__ N170 amplitude and high load Oz power across frequency band 
+ __PC9_EEG:__ P3 component
+ __PC11_EEG:__ Oz at low load, mid occipital at high load 
+ __PC3_FA:__ cingulum 
+ __PC2_struct:__ Subcortical structures (including cerebellum)
+ Gender
+ Age
+ Scanner

```{r stepwise - high acc}

# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_step_high_acc <- list()
RMSE_cv_step_high_acc <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(3, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(3, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  
  step.high_acc <- train(high_acc ~., data = train_data,
                         method = "lmStepAIC", 
                         trControl = trainControl("cv", number = 10),
                         trace = FALSE
  )
  best_models_step_high_acc[[fold]] <- step.high_acc$finalModel
  preds <- step.high_acc %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_step_high_acc <- data.frame(true = test_data$high_acc, pred = preds)
  }else{ 
    cv_preds_step_high_acc <- rbind(cv_preds_step_high_acc, data.frame(true = test_data$high_acc, pred = preds))}
  
  RMSE_cv_step_high_acc[fold] <- RMSE(preds, test_data$high_acc)
  
}

```

```{r compare model comparison - step high_acc}

step_high_acc_best_coeffs <- model_comparison_template

for (fold in seq.int(1,10)){ 
  coefs <- rownames(data.frame(best_models_step_high_acc[[fold]]$coefficients))
  split_coef <- strsplit(coefs, split="_")
  for (row in seq.int(2,length(coefs))){
    if (length(split_coef[[row]]) > 1){
      PC <- as.numeric(strsplit(split_coef[[row]][[1]], split="PC")[[1]][[2]])
      step_high_acc_best_coeffs[[split_coef[[row]][[2]]]][fold,PC] <- "x"
    }
  }
  
  if ("GENDER" %in% coefs){
    step_high_acc_best_coeffs[["demo"]]$GENDER <- "x"
  }
  if ("AGE" %in% coefs){
    step_high_acc_best_coeffs[["demo"]]$AGE <- "x"
  }
  if ("SCANNER" %in% coefs){
    step_high_acc_best_coeffs[["demo"]]$SCANNER <- "x"
  }
}

```

```{r create comparisons - high_acc}

compare_high_acc <- data.frame(matrix(nrow=2, ncol=4))
colnames(compare_high_acc) <- c("stepwise", "ridge", "lasso", "elastic")
rownames(compare_high_acc) <- c("RMSE", "Rsquared")

compare_high_acc$stepwise[1] <- rowMeans(RMSE_cv_step_high_acc)
compare_high_acc$stepwise[2] <- cor(cv_preds_step_high_acc$true, cv_preds_step_high_acc$pred)^2

```

## Ridge regression

```{r ridge - high_acc}


# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_ridge_high_acc <- list()
RMSE_cv_high_acc <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(3, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(3, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  ridge.high_acc <- train(
    high_acc ~., data = train_data, method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneGrid = expand.grid(alpha = 0, lambda = lambda)
  )
  best_models_ridge_high_acc[[fold]] <- coef(ridge.high_acc$finalModel, ridge.high_acc$bestTune$lambda)
  preds <- ridge.high_acc %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_high_acc <- data.frame(true = test_data$high_acc, pred = preds)
  }else{ 
    cv_preds_high_acc <- rbind(cv_preds_high_acc, data.frame(true = test_data$high_acc, pred = preds))}
  
  RMSE_cv_high_acc[fold] <- RMSE(preds, test_data$high_acc)
  
}

compare_high_acc$ridge[1] <- rowMeans(RMSE_cv_high_acc)
compare_high_acc$ridge[2] <- cor(cv_preds_high_acc$true, cv_preds_high_acc$pred)^2

```

## LASSO Regression

+ __PC1_univ:__ encoding load effects and the combined encoding+encoding-delay in the PFC regions
+ __PC2_univ:__ delay load effect
+ __PC3_univ:__ encoding - delay in parietal regions and fusiform activity during delay 
+ __PC1_sim:__ Similarity within trial 
+ __PC5_MVPA:__ Fusiform encoding during template -- most variance comes from high incorrect trials during individual trials
+ __PC10_MVPA:__ Correct averaged from template trials during delay and probe - mostly DFR during probe 
+ __PC12_MVPA:__ Mostly correct trials from templates in the fusiform - most variance explained by encoding and probe 
+ __PC2_EEG:__ ERSPs at probe during low load trials; specifically, low gamma  
+ __PC4_EEG:__ Low gamma 
+ __PC6_EEG:__ N170 amplitude and high load Oz power across frequency band 
+ __PC7_EEG:__ P3, n170 amplitude; low gamma 
+ __PC9_EEG:__ P3 component
+ __PC11_EEG:__ Oz at low load, mid occipital at high load 
+ __PC2_struct:__ Subcortical structures (including cerebellum)
+ __PC3_struct:__ Cuneus, pericalcarine, superior parietal, lingual 
+ __PC17_struct:__ banks sts, some temporal and parietal cortex
+ Gender
+ Age
+ Scanner


```{r lasso - high_acc}


# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_lasso_high_acc <- list()
RMSE_cv_lasso_high_acc <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(3, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(3, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  lasso.high_acc <- train(
    high_acc ~., data =train_data, method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneGrid = expand.grid(alpha = 1, lambda = lambda)
  )
  best_models_lasso_high_acc[[fold]] <- coef(lasso.high_acc$finalModel, lasso.high_acc$bestTune$lambda)
  preds <- lasso.high_acc %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_lasso_high_acc <- data.frame(true = test_data$high_acc, pred = preds)
  }else{ 
    cv_preds_lasso_high_acc <- rbind(cv_preds_lasso_high_acc, data.frame(true = test_data$high_acc, pred = preds))}
  
  RMSE_cv_lasso_high_acc[fold] <- RMSE(preds, test_data$high_acc)
  
}
compare_high_acc$lasso[1] <- rowMeans(RMSE_cv_lasso_high_acc)
compare_high_acc$lasso[2] <- cor(cv_preds_lasso_high_acc$true, cv_preds_lasso_high_acc$pred)^2


```

```{r compare model comparison - lasso high_acc}

lasso_high_acc_best_coeffs <- model_comparison_template

for (fold in seq.int(1,10)){ 
  coefs <- rownames(best_models_lasso_high_acc[[fold]])
  split_coef <- strsplit(coefs, split="_")
  for (row in seq.int(2,length(coefs))){
    if (length(split_coef[[row]]) > 1){
      PC <- as.numeric(strsplit(split_coef[[row]][[1]], split="PC")[[1]][[2]])
      if (best_models_lasso_high_acc[[fold]][row]!= 0){
        lasso_high_acc_best_coeffs[[split_coef[[row]][[2]]]][fold,PC] <- "x"
      }
    }
  }
  
  if ("GENDER" %in% coefs){
    lasso_high_acc_best_coeffs[["demo"]]$GENDER <- "x"
  }
  if ("AGE" %in% coefs){
    lasso_high_acc_best_coeffs[["demo"]]$AGE <- "x"
  }
  if ("SCANNER" %in% coefs){
    lasso_high_acc_best_coeffs[["demo"]]$SCANNER <- "x"
  }
}

```

## Elastic Net

When we look at ElasticNet, all coefficients play a role. The most important ones seem to be: 

+ __PC1_univ:__ encoding load effects and the combined encoding+encoding-delay in the PFC regions
+ __PC2_univ:__ delay load effect
+ __PC3_univ:__ encoding - delay in parietal regions and fusiform activity during delay 
+ __PC1_sim:__ Similarity within trial 
+ __PC5_sim:__ Correlation within low correct and high incorrect trials in DFR mask 
+ __PC5_MVPA:__ Fusiform encoding during template -- most variance comes from high incorrect trials during individual trials
+ __PC10_MVPA:__ Correct averaged from template trials during delay and probe - mostly DFR during probe 
+ __PC12_MVPA:__ Mostly correct trials from templates in the fusiform - most variance explained by encoding and probe 
+ __PC2_EEG:__ ERSPs at probe during low load trials; specifically, low gamma  
+ __PC4_EEG:__ Low gamma 
+ __PC6_EEG:__ N170 amplitude and high load Oz power across frequency band 
+ __PC7_EEG:__ P3, n170 amplitude; low gamma 
+ __PC9_EEG:__ P3 component
+ __PC11_EEG:__ Oz at low load, mid occipital at high load 
+ __PC2_struct:__ Subcortical structures (including cerebellum)
+ __PC3_struct:__ Cuneus, pericalcarine, superior parietal, lingual 
+ __PC17_struct:__ banks sts, some temporal and parietal cortex
+ Gender
+ Scanner
+ Age 

```{r elastic net - high_acc}

# set up outer cross validation 
split <- vfold_cv(reg_data,v=10)

best_models_elastic_high_acc <- list()
RMSE_cv_elastic_high_acc <- data.frame(matrix(ncol=10, nrow=1))

for (fold in seq.int(1,10)){ 
  
  # set up training and test set for fold
  train_data <-  analysis(split$splits[[fold]])
  train_data <- train_data[,c(3, 5:70)]
  test_data <- assessment(split$splits[[fold]])
  test_data <- test_data[,c(3, 5:70)]
  train_data[,1:67] <- sapply(train_data[,1:67],scale)
  train_data <- data.frame(train_data)
  test_data[,1:67] <- sapply(test_data[,1:67], scale)
  test_data <- data.frame(test_data)
  
  elastic.high_acc <- train(
    high_acc ~., data = train_data, method = "glmnet",
    trControl = trainControl("cv", number = 10),
    tuneLength = 10
  )
  best_models_elastic_high_acc[[fold]] <- elastic.high_acc$finalModel
  preds <- elastic.high_acc %>% predict(test_data)
  
  # Make predictions
  if (fold == 1){ 
    cv_preds_elastic_high_acc <- data.frame(true = test_data$high_acc, pred = preds)
  }else{ 
    cv_preds_elastic_high_acc <- rbind(cv_preds_elastic_high_acc, data.frame(true = test_data$high_acc, pred = preds))}
  
  RMSE_cv_elastic_high_acc[fold] <- RMSE(preds, test_data$high_acc)
  
}

compare_high_acc$elastic[1] <- rowMeans(RMSE_cv_elastic_high_acc)
compare_high_acc$elastic[2] <- cor(cv_preds_elastic_high_acc$true, cv_preds_elastic_high_acc$pred)^2

```

```{r compare model comparison - elastic high_acc}

elastic_high_acc_best_coeffs <- model_comparison_template

for (fold in seq.int(1,10)){ 
  coefs <- coef(best_models_elastic_high_acc[[fold]], s = best_models_elastic_high_acc[[fold]]$tuneValue$lambda)
  split_coef <- strsplit(rownames(coefs), split="_")
  for (row in seq.int(2,length(coefs))){
    if (length(split_coef[[row]]) > 1){
      PC <- as.numeric(strsplit(split_coef[[row]][[1]], split="PC")[[1]][[2]])
      if (coefs[row]!= 0){
        elastic_high_acc_best_coeffs[[split_coef[[row]][[2]]]][fold,PC] <- "x"
      }
    }
  }
  
  if ("GENDER" %in% rownames(coefs)){
    elastic_high_acc_best_coeffs[["demo"]]$GENDER <- "x"
  }
  if ("AGE" %in% rownames(coefs)){
    elastic_high_acc_best_coeffs[["demo"]]$AGE <- "x"
  }
  if ("SCANNER" %in% rownames(coefs)){
    elastic_high_acc_best_coeffs[["demo"]]$SCANNER <- "x"
  }
}

```

## Compare models

Here, ElasticNet is our best model with feature selection, explaining 12% of variance in accuracy at high load. Just as in the previous behavioral measures, Ridge regression performs best, explaining 14% of the variance. 

```{r compare models - high_acc}

compare_high_acc

```

