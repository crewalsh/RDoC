---
title: "MVPA in fusiform with unsmoothed data"
author: "Catherine Walsh"
date: "5/7/2020"
output:
  html_document:
    toc: true 
    toc_float: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Another potentially interesting question we can try to answer is how much face representation we see across the task. In order to do so, we've trained a linear SVM classifier within subjects on the data from the UNSMOOTHED FFA localizer to classify signal into faces, objects and scrambles. We can then apply that classifier to various facets of our data. For each of these analyses, we will look at the probability of the classifier predicting a face. If the classifier does indeed predict a face, we score that TR with a "1", otherwise, it gets a "0", meaning chance becomes 1/3 = .33. 

First, we will apply it to each TR of individual trials. Trials are split into 4 bins based on accuracy and load, and averaged over those measures to create a single time course for each category. The classifier was also applied to each TR of a "template" for each condition. In this analysis, all trials in a given condition were averaged to create a prototypical example for the category. The classifier was then applied to those averages. 

We can then look at the probability of classification across subjects. First, we look at it across all subjects, but then we can look at it across our working memory capacity groups. 

Finally, we will relate these neural measures to behavior, both averaged over time and for each TR. 

```{r import packages, data etc}

library(reshape2)
library(tidyverse)
library(patchwork)

load('data/behav.RData')
load('data/split_groups_info.RData')
load('data/DFR_split_groups_info.RData')

source("helper_fxns/split_into_groups.R")
source('helper_fxns/prep_trial_levels_for_plot.R')
source("helper_fxns/split_trial_type.R")

se <- function(x) {
  sd(x,na.rm=TRUE)/sqrt(length(x[!is.na(x)])) 
}

```

```{r load in data}

#classifier information
clf_acc <- read.csv('data/MVPA/fusiform_unsmoothed/clf_acc.csv')
best_c <- read.csv('data/MVPA/fusiform_unsmoothed/best_C.csv')

# averaages from template 
averages_from_template <- list(high_correct = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_high_correct_avg.csv',header=FALSE), 
                               high_incorrect = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_high_incorrect_avg.csv',header=FALSE), 
                               low_correct = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_low_correct_avg.csv',header=FALSE), 
                               low_incorrect = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_low_incorrect_avg.csv',header=FALSE))

averages_from_template[["high_load_correct_diff"]] <- averages_from_template[["high_correct"]][,1:14] - averages_from_template[["high_incorrect"]][,1:14]
averages_from_template[["low_load_correct_diff"]] <- averages_from_template[["low_correct"]][,1:14] - averages_from_template[["low_incorrect"]][,1:14]

# averages from individual trials
individual_trial_averages_probs <- list(
  high_correct = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_high_correct_indiv_avg_probs.csv',header=FALSE),
  high_incorrect = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_high_incorrect_indiv_avg_probs.csv',header=FALSE),
  low_correct = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_low_correct_indiv_avg_probs.csv',header=FALSE),
  low_incorrect = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_low_incorrect_indiv_avg_probs.csv',header=FALSE)) 

individual_trial_averages_probs[["high_load_correct_diff"]] <- individual_trial_averages_probs[["high_correct"]][,1:14] - individual_trial_averages_probs[["high_incorrect"]][,1:14]
individual_trial_averages_probs[["low_load_correct_diff"]] <- individual_trial_averages_probs[["low_correct"]][,1:14] - individual_trial_averages_probs[["low_incorrect"]][,1:14]


# averages from individual trials
individual_trial_averages_preds <- list(
  high_correct = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_high_correct_indiv_avg_preds.csv',header=FALSE),
  high_incorrect = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_high_incorrect_indiv_avg_preds.csv',header=FALSE),
  low_correct = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_low_correct_indiv_avg_preds.csv',header=FALSE),
  low_incorrect = read.csv('data/MVPA/fusiform_unsmoothed/all_suj_low_incorrect_indiv_avg_preds.csv',header=FALSE)) 

individual_trial_averages_preds[["high_load_correct_diff"]] <- individual_trial_averages_preds[["high_correct"]][,1:14] - individual_trial_averages_preds[["high_incorrect"]][,1:14]

individual_trial_averages_preds[["low_load_correct_diff"]] <- individual_trial_averages_preds[["low_correct"]][,1:14] - individual_trial_averages_preds[["low_incorrect"]][,1:14]


# replace NaNs with NA, add in PTID  

for (i in seq.int(1,6)){
  for (ii in seq.int(1,14)){
    averages_from_template[[i]][is.nan(averages_from_template[[i]][,ii]),ii] <- NA
    individual_trial_averages_probs[[i]][is.nan(individual_trial_averages_probs[[i]][,ii]),ii] <- NA
    individual_trial_averages_preds[[i]][is.nan(individual_trial_averages_preds[[i]][,ii]),ii] <- NA
    
  }
  averages_from_template[[i]]$PTID <- constructs_fMRI$PTID
  individual_trial_averages_probs[[i]]$PTID <- constructs_fMRI$PTID
  individual_trial_averages_preds[[i]]$PTID <- constructs_fMRI$PTID
  
}

save(list=c("clf_acc", "best_c", "averages_from_template", "individual_trial_averages_probs","individual_trial_averages_preds"), file = "data/MVPA_fusiform_unsmoothed.RData")

```

# Probability of classifying faces 

On average, we were able to classify faces with 79.8% accuracy (statistically significantly different from chance = 0.33). The classifier was trained on data from an independent FFA localizer. Data was masked using a bilateral fusiform mask from the AAL atlas; from that, the top 100 voxels based on the faces vs objects contrast in the overall subject GLM were selected as features for the classifier. The data used to train the classifier were shifted by 4.5 seconds to account for the hemodynamic delay. 

A linear SVM classifer was used; the localizer task was split into 6 blocks of stimuli. These blocks were used in a pre-defined split for cross validation, where one block of each stimulus type was held out as a test set. Data were normalized within the training and test sets separately. Within this training set, another cross validation process was repeated to tune the cost of the model over the values [0.01, 0.1, 1, 10]. The best value of the cost function was used for each cross validation to score the classifier on the test set. The best classifer was also used to predict face presence at each TR during the DFR task. 


```{r calculate classifier average}

clf_acc$average <- rowMeans(clf_acc)
t.test(clf_acc$average,mu=0.33)

```

```{r average over all subjects}

template_preds_melt <- prep_trial_levels_for_plot(averages_from_template)
individual_trial_probs_melt <- prep_trial_levels_for_plot(individual_trial_averages_probs)
individual_trial_preds_melt <- prep_trial_levels_for_plot(individual_trial_averages_preds)

```

## All subjects

It's good to see here that the probability of classifying a face in this task more or less tracks with our task structure - we see increased probability of classification when there are faces on the screen (ie during encoding and probe). Interestingly, the probability of classifying a face during the delay period is less than chance accuracy. 

### From individual trials 

There is significantly higher likelihood of decoding a face during encoding in high load trials than low load trials. 

```{r plot individual trial avgs for all subjects}

ggplot(data=individual_trial_probs_melt %>% filter(level %in% c("high_correct", "high_incorrect", "low_correct", "low_incorrect")),aes(x=TR,y=value))+
  geom_line(aes(color=level))+
  geom_line(aes(x=TR,y=0.33),color="black",linetype="dotted")+
  geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=level),alpha=0.2)+
  scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
  ylab("Probability of classifier predicting a face")+
  theme_classic()


```

```{r compare indiv encoding prob}

encoding_level_avg <- data.frame(high = rowMeans(cbind(individual_trial_averages_probs[["high_correct"]]$V6, individual_trial_averages_probs[["high_incorrect"]]$V6), na.rm=TRUE), low = rowMeans(cbind(individual_trial_averages_probs[["low_correct"]]$V6, individual_trial_averages_probs[["low_incorrect"]]$V6),na.rm=TRUE))

t.test(encoding_level_avg$high,encoding_level_avg$low,paired=TRUE)

```

Here, we're looking at correct - incorrect probability - typically, we see a higher probability in the correct trials, but it seems like in the high load trials, it's more likely to predict a face from the incorrect trials than the correct ones during the delay period. Must take this with a grain of salt, however, since those TRs don't have above chance likelihood of predicting a face. 

```{r plot differences between correctness for all subjects}

ggplot(data=individual_trial_probs_melt %>% filter(level %in% c("low_load_correct_diff","high_load_correct_diff")),aes(x=TR,y=value))+
  geom_line(aes(x=TR,y=0), linetype="dotted")+
  geom_line(aes(color=level))+
  geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=level),alpha=0.2)+
  scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
  ylab("Correct - Incorrect Diff in Probability of Classifying Faces")+
  theme_classic()


```

### From templates

In the template, however, there is no difference between load at encoding. Instead, we see that the low correct have significantly more likelihood of having a face classified at probe than either of the high load templates. We also see that for the correct trials, we're more likely to classify from the correct vs incorrect trials. 

```{r plot template average over all subjects}


ggplot(data=template_preds_melt%>% filter(level %in% c("high_correct", "high_incorrect", "low_correct", "low_incorrect")),aes(x=TR,y=value))+
  geom_line(aes(color=level))+
  geom_line(aes(x=TR,y=0.33),color="black",linetype="dotted")+
  geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=level),alpha=0.2)+
  scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
  ylab("Probability of classifier predicting a face")+
  theme_classic()

```

```{r probe template anova}

probe_data_template <- data.frame(high_correct=averages_from_template[["high_correct"]]$V11, high_incorrect = averages_from_template[["high_incorrect"]]$V11, low_correct = averages_from_template[["low_correct"]]$V11)
probe_data_template <- melt(probe_data_template)

probe.aov <- aov(value ~ variable, data = probe_data_template)
summary(probe.aov)
TukeyHSD(probe.aov)

```

Weirdly, in the template, it is during the low load trials where we really can see prediction from the faces. This is probably because in the templates, we don't see any classification from the low load incorrect trials. What's maybe more notable is that there's basically no difference between the correct and incorrect trials at high load. 

```{r plot differences between correctness for template}

ggplot(data=template_preds_melt %>% filter(level %in% c("low_load_correct_diff","high_load_correct_diff")),aes(x=TR,y=value))+
  geom_line(aes(color=level))+
  geom_line(aes(x=TR,y=0), linetype="dotted")+
  geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=level),alpha=0.2)+
  scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
  ylab("Correct - Incorrect Diff in Probability of Classifying Faces")+
  theme_classic()

```

I'm not 100% sure this is statistically valid, but the average prediction is higher for the predictions from template vs predictions from the individual trials. 

```{r compare template to indiv trials}

compare_across_temp_indiv <- data.frame(template = rowMeans(cbind(averages_from_template[["high_correct"]]$V6,
                                                                  averages_from_template[["high_incorrect"]]$V6,
                                                                  averages_from_template[["low_correct"]]$V6)),
                                        indiv = rowMeans(cbind(individual_trial_averages_probs[["high_correct"]]$V6,
                                                               individual_trial_averages_probs[["high_incorrect"]]$V6,
                                                               individual_trial_averages_probs[["low_correct"]]$V6)))

wilcox.test(compare_across_temp_indiv$template, compare_across_temp_indiv$indiv,paired=TRUE)

```

## By Working Memory Capacity Groups 

```{r split into groups}

split_template <- split_trial_type(averages_from_template,WM_groups)
split_indiv_probs <- split_trial_type(individual_trial_averages_probs, WM_groups)

```

### From Indiv Trials  

The only difference between groups we see is a trend towards a difference between low and medium capacity groups during probe for the incorrect high load trial, where we see higher probability of classifying faces in low capacity subjects.  

```{r split group indiv prob plots}

indiv_avgs <- list()

for (i in seq.int(1,4)){
  indiv_avgs[[i]] <- ggplot(data = split_indiv_probs[["avgs"]][[i]][["all"]])+
    geom_line(aes(x=TR,y=mean,color=group))+
    geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=group),alpha=0.2)+
    geom_line(aes(x=TR,y=0.33),color="black",linetype="dotted")+
    scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
    ggtitle(names(split_indiv_probs[["avgs"]])[i])+
    ylab("Probability")+
    theme_classic()
  
}

(indiv_avgs[[1]] + indiv_avgs[[2]]) / (indiv_avgs[[3]] + indiv_avgs[[4]])+
  plot_layout(guides = "collect")+
  plot_annotation(title="Probability of classifier predicting a face from individual trials")

```

```{r anova between groups indiv}

# encoding 
for (trial_type in seq.int(1,4)){ 
  print(names(split_indiv_probs[["all_data"]])[trial_type])
  temp.aov <- aov(split_indiv_probs[["all_data"]][[trial_type]][["all"]][,6] ~ split_indiv_probs[["all_data"]][[trial_type]][["all"]][,16])
  print(summary(temp.aov))
  print(TukeyHSD(temp.aov))
}

# probe
for (trial_type in seq.int(1,4)){ 
  print(names(split_indiv_probs[["all_data"]])[trial_type])
  temp.aov <- aov(split_indiv_probs[["all_data"]][[trial_type]][["all"]][,11] ~ split_indiv_probs[["all_data"]][[trial_type]][["all"]][,16])
  print(summary(temp.aov))
  print(TukeyHSD(temp.aov))
}

```

### From templates 

There are no significant differences during encoding, but we do see a trend towards greater likelihood of face classification at TR 12 in low capacity subjects than high capacity subjects. 

```{r split group template prob plots}

template_avgs <- list()

for (i in seq.int(1,4)){
  template_avgs[[i]] <- ggplot(data = split_template[["avgs"]][[i]][["all"]])+
    geom_line(aes(x=TR,y=mean,color=group))+
    geom_ribbon(aes(x=TR,ymin=se_min,ymax=se_max,fill=group),alpha=0.2)+
    geom_line(aes(x=TR,y=0.33),color="black",linetype="dotted")+
    scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
    ggtitle(names(split_template[["avgs"]])[i])+
    ylab("Probability")+
    theme_classic()
  
}

(template_avgs[[1]] + template_avgs[[2]]) / (template_avgs[[3]] + template_avgs[[4]])+
  plot_layout(guides = "collect")+
  plot_annotation(title="Probability of classifier predicting a face from trial templates")

```

```{r anova between groups template}

for (trial_type in seq.int(1,4)){ 
  print(names(split_template[["all_data"]])[trial_type])
  temp.aov <- aov(split_template[["all_data"]][[trial_type]][["all"]][,12] ~ split_template[["all_data"]][[trial_type]][["all"]][,16])
  print(summary(temp.aov))
  print(TukeyHSD(temp.aov))
}

```

# Correlation with Behavior 

## Individual Trials

### Averaged over time

One significant relationship between classification probability averaged over time and behavior is with DFR high load accuracy and classfication probability at high load incorrect trials - higher classification probability is associated with less accuracy. We also see a significant relationship between high load accuracy and the difference in classification probability - the stronger the correct - incorrect difference, the higher accuracy. 

We also see trends (p ~ 0.06) for the relationships of omnibus span and classification probability in the difference between correct and incorrect, and for the accuracy at high load and classification in the low load correct trials. 

```{r make plots to correlate indiv over time}

indiv_avg_over_time <- data.frame(high_correct = rowMeans(individual_trial_averages_probs[["high_correct"]][,1:14]),
                                  high_incorrect = rowMeans(individual_trial_averages_probs[["high_incorrect"]][,1:14]),
                                  low_correct = rowMeans(individual_trial_averages_probs[["low_correct"]][,1:14]),
                                  low_incorrect = rowMeans(individual_trial_averages_probs[["low_incorrect"]][,1:14],na.rm=TRUE), 
                                  high_load_diff_correct = rowMeans(individual_trial_averages_probs[["high_load_correct_diff"]][,1:14]),
                                  low_load_diff_correct = rowMeans(individual_trial_averages_probs[["low_load_correct_diff"]][,1:14]))

indiv_avg_over_time[is.na(indiv_avg_over_time)] <- NA 
indiv_avg_over_time <- data.frame(indiv_avg_over_time, omnibus_span = constructs_fMRI$omnibus_span_no_DFR_MRI, PTID = constructs_fMRI$PTID)
indiv_avg_over_time <- merge(indiv_avg_over_time, p200_data[,c("PTID","BPRS_TOT","XDFR_MRI_ACC_L3", "XDFR_MRI_ACC_L1")],by="PTID")


plot_list <- list()

for (i in seq.int(1,6)){
  plot_data <- indiv_avg_over_time[,c(i+1,8:11)]
  colnames(plot_data)[1] <- "prob"
  plot_list[["omnibus"]][[i]] <- ggplot(data = plot_data,aes(x=prob,y=omnibus_span))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(indiv_avg_over_time)[i+1])+
    theme_classic()
  
  plot_list[["DFR_Acc"]][[i]] <- ggplot(data = plot_data,aes(x=prob,y=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(indiv_avg_over_time)[i+1])+
    theme_classic()
  
  plot_list[["BPRS"]][[i]] <- ggplot(data = plot_data,aes(x=prob,y=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(indiv_avg_over_time)[i+1])+
    theme_classic()
  
}

(plot_list[["omnibus"]][[1]] + plot_list[["omnibus"]][[2]]) /
  (plot_list[["omnibus"]][[3]] + plot_list[["omnibus"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and Omnibus Span")

(plot_list[["omnibus"]][[5]] + plot_list[["omnibus"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and Omnibus Span")

(plot_list[["DFR_Acc"]][[1]] + plot_list[["DFR_Acc"]][[2]]) /
  (plot_list[["DFR_Acc"]][[3]] + plot_list[["DFR_Acc"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and DFR High Load Accuracy")

(plot_list[["DFR_Acc"]][[5]] + plot_list[["DFR_Acc"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and DFR High Load Accuracy")

(plot_list[["BPRS"]][[1]] + plot_list[["BPRS"]][[2]]) /
  (plot_list[["BPRS"]][[3]] + plot_list[["BPRS"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and BPRS")
(plot_list[["BPRS"]][[5]] + plot_list[["BPRS"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and BPRS")

cor.test(indiv_avg_over_time$high_correct, indiv_avg_over_time$omnibus_span)
cor.test(indiv_avg_over_time$high_load_diff_correct, indiv_avg_over_time$omnibus_span)

cor.test(indiv_avg_over_time$low_correct, indiv_avg_over_time$XDFR_MRI_ACC_L3)
cor.test(indiv_avg_over_time$high_incorrect, indiv_avg_over_time$XDFR_MRI_ACC_L3)
cor.test(indiv_avg_over_time$high_load_diff_correct, indiv_avg_over_time$XDFR_MRI_ACC_L3)



```

### All subjects

#### Across time 

If we look at the patterns over time, we can see that BPRS tends to be positively related to classification only in the probe period during the high load trials, but starts to peak earlier in the low load trials. There is most correlation with accuracy during the encoding period. We also see a slight negative correlation with omnibus span during probe, particularly in the correct high load trials. 

Next step is to pull out some of these correlations and see if they're significant. 

```{r make indiv correlations with behav across time for all subj}

data_to_plot <- merge(constructs_fMRI,p200_data,by="PTID")
data_to_plot <- merge(data_to_plot,p200_clinical_zscores,by="PTID")

data_to_plot <- data_to_plot[,c(1,7,14,15,41,42)]
data_to_plot$ACC_LE <- data_to_plot$XDFR_MRI_ACC_L3 - data_to_plot$XDFR_MRI_ACC_L1

corr_to_behav_plots <- list()

for (i in seq.int(1,6)){
  measure_by_time <- data.frame(matrix(nrow=4,ncol=14))
  
  for (measure in seq.int(2,5)){
    for (TR in seq.int(1,14)){
      measure_by_time[measure-1,TR] <- cor(data_to_plot[,measure],individual_trial_averages_probs[[i]][,TR],use = "pairwise.complete.obs")
    }
  }
  
  measure_by_time <- data.frame(t(measure_by_time))
  measure_by_time$TR <- seq.int(1,14)
  
  colnames(measure_by_time)[1:4] <- colnames(data_to_plot)[2:5]
  
  melted_measure_by_time <- melt(measure_by_time,id.vars="TR")
  
  corr_to_behav_plots[[names(individual_trial_averages_probs)[i]]] <- ggplot(data=melted_measure_by_time,aes(x=TR,y=value))+
    geom_line(aes(color=variable))+
    scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
    ggtitle(names(individual_trial_averages_probs)[i])+
    theme_classic()
  
}


```

```{r print TR indiv correlation all subj plots}

(corr_to_behav_plots[[1]] + corr_to_behav_plots[[2]]) / (corr_to_behav_plots[[3]] + corr_to_behav_plots[[4]])+
  plot_layout(guides="collect")+
  plot_annotation(title = "Correlation between face classification and behavioral measures")

(corr_to_behav_plots[[5]] + corr_to_behav_plots[[6]])+
  plot_layout(guides="collect")+
  plot_annotation(title = "Correlation between difference across correctness in face classification and behavioral measures")


```

```{r pull out specfic time points from indiv correlation}

plot_list <- list()

for(trial_type in seq.int(1,6)){ 
  temp_plot_data <- merge(p200_data, individual_trial_averages_probs[[trial_type]],by="PTID")
  temp_plot_data <- merge(temp_plot_data,constructs_fMRI,by="PTID")
  
  plot_list[["omnibus"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["omnibus"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["omnibus"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  # Acc
  
  plot_list[["L3_Acc"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["L3_Acc"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["L3_Acc"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  # BPRS  
  plot_list[["BPRS"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["BPRS"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  plot_list[["BPRS"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(individual_trial_averages_probs)[trial_type])+
    theme_classic()
  
  
}


```

#### Encoding 

We see significant correlations between high load accuracy and classification probability during high load correct trials and the correct-incorrect difference in high load trials. 

```{r plot specific time points from indiv - encoding }

(plot_list[["omnibus"]][["cue"]][[1]] + plot_list[["omnibus"]][["cue"]][[2]]) /  
  (plot_list[["omnibus"]][["cue"]][[3]] + plot_list[["omnibus"]][["cue"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at Cue Period")

(plot_list[["omnibus"]][["cue"]][[5]] + plot_list[["omnibus"]][["cue"]][[6]])  +
  plot_annotation(title = "Omnibus vs Classification at Cue Period")

(plot_list[["L3_Acc"]][["cue"]][[1]] + plot_list[["L3_Acc"]][["cue"]][[2]]) /  
  (plot_list[["L3_Acc"]][["cue"]][[3]] + plot_list[["L3_Acc"]][["cue"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at Cue Period")

(plot_list[["L3_Acc"]][["cue"]][[5]] + plot_list[["L3_Acc"]][["cue"]][[6]])  +
  plot_annotation(title = "L3_Acc vs Classification at Cue Period")

(plot_list[["BPRS"]][["cue"]][[1]] + plot_list[["BPRS"]][["cue"]][[2]]) /  
  (plot_list[["BPRS"]][["cue"]][[3]] + plot_list[["BPRS"]][["cue"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at Cue Period")

(plot_list[["BPRS"]][["cue"]][[5]] + plot_list[["BPRS"]][["cue"]][[6]])  +
  plot_annotation(title = "BPRS vs Classification at Cue Period")

cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V6,temp_plot_data$omnibus_span_no_DFR_MRI)
cor.test(individual_trial_averages_probs[["high_correct"]]$V6,temp_plot_data$XDFR_MRI_ACC_L3)
cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V6,temp_plot_data$XDFR_MRI_ACC_L3)
cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V6,temp_plot_data$BPRS_TOT)



``` 

#### Delay 

There is a significant negative relationship between accuracy at high load and the probability of face classification at low load. 

``` {r plot specific time points from indiv - delay }

(plot_list[["omnibus"]][["delay"]][[1]] + plot_list[["omnibus"]][["delay"]][[2]]) /  
  (plot_list[["omnibus"]][["delay"]][[3]] + plot_list[["omnibus"]][["delay"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at delay Period")

(plot_list[["omnibus"]][["delay"]][[5]] + plot_list[["omnibus"]][["delay"]][[6]])  +
  plot_annotation(title = "Omnibus vs Classification at delay Period")

(plot_list[["L3_Acc"]][["delay"]][[1]] + plot_list[["L3_Acc"]][["delay"]][[2]]) /  
  (plot_list[["L3_Acc"]][["delay"]][[3]] + plot_list[["L3_Acc"]][["delay"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at delay Period")

(plot_list[["L3_Acc"]][["delay"]][[5]] + plot_list[["L3_Acc"]][["delay"]][[6]])  +
  plot_annotation(title = "L3_Acc vs Classification at delay Period")

(plot_list[["BPRS"]][["delay"]][[1]] + plot_list[["BPRS"]][["delay"]][[2]]) /  
  (plot_list[["BPRS"]][["delay"]][[3]] + plot_list[["BPRS"]][["delay"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at delay Period")

(plot_list[["BPRS"]][["delay"]][[5]] + plot_list[["BPRS"]][["delay"]][[6]])  +
  plot_annotation(title = "BPRS vs Classification at delay Period")

cor.test(individual_trial_averages_probs[["high_correct"]]$V8,temp_plot_data$omnibus_span_no_DFR_MRI)
cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V8,temp_plot_data$omnibus_span_no_DFR_MRI)
cor.test(individual_trial_averages_probs[["low_load_correct_diff"]]$V8,temp_plot_data$omnibus_span_no_DFR_MRI)

cor.test(individual_trial_averages_probs[["low_correct"]]$V8,temp_plot_data$XDFR_MRI_ACC_L3)
cor.test(individual_trial_averages_probs[["low_load_correct_diff"]]$V8,temp_plot_data$XDFR_MRI_ACC_L3)


cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V8,temp_plot_data$BPRS_TOT)


``` 

#### Probe

Probability of classification at incorrect high load trial is significantly negatively correlated with high load accuracy during probe and positively with correct - incorrect difference at high load. 

```{r plot specific time points from indiv - probe }

(plot_list[["omnibus"]][["probe"]][[1]] + plot_list[["omnibus"]][["probe"]][[2]]) /  
  (plot_list[["omnibus"]][["probe"]][[3]] + plot_list[["omnibus"]][["probe"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at probe Period")

(plot_list[["omnibus"]][["probe"]][[5]] + plot_list[["omnibus"]][["probe"]][[6]])  +
  plot_annotation(title = "Omnibus vs Classification at probe Period")

(plot_list[["L3_Acc"]][["probe"]][[1]] + plot_list[["L3_Acc"]][["probe"]][[2]]) /  
  (plot_list[["L3_Acc"]][["probe"]][[3]] + plot_list[["L3_Acc"]][["probe"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at probe Period")

(plot_list[["L3_Acc"]][["probe"]][[5]] + plot_list[["L3_Acc"]][["probe"]][[6]])  +
  plot_annotation(title = "L3_Acc vs Classification at probe Period")

(plot_list[["BPRS"]][["probe"]][[1]] + plot_list[["BPRS"]][["probe"]][[2]]) /  
  (plot_list[["BPRS"]][["probe"]][[3]] + plot_list[["BPRS"]][["probe"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at probe Period")

(plot_list[["BPRS"]][["probe"]][[5]] + plot_list[["BPRS"]][["probe"]][[6]])  +
  plot_annotation(title = "BPRS vs Classification at probe Period")

cor.test(individual_trial_averages_probs[["high_incorrect"]]$V11,temp_plot_data$XDFR_MRI_ACC_L3)
cor.test(individual_trial_averages_probs[["high_load_correct_diff"]]$V11,temp_plot_data$XDFR_MRI_ACC_L3)




```

```{r correlate behav to each indiv category TR for each group, warning=FALSE}

behav_classification_corr_list <- list()

for (trial_type in seq.int(1,6)){ 
  group_corrs_omnibus <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_omnibus) <- names(split_indiv_probs[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_omnibus) <- seq.int(1,14)
  
  group_corrs_acc <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_acc) <- names(split_indiv_probs[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_acc) <- seq.int(1,14)
  
  group_corrs_BPRS <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_BPRS) <- names(split_indiv_probs[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_BPRS) <- seq.int(1,14)
  
  for (level in seq.int(1,3)){ 
    temp_subj <- split_indiv_probs[["all_data"]][[trial_type]][[level]][order(split_indiv_probs[["all_data"]][[trial_type]][[level]]$PTID),]
    temp_data <- data_to_plot[data_to_plot$PTID %in% split_indiv_probs[["all_data"]][[trial_type]][[level]]$PTID,]
    
    for (TR in seq.int(1,14)){
      
      group_corrs_omnibus[level,TR] <- cor(temp_subj[,TR],temp_data$omnibus_span_no_DFR_MRI,use="pairwise.complete.obs")
      group_corrs_acc[level,TR] <- cor(temp_subj[,TR],temp_data$XDFR_MRI_ACC_L3,use="pairwise.complete.obs")
      group_corrs_BPRS[level,TR] <- cor(temp_subj[,TR],temp_data$BPRS_TOT.x,use="pairwise.complete.obs")
      
    }
    group_corrs_acc$level <- factor(rownames(group_corrs_acc))
    group_corrs_BPRS$level <- factor(rownames(group_corrs_acc))
    group_corrs_omnibus$level <- factor(rownames(group_corrs_acc))
    
  }
  
  behav_classification_corr_list[["omnibus"]][[names(split_indiv_probs[["all_data"]])[trial_type]]] <- group_corrs_omnibus
  behav_classification_corr_list[["BPRS"]][[names(split_indiv_probs[["all_data"]])[trial_type]]] <- group_corrs_BPRS
  behav_classification_corr_list[["L3_Acc"]][[names(split_indiv_probs[["all_data"]])[trial_type]]] <- group_corrs_acc
}

```

#### By Working Memory Capacity

```{r melt group vs behav indiv, warning=FALSE}

behav_classification_corr_melt <- list()
behav_split_plot_list <- list()

for (measure in seq.int(1,3)){
  for (trial_type in seq.int(1,6)){ 
    behav_classification_corr_melt[[names(behav_classification_corr_list)[measure]]][[names(behav_classification_corr_list[[measure]])[trial_type]]] <- melt(behav_classification_corr_list[[measure]][[trial_type]],id.vars="level")
    behav_classification_corr_melt[[measure]][[trial_type]]$variable <- as.numeric(as.character(behav_classification_corr_melt[[measure]][[trial_type]]$variable))
    behav_classification_corr_melt[[measure]][[trial_type]]$level <- factor(behav_classification_corr_melt[[measure]][[trial_type]]$level, levels=c("high","med","low"))
    
    behav_split_plot_list[[names(behav_classification_corr_melt)[measure]]][[names(behav_classification_corr_melt[[measure]])[trial_type]]] <- 
      ggplot(data = behav_classification_corr_melt[[measure]][[trial_type]],aes(x=variable,y=value))+
      geom_line(aes(color=level))+
      scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
      ggtitle(names(behav_classification_corr_list[[measure]])[trial_type])+
      xlab("TR")+
      ylab("Correlation")+
      theme_classic()
    
  }
}

```

```{r plot indiv prob vs behav by group}

(behav_split_plot_list[["omnibus"]][[1]] + behav_split_plot_list[["omnibus"]][[2]]) / 
  (behav_split_plot_list[["omnibus"]][[3]] + behav_split_plot_list[["omnibus"]][[4]])+
  plot_annotation("Omnibus Span Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["omnibus"]][[5]] + behav_split_plot_list[["omnibus"]][[6]]) + 
  plot_annotation("Omnibus Span Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["L3_Acc"]][[1]] + behav_split_plot_list[["L3_Acc"]][[2]]) / 
  (behav_split_plot_list[["L3_Acc"]][[3]] + behav_split_plot_list[["L3_Acc"]][[4]])+
  plot_annotation("High Load Acc Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["L3_Acc"]][[5]] + behav_split_plot_list[["L3_Acc"]][[6]]) +
  plot_annotation("High Load Acc Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["BPRS"]][[1]] + behav_split_plot_list[["BPRS"]][[2]]) / 
  (behav_split_plot_list[["BPRS"]][[3]] + behav_split_plot_list[["BPRS"]][[4]])+
  plot_annotation("BPRS Total Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["BPRS"]][[5]] + behav_split_plot_list[["BPRS"]][[6]]) +
  plot_annotation("BPRS Total Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")




```

## Template

### Averaged over time

If we average over time, there are no relationships between template classification and behavior. 

```{r make plots to correlate template over time}

template_avg_over_time <- data.frame(high_correct = rowMeans(averages_from_template[["high_correct"]][,1:14]),
                                     high_incorrect = rowMeans(averages_from_template[["high_incorrect"]][,1:14]),
                                     low_correct = rowMeans(averages_from_template[["low_correct"]][,1:14]),
                                     low_incorrect = rowMeans(averages_from_template[["low_incorrect"]][,1:14],na.rm=TRUE), 
                                     high_load_diff_correct = rowMeans(averages_from_template[["high_load_correct_diff"]][,1:14]),
                                     low_load_diff_correct = rowMeans(averages_from_template[["low_load_correct_diff"]][,1:14]))

template_avg_over_time[is.na(template_avg_over_time)] <- NA 
template_avg_over_time <- data.frame(template_avg_over_time, omnibus_span = constructs_fMRI$omnibus_span_no_DFR_MRI, PTID = constructs_fMRI$PTID)
template_avg_over_time <- merge(template_avg_over_time, p200_data[,c("PTID","BPRS_TOT","XDFR_MRI_ACC_L3", "XDFR_MRI_ACC_L1")],by="PTID")


plot_list <- list()

for (i in seq.int(1,6)){
  plot_data <- template_avg_over_time[,c(i+1,8:11)]
  colnames(plot_data)[1] <- "prob"
  plot_list[["omnibus"]][[i]] <- ggplot(data = plot_data,aes(x=prob,y=omnibus_span))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(template_avg_over_time)[i+1])+
    theme_classic()
  
  plot_list[["DFR_Acc"]][[i]] <- ggplot(data = plot_data,aes(x=prob,y=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(template_avg_over_time)[i+1])+
    theme_classic()
  
  plot_list[["BPRS"]][[i]] <- ggplot(data = plot_data,aes(x=prob,y=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    xlab("Probability")+
    ggtitle(colnames(template_avg_over_time)[i+1])+
    theme_classic()
  
}

(plot_list[["omnibus"]][[1]] + plot_list[["omnibus"]][[2]]) /
  (plot_list[["omnibus"]][[3]] + plot_list[["omnibus"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and Omnibus Span")

(plot_list[["omnibus"]][[5]] + plot_list[["omnibus"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and Omnibus Span")

(plot_list[["DFR_Acc"]][[1]] + plot_list[["DFR_Acc"]][[2]]) /
  (plot_list[["DFR_Acc"]][[3]] + plot_list[["DFR_Acc"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and DFR High Load Accuracy")

(plot_list[["DFR_Acc"]][[5]] + plot_list[["DFR_Acc"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and DFR High Load Accuracy")

(plot_list[["BPRS"]][[1]] + plot_list[["BPRS"]][[2]]) /
  (plot_list[["BPRS"]][[3]] + plot_list[["BPRS"]][[4]]) + 
  plot_annotation(title="Correlation of face probability and BPRS")
(plot_list[["BPRS"]][[5]] + plot_list[["BPRS"]][[6]])+
  plot_annotation(title="Correlation of difference in face probability across correctness and BPRS")


```

### All subjects

#### Over time 

```{r make template correlations with behav across time for all subj, warning = FALSE}

data_to_plot <- merge(constructs_fMRI,p200_data,by="PTID")
data_to_plot <- merge(data_to_plot,p200_clinical_zscores,by="PTID")

data_to_plot <- data_to_plot[,c(1,7,14,15,41,42)]
data_to_plot$ACC_LE <- data_to_plot$XDFR_MRI_ACC_L3 - data_to_plot$XDFR_MRI_ACC_L1

corr_to_behav_plots <- list()


for (i in seq.int(1,6)){
  measure_by_time <- data.frame(matrix(nrow=4,ncol=14))
  
  for (measure in seq.int(2,5)){
    for (TR in seq.int(1,14)){
      measure_by_time[measure-1,TR] <- cor(data_to_plot[,measure],averages_from_template[[i]][,TR],use = "pairwise.complete.obs")
    }
  }
  
  measure_by_time <- data.frame(t(measure_by_time))
  measure_by_time$TR <- seq.int(1,14)
  
  colnames(measure_by_time)[1:4] <- colnames(data_to_plot)[2:5]
  
  melted_measure_by_time <- melt(measure_by_time,id.vars="TR")
  
  corr_to_behav_plots[[names(averages_from_template)[i]]] <- ggplot(data=melted_measure_by_time,aes(x=TR,y=value))+
    geom_line(aes(color=variable))+
    scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
    ggtitle(names(averages_from_template)[i])+
    theme_classic()
  
}


```

```{r print TR template correlation all subj plots}

(corr_to_behav_plots[[1]] + corr_to_behav_plots[[2]]) / (corr_to_behav_plots[[3]] + corr_to_behav_plots[[4]])+
  plot_layout(guides="collect")+
  plot_annotation(title = "Correlation between face classification and behavioral measures")

(corr_to_behav_plots[[5]] + corr_to_behav_plots[[6]])+
  plot_layout(guides="collect")+
  plot_annotation(title = "Correlation between face classification and behavioral measures")


```

```{r pull out specfic time points from template correlation}

plot_list <- list()

for(trial_type in seq.int(1,6)){ 
  temp_plot_data <- merge(p200_data, averages_from_template[[trial_type]],by="PTID")
  temp_plot_data <- merge(temp_plot_data,constructs_fMRI,by="PTID")
  
  plot_list[["omnibus"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["omnibus"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["omnibus"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=omnibus_span_no_DFR_MRI))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  # Acc
  
  plot_list[["L3_Acc"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["L3_Acc"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["L3_Acc"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=XDFR_MRI_ACC_L3))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  # BPRS  
  plot_list[["BPRS"]][["cue"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V6,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["BPRS"]][["delay"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V8,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  plot_list[["BPRS"]][["probe"]][[trial_type]] <- ggplot(data=temp_plot_data,aes(y=V11,x=BPRS_TOT))+
    geom_point()+
    stat_smooth(method="lm")+
    ylab("Probability")+
    ggtitle(names(averages_from_template)[trial_type])+
    theme_classic()
  
  
}


```

#### Encoding 

```{r plot specific time points from template - encoding }


(plot_list[["omnibus"]][["cue"]][[1]] + plot_list[["omnibus"]][["cue"]][[2]]) /  
  (plot_list[["omnibus"]][["cue"]][[3]] + plot_list[["omnibus"]][["cue"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at Cue Period")

(plot_list[["omnibus"]][["cue"]][[5]] + plot_list[["omnibus"]][["cue"]][[6]]) +
  plot_annotation(title = "Omnibus vs Classification at Cue Period")

(plot_list[["L3_Acc"]][["cue"]][[1]] + plot_list[["L3_Acc"]][["cue"]][[2]]) /  
  (plot_list[["L3_Acc"]][["cue"]][[3]] + plot_list[["L3_Acc"]][["cue"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at Cue Period")

(plot_list[["L3_Acc"]][["cue"]][[5]] + plot_list[["L3_Acc"]][["cue"]][[6]]) +
  plot_annotation(title = "L3_Acc vs Classification at Cue Period")

(plot_list[["BPRS"]][["cue"]][[1]] + plot_list[["BPRS"]][["cue"]][[2]]) /  
  (plot_list[["BPRS"]][["cue"]][[3]] + plot_list[["BPRS"]][["cue"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at Cue Period")

(plot_list[["BPRS"]][["cue"]][[5]] + plot_list[["BPRS"]][["cue"]][[6]]) +
  plot_annotation(title = "BPRS vs Classification at Cue Period")


``` 

#### Delay 

``` {r plot specific time points from template - delay }

(plot_list[["omnibus"]][["delay"]][[1]] + plot_list[["omnibus"]][["delay"]][[2]]) /  
  (plot_list[["omnibus"]][["delay"]][[3]] + plot_list[["omnibus"]][["delay"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at delay Period")

(plot_list[["omnibus"]][["delay"]][[5]] + plot_list[["omnibus"]][["delay"]][[6]]) +
  plot_annotation(title = "Omnibus vs Classification at delay Period")

(plot_list[["L3_Acc"]][["delay"]][[1]] + plot_list[["L3_Acc"]][["delay"]][[2]]) /  
  (plot_list[["L3_Acc"]][["delay"]][[3]] + plot_list[["L3_Acc"]][["delay"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at delay Period")

(plot_list[["L3_Acc"]][["delay"]][[5]] + plot_list[["L3_Acc"]][["delay"]][[6]]) +
  plot_annotation(title = "L3_Acc vs Classification at delay Period")

(plot_list[["BPRS"]][["delay"]][[1]] + plot_list[["BPRS"]][["delay"]][[2]]) /  
  (plot_list[["BPRS"]][["delay"]][[3]] + plot_list[["BPRS"]][["delay"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at delay Period")

(plot_list[["BPRS"]][["delay"]][[5]] + plot_list[["BPRS"]][["delay"]][[6]]) +
  plot_annotation(title = "BPRS vs Classification at delay Period")


cor.test(averages_from_template[["high_incorrect"]]$V8,temp_plot_data$omnibus_span_no_DFR_MRI)


``` 

#### Probe

There is a significant relationship with BPRS and the difference between high correct and incorrect trials. 

```{r plot specific time points from template - probe }

(plot_list[["omnibus"]][["probe"]][[1]] + plot_list[["omnibus"]][["probe"]][[2]]) /  
  (plot_list[["omnibus"]][["probe"]][[3]] + plot_list[["omnibus"]][["probe"]][[4]]) +
  plot_annotation(title = "Omnibus vs Classification at probe Period")

(plot_list[["omnibus"]][["probe"]][[5]] + plot_list[["omnibus"]][["probe"]][[6]]) +
  plot_annotation(title = "Omnibus vs Classification at probe Period")

(plot_list[["L3_Acc"]][["probe"]][[1]] + plot_list[["L3_Acc"]][["probe"]][[2]]) /  
  (plot_list[["L3_Acc"]][["probe"]][[3]] + plot_list[["L3_Acc"]][["probe"]][[4]]) +
  plot_annotation(title = "L3_Acc vs Classification at probe Period")


(plot_list[["L3_Acc"]][["probe"]][[5]] + plot_list[["L3_Acc"]][["probe"]][[6]]) +
  plot_annotation(title = "L3_Acc vs Classification at probe Period")

(plot_list[["BPRS"]][["probe"]][[1]] + plot_list[["BPRS"]][["probe"]][[2]]) /  
  (plot_list[["BPRS"]][["probe"]][[3]] + plot_list[["BPRS"]][["probe"]][[4]]) +
  plot_annotation(title = "BPRS vs Classification at probe Period")

(plot_list[["BPRS"]][["probe"]][[5]] + plot_list[["BPRS"]][["probe"]][[6]]) +
  plot_annotation(title = "BPRS vs Classification at probe Period")



cor.test(averages_from_template[["low_load_correct_diff"]]$V11,temp_plot_data$omnibus_span_no_DFR_MRI)
cor.test(averages_from_template[["high_load_correct_diff"]]$V11,temp_plot_data$XDFR_MRI_ACC_L3)
cor.test(averages_from_template[["high_correct"]]$V11,temp_plot_data$BPRS_TOT)
cor.test(averages_from_template[["high_incorrect"]]$V11,temp_plot_data$BPRS_TOT)
cor.test(averages_from_template[["high_load_correct_diff"]]$V11,temp_plot_data$BPRS_TOT)


```

```{r correlate behav to each template TR for each group, warning=FALSE}

behav_classification_corr_list <- list()

for (trial_type in seq.int(1,6)){ 
  group_corrs_omnibus <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_omnibus) <- names(split_template[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_omnibus) <- seq.int(1,14)
  
  group_corrs_acc <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_acc) <- names(split_template[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_acc) <- seq.int(1,14)
  
  group_corrs_BPRS <- data.frame(matrix(nrow=3,ncol=14))
  rownames(group_corrs_BPRS) <- names(split_template[["all_data"]][[trial_type]])[1:3]
  colnames(group_corrs_BPRS) <- seq.int(1,14)
  
  for (level in seq.int(1,3)){ 
    temp_subj <- split_template[["all_data"]][[trial_type]][[level]][order(split_template[["all_data"]][[trial_type]][[level]]$PTID),]
    temp_data <- data_to_plot[data_to_plot$PTID %in% split_template[["all_data"]][[trial_type]][[level]]$PTID,]
    
    for (TR in seq.int(1,14)){
      
      group_corrs_omnibus[level,TR] <- cor(temp_subj[,TR],temp_data$omnibus_span_no_DFR_MRI,use="pairwise.complete.obs")
      group_corrs_acc[level,TR] <- cor(temp_subj[,TR],temp_data$XDFR_MRI_ACC_L3,use="pairwise.complete.obs")
      group_corrs_BPRS[level,TR] <- cor(temp_subj[,TR],temp_data$BPRS_TOT.x,use="pairwise.complete.obs")
      
    }
    group_corrs_acc$level <- factor(rownames(group_corrs_acc))
    group_corrs_BPRS$level <- factor(rownames(group_corrs_acc))
    group_corrs_omnibus$level <- factor(rownames(group_corrs_acc))
    
  }
  
  behav_classification_corr_list[["omnibus"]][[names(split_template[["all_data"]])[trial_type]]] <- group_corrs_omnibus
  behav_classification_corr_list[["BPRS"]][[names(split_template[["all_data"]])[trial_type]]] <- group_corrs_BPRS
  behav_classification_corr_list[["L3_Acc"]][[names(split_template[["all_data"]])[trial_type]]] <- group_corrs_acc
}

```

#### By Working Memory Capacity

```{r melt group vs behav template, warning = FALSE}

behav_classification_corr_melt <- list()
behav_split_plot_list <- list()

for (measure in seq.int(1,3)){
  for (trial_type in seq.int(1,6)){ 
    behav_classification_corr_melt[[names(behav_classification_corr_list)[measure]]][[names(behav_classification_corr_list[[measure]])[trial_type]]] <- melt(behav_classification_corr_list[[measure]][[trial_type]],id.vars="level")
    behav_classification_corr_melt[[measure]][[trial_type]]$variable <- as.numeric(as.character(behav_classification_corr_melt[[measure]][[trial_type]]$variable))
    behav_classification_corr_melt[[measure]][[trial_type]]$level <- factor(behav_classification_corr_melt[[measure]][[trial_type]]$level, levels=c("high","med","low"))
    
    behav_split_plot_list[[names(behav_classification_corr_melt)[measure]]][[names(behav_classification_corr_melt[[measure]])[trial_type]]] <- 
      ggplot(data = behav_classification_corr_melt[[measure]][[trial_type]],aes(x=variable,y=value))+
      geom_line(aes(color=level))+
      scale_x_continuous(breaks = c(1:14),labels=c(1:14))+
      ggtitle(names(behav_classification_corr_list[[measure]])[trial_type])+
      xlab("TR")+
      ylab("Correlation")+
      theme_classic()
    
  }
}

```

```{r plot template prob vs behav by group}

(behav_split_plot_list[["omnibus"]][[1]] + behav_split_plot_list[["omnibus"]][[2]]) / 
  (behav_split_plot_list[["omnibus"]][[3]] + behav_split_plot_list[["omnibus"]][[4]])+
  plot_annotation("Omnibus Span Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["omnibus"]][[5]] + behav_split_plot_list[["omnibus"]][[6]]) + 
  plot_annotation("Omnibus Span Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["L3_Acc"]][[1]] + behav_split_plot_list[["L3_Acc"]][[2]]) / 
  (behav_split_plot_list[["L3_Acc"]][[3]] + behav_split_plot_list[["L3_Acc"]][[4]])+
  plot_annotation("High Load Acc Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["L3_Acc"]][[5]] + behav_split_plot_list[["L3_Acc"]][[6]]) + 
  plot_annotation("High Load Acc Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")


(behav_split_plot_list[["BPRS"]][[1]] + behav_split_plot_list[["BPRS"]][[2]]) / 
  (behav_split_plot_list[["BPRS"]][[3]] + behav_split_plot_list[["BPRS"]][[4]])+
  plot_annotation("BPRS Total Correlation with Face Classification Probability by Group")+
  plot_layout(guides="collect")

(behav_split_plot_list[["BPRS"]][[5]] + behav_split_plot_list[["BPRS"]][[6]]) + 
  plot_annotation("BPRS Total with Face Classification Probability by Group")+
  plot_layout(guides="collect")



```

